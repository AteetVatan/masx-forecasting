[
  {
    "section": "Introduction",
    "text": "Through the weaponization of social media, the internet is changing war and politics, just as war and politics are changing the internet. Terrorists livestream their attacks, “Twitter wars” produce real-world casualties, and viral disinformation alters not just the flow of battles, but the very fate of nations. The result is that war, tech, and politics have blurred into a new kind of battlespace that plays out on our smartphones. P. W. Singer and Emerson T. Brooking tackle the mind-bending questions that arise when war goes online and the online world goes to war. They explore how ISIS copies the Instagram tactics of Taylor Swift, a former World of Warcraft addict foils war crimes thousands of miles away, internet trolls shape elections, and China uses a smartphone app to police the thoughts of its 1.4 billion citizens. What can be kept secret in a world of networks? Does social media expose the truth or bury it? And what role do ordinary people now play in international conflicts? Delving into the web’s darkest corners, we meet the unexpected warriors of social media, such as the rapper turned jihadist PR czar and the Russian hipsters who wage unceasing infowars against the West. Finally, looking to the crucial years ahead, LikeWar outlines a radical new paradigm for understanding and defending against the unprecedented threats of our networked world.",
    "meta": {
      "theme": "The weaponization of social media and its impact on war, politics, and the internet.",
      "region": "Global",
      "use_case": "Understanding the changing nature of conflict in the digital age.",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture",
        "geostrategic_positioning"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "warfare",
        "politics",
        "information operations",
        "disinformation",
        "cybersecurity"
      ],
      "influence_map": [],
      "chunk_index": 1
    },
    "id": "likewar_001"
  },
  {
    "section": "The War Begins",
    "text": "The opening shot of the war was fired on May 4, 2009, with Donald Trump’s first tweet.  Social media platforms like Twitter, Facebook, and YouTube were on the verge of becoming central to civic life and global politics.  A few weeks later, Michael Jackson's death and the subsequent outpouring of grief online demonstrated the power of social media to shape shared experiences.  Trump, facing business setbacks, began using Twitter more frequently, his tone shifting to become more personal and combative.  He engaged in online feuds, honing his characteristically aggressive language. This garnered attention and as the feed became more personal, it also became more political.  Trump used the platform to test political messages, attacking President Obama and flirting with the idea of running for office.  Social media provided immediate feedback, validating his approach and allowing him to refine his message.  Trump became hooked on the dopamine rush of online engagement, personally authoring thousands of tweets.  His journey from businessman to reality TV star to right-wing political figure was intertwined with his mastery of social media as a tool for attention and influence.  This transformation culminated in his 2017 presidential announcement, broadcast to a world reshaped by online virality and “alternative facts.”",
    "meta": {
      "theme": "The rise of Donald Trump's use of social media as a tool for political influence.",
      "region": "United States",
      "use_case": "Illustrating the early stages of social media's impact on political discourse and campaigns.",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "politics",
        "US presidential election",
        "Donald Trump",
        "public opinion",
        "political campaigns"
      ],
      "influence_map": [],
      "chunk_index": 2
    },
    "id": "likewar_002"
  },
  {
    "section": "War Goes Viral",
    "text": "The summer of 2014 saw ISIS launch its invasion of northern Iraq, using a hashtag, #AllEyesOnISIS, as a key part of its strategy. This social media campaign, amplified by bots, spread terror and disinformation among the Iraqi population.  Selfies of militants and images of convoys were posted, creating a sense of momentum and fear.  A dedicated smartphone app further boosted their message, allowing followers to connect their accounts and spread ISIS propaganda.  The hashtag became top-trending on Arabic Twitter, reaching millions, including those in the targeted cities.  Demands for surrender spread online, accompanied by gruesome videos of executions. This online campaign acted as a psychological weapon, sowing terror and disunity among the defenders.  This highlighted the changing nature of warfare in a connected world, where mobile phone and internet penetration had become widespread.  The contrast between a previously restrictive regime and the current, hyper-connected environment emphasized the speed and impact of this new form of information warfare.",
    "meta": {
      "theme": "ISIS's use of social media as a tool for psychological warfare and territorial expansion.",
      "region": "Middle East (Iraq)",
      "use_case": "Demonstrating the effectiveness of social media in disseminating propaganda and influencing the outcome of conflicts.",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems",
        "historical_memory"
      ],
      "usage_tags": [
        "social media",
        "warfare",
        "terrorism",
        "ISIS",
        "propaganda",
        "psychological operations",
        "information warfare"
      ],
      "influence_map": [],
      "chunk_index": 3
    },
    "id": "likewar_003"
  },
  {
    "section": "The Fall of Mosul",
    "text": "Over 200,000 Iraqi civilians and 4,500 U.S. soldiers — the wounds of a decade of war — still simmered. Especially in the west and north, where most Sunnis lived, the army was undertrained and often unpaid. Soldiers and police barely trusted each other. Sunni civilians trusted both groups even less. As it laid the groundwork for invasion, ISIS didn’t have to look far for willing spies and insurgents, recruited via online forum boards and coordinated via the messaging service WhatsApp. The prized target for ISIS was Mosul, a 3,000-year-old multicultural metropolis of 1.8 million. As the ISIS vanguard approached and #AllEyesOnISIS went viral, the city was consumed with fear. Sunni, Shia, and Kurdish neighbors eyed each other with suspicion. Were these high-definition beheadings and executions real? Would the same things happen here? Then young Sunni men, inspired by the images of the indomitable black horde, threw themselves into acts of terror, doing the invaders’ work for them. The Iraqi army stood ready to protect the city from this tiny but fearsome horde — in theory, at least. In reality, most of Mosul’s 25,000-strong garrison existed only on paper, either having long since deserted or been invented by corrupt officers eager to fatten their paychecks. Worse, the roughly 10,000 who actually did exist were able to track the invading army’s highly publicized advance and atrocities on their smartphones. With #AllEyesOnISIS, soldiers began to ask each other whether they should fight or flee. The enemy hadn’t even arrived, but fear already ruled the ranks. Defenders began to slip away, and then the trickle became a flood. Thousands of soldiers streamed from the city, many leaving their weapons and vehicles behind. Most of the city’s police followed. Among Mosul’s citizens, the same swirling rumors drove mass panic. Nearly half a million civilians fled. When the invading force of 1,500 ISIS fighters finally reached the city’s outskirts, they were astounded by their good fortune. Only a handful of brave (or confused) soldiers and police remained behind. They were easily overwhelmed. It wasn’t a battle but a massacre, dutifully filmed and edited for the next cycle of easy online distribution. ISIS militants gleefully posted pictures of the arsenal they had captured, mountains of guns and ammunition, and thousands of American-made, state-of-the-art vehicles that ranged from Humvees to M1A1 Abrams battle tanks to a half dozen Black Hawk helicopters. They staged gaudy parades to celebrate their unlikely triumph. Those so inclined could follow these events in real time, flipping between the posts of ISIS fighters marching in the streets and those watching them march. Each point of view was different, but all promised the same: more — much more — to come.",
    "meta": {
      "theme": "The rise of ISIS and the fall of Mosul",
      "region": "Middle East (Iraq)",
      "use_case": "Military offensive leveraging social media",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "information warfare",
        "social media",
        "propaganda",
        "psychological operations"
      ],
      "influence_map": [],
      "chunk_index": 4
    },
    "id": "likewar_004"
  },
  {
    "section": "Strange Defeat: Echoes of the Past",
    "text": "How had it gone so wrong? This was the question that haunted Iraqi officials ensconced in the capital, U.S. military officers now working marathon shifts in the Pentagon, and the hundreds of thousands of refugees forced to abandon their homes. It wasn’t just that entire cities had been lost to a ragtag army of millennials, but that four whole Iraqi army divisions — trained and armed by the most powerful nation in the world — had essentially evaporated into thin air. In the surprising loss of Mosul and collapse of the defending Iraqi forces, though, a student of history could detect echoes of another strange defeat. In 1940, amid the opening stages of World War II, France had seemed unassailable. The nation boasted an army of 5 million soldiers, equipped with modern tanks and artillery. Its Maginot Line, 60 massive fortresses stretched over 900 miles, loomed as the mightiest defensive fortification in the world. French generals had spent twenty years studying the last war with Germany, drawing up precise new battle plans. As 2.5 million Nazi soldiers amassed at the border, French commanders thought they were ready. They weren’t. France would fall in less than two months. German tanks tore through forests the French had thought impassable, making the vaunted Maginot Line irrelevant. The German forces then moved faster than the French generals could think. Commanders received belated orders to halt German units that had already blown past them, gone around them, or simply weren’t there. When French armies retreated, they had no time to establish a new defensive line before the Germans were already upon them, forcing further retreat. The true power of the German blitzkrieg was speed: a pace of advance so relentless that French defenders were consumed with an uneasiness that turned swiftly to panic. The weapon that made all this possible was the humble radio. Radio allowed armored formations to move in swift harmony. Radio spread reports of their attacks — sometimes real, sometimes not — which spread confusion across the entire French army. Radio also let the Germans bombard the French civilian leaders and populace with an endless stream of propaganda, sowing fear and doubt among what soon became a captive audience. Marc Bloch, a French historian and soldier who would ultimately meet his death at the hands of a Nazi firing squad, recorded his memories of the French rout almost as soon as it happened. His recollections survive in a book aptly titled *Strange Defeat*. Bloch described the fear that swept through the French ranks. Soldiers were given continuous orders to fall back, while French fire brigades clogged the roads as they preemptively abandoned their towns to burn. “Many instructions to evacuate were issued before they need have been,” he recalled. “A sort of frenzy of flight swept over the whole country.”",
    "meta": {
      "theme": "Historical parallels between the fall of France and Mosul",
      "region": "Europe (France) and Middle East (Iraq)",
      "use_case": "Analysis of military defeats and the role of technology",
      "strategic_category": [
        "military_doctrine"
      ],
      "economic_category": [],
      "civilizational_category": [
        "historical_memory"
      ],
      "usage_tags": [
        "blitzkrieg",
        "propaganda",
        "psychological warfare"
      ],
      "influence_map": [
        "Strange Defeat by Marc Bloch"
      ],
      "chunk_index": 5
    },
    "id": "likewar_005"
  },
  {
    "section": "The ISIS Blitzkrieg",
    "text": "Where the Germans had harnessed radio and armored vehicles, ISIS pioneered a different sort of blitzkrieg, one that used the internet itself as a weapon. The same Toyota pickup trucks and secondhand weapons of countless guerrilla groups past had taken on a new power when combined with the right Instagram filter, especially when shared hundreds of thousands of times by adoring fans and automated accounts that mimicked them. With careful editing, an indecisive firefight could be recast as a heroic battlefield victory. A few countering voices might claim otherwise, but how could they prove it? These videos and images moved faster than the truth. Their mix of religiosity and ultraviolence was horrifying to many; to some, however, it was intoxicating. Of course, Iraqis weren’t the only ones who watched the Islamic State’s relentless advance. Anyone anywhere in the world with an internet connection could track each agonizing twist and turn of the conflict, using Google Translate to fill in the gaps. Observers could swoop from official Iraqi news sources to the (usually more interesting) social media feeds of the jihadists themselves. You could check the war like you checked the @ESPN Twitter feed. If you were so inclined, you could message with the people fighting it. Sometimes, they’d talk back. Even ISIS militants were addicted to the feedback loop that social media provided. It was a cruel, surreal spectacle. To us, two internet junkies and defense analysts, it also sounded an alarm bell. Many articles and books had been written on “cybersecurity” and “cyberwar” (including by one of us) — raising the specter of hackers breaking into computers and implanting malicious lines of software code. When the next war came, we’d often been told, it would be a techno-nightmare marked by crashing networks, the disruption of financial markets, and electrical outages. It would show the “true” power of the internet in action. But the abrupt fall of Mosul showed that there was another side to computerized war. The Islamic State, which had no real cyberwar capabilities to speak of, had just run a military offensive like a viral marketing campaign and won a victory that shouldn’t have been possible. It hadn’t hacked the network; it had hacked the information on it.",
    "meta": {
      "theme": "ISIS's use of the internet as a weapon",
      "region": "Global",
      "use_case": "Information warfare and propaganda dissemination",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "information warfare",
        "social media",
        "propaganda",
        "viral marketing"
      ],
      "influence_map": [],
      "chunk_index": 6
    },
    "id": "likewar_006"
  },
  {
    "section": "Global Contagion and the New Battlefield",
    "text": "In the months that followed, ISIS’s improbable momentum continued. The group recruited over 30,000 foreigners from nearly a hundred countries to join the fight in its self-declared “caliphate.” The export of its message proved equally successful. Like a demonic McDonald’s, ISIS opened more than a dozen new franchises, everywhere from Libya and Afghanistan to Nigeria and Bangladesh. Where franchises were not possible, ISIS propaganda spurred “lone wolves” to strike, inspiring scores of terrorist attacks from Paris and Sydney to Orlando and San Bernardino. And that same contagion of fear spread wider than ever before. Polling showed Americans were suddenly more frightened of terrorism than they’d been in the immediate aftermath of 9/11. All thanks, essentially, to the fact that ISIS was very good at social media. ISIS was just the leading edge of a broader, globe-spanning phenomenon. The technology it was using — rather than any unique genius on the part of the jihadists — lay at the heart of its disruptive power and outsize success. And it was a technology available to everyone. Others could do the same thing. Indeed, they already were. In the Syrian civil war where ISIS first roared to prominence, nearly every rebel group used YouTube to recruit, fundraise, and train. In turn, the regime of Syrian president Bashar al-Assad used Instagram to project a friendly face to the world, while it gassed its own citizens. When Russian forces annexed Crimea and chomped away at eastern Ukraine, the Russians made their initial forays online, fomenting unrest. During the battles that followed, opposing soldiers trolled each other’s social media pages. So, too, the Israeli Defense Forces and Hamas militants fought multiple “Twitter wars” before a global audience. The IDF took this fight, and how it influenced world opinion, so seriously that the volume of “likes” and retweets influenced the targets it chose and its pace of operations on the ground. In Afghanistan, NATO and the Taliban had taken to sniping at each other’s Twitter feeds, mixing mockery with battle footage. Everywhere, armed groups and governments had begun generating information operations and war propaganda that lived alongside the internet’s infinite supply of silly memes and cat videos. It all represented a momentous development in the history of conflict. Just as the modern internet had “disrupted” the worlds of entertainment, business, and dating, it was now disrupting war and politics. It was a revolution that no leader, group, army, or nation could afford to ignore.",
    "meta": {
      "theme": "The global spread of online information warfare",
      "region": "Global",
      "use_case": "Various examples of state and non-state actors using social media in conflict",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "information warfare",
        "social media",
        "propaganda",
        "hybrid warfare"
      ],
      "influence_map": [],
      "chunk_index": 7
    },
    "id": "likewar_007"
  },
  {
    "section": "The Recapture of Mosul and the Evolving Battlefield",
    "text": "How much the novel had become normal was evidenced when a reconstituted Iraqi army swept back into Mosul in 2016, two years after #AllEyesOnISIS had chased it away. This time it came equipped for the new battlefield that extended far beyond Mosul’s battered streets. Eighteen-wheel trucks lumbered after tanks and armored personnel carriers, dragging portable cellphone towers to ensure bandwidth for its own messaging. The Iraqi military issued a rapid-fire stream of Facebook, YouTube, and Twitter updates both practical (the status of the operation) and bizarre (grinning selfies of Iraqi soldiers as they detonated leftover ISIS suicide-bomb trucks). Naturally, the operation had its own hashtag: #FreeMosul. The Iraqis’ U.S. military allies also threw themselves into this new fight. Just as U.S. forces coordinated air strikes and targeting data for the Iraqi army, they also sought to shape the flow of online conversation in Iraq and beyond. For months, U.S. special operators and information warfare officers had trained for the assault by practicing “cognitive maneuvering” against pretend ISIS propagandists. Now they pushed out message after message that reflected what they had learned. Meanwhile, hundreds of contractors in the employ of the U.S. State Department stalked the conversations of potential ISIS recruits, reminding them of ISIS’s barbarity and its impending defeat. Because the Islamic State was also online, the result could be surreal, almost circular moments. At one point, the Iraqi army proudly announced on Facebook that it had shot down a drone used by ISIS to film battles to put on Facebook. It also meant that combat could be followed live, now from both sides of the front lines. You could “like” whichever version you preferred, your clicks enlisted in the fight to determine whose version got more views. The physical and digital battlefields could drift eerily close together. The Kurdish news network Rudaw didn’t just dispatch camera crews to embed with soldiers on the front lines; it also livestreamed the whole thing, promising “instant access” to the carnage across Facebook, Twitter, and YouTube. When an ISIS car bomb hurtled toward the screen and exploded, friends, family, and tens of thousands of strangers watched together as a Rudaw reporter struggled to his feet before screaming the name of his cameraman into the billowing smoke. Because the livestream included emojis — smiling and frowning faces, hearts, and the universal “like” symbol — the scene unleashed a cascade of cartoon emotions. Most viewers were fearful for the crew’s safety, so their yellow emoji faces registered shock. When the cameraman’s friend emerged safely, the emojis changed to a wave of online smiles. Scattered among them, however, were a few frowning faces. These were the ISIS sympathizers and fighters who had wanted the journalists to die. The online crowd didn’t just watch and cheer; it even got involved in other, more positive ways. In a reversal of how ISIS had first exploited the technology in taking Mosul, a global network of online volunteers formed, dedicated to using social media to save lives there. They scanned online networks for any snippet of information about where civilians were caught in the crossfire, steering rescuers from the local hospital to their location. A hub for this effort was @MosulEye, run by an Iraqi man working behind ISIS lines as a new kind of online fifth column.",
    "meta": {
      "theme": "The recapture of Mosul and the integration of online and offline battlefields",
      "region": "Middle East (Iraq)",
      "use_case": "Military operations incorporating social media and information warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "information warfare",
        "social media",
        "propaganda",
        "hybrid warfare",
        "citizen journalism"
      ],
      "influence_map": [],
      "chunk_index": 8
    },
    "id": "likewar_008"
  },
  {
    "section": "Part 1: The Changing Nature of War",
    "text": "peace. He described this effort as “a huge change . . . To be able to reach out to those who were rescued and hear their voices, knowing that I helped rescue them and spare their lives is priceless.” Social media had changed not just the message, but the dynamics of conflict. How information was being accessed, manipulated, and spread had taken on new power. Who was involved in the fight, where they were located, and even how they achieved victory had been twisted and transformed. Indeed, if what was online could swing the course of a battle ​— ​or eliminate the need for battle entirely ​— ​what, exactly, could be considered “war” at all? The very same questions were being asked 6,000 miles from Mosul and, for most readers, quite a bit closer to home. THE INTERNET WORLD COLLIDER Like so many young men, Shaquon Thomas lived his life online. For “Young Pappy,” as Thomas was known, it was a life of crime, his online brand extolling murders and drug deals. Thomas had grown up with a loving family and a talent for music. At the age of 4, he started rapping, taught by his brother. But his future The War Begins 11 would be shaped by the intersection of old geography and new tech- nology. The family lived in a neighborhood in Chicago that was caught between three street gangs: the Conservative Vice Lords, the Gangster Disciples, and the Black P. Stones. Thomas was a Gangster Disciple and wanted everyone to know it. So he trumpeted the fact online, using it to build up that essential new cur- rency: his personal brand.",
    "meta": {
      "theme": "The impact of social media on conflict",
      "region": "Global, with specific examples from the Middle East (Mosul), United States (Chicago), Latin America, and Asia.",
      "use_case": "Illustrating how social media transforms conflict dynamics, from interpersonal gang violence to international relations.",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "conflict",
        "war",
        "information warfare",
        "gang violence",
        "international relations"
      ],
      "influence_map": [],
      "chunk_index": 9
    },
    "id": "likewar_009"
  },
  {
    "section": "Part 2: Social Media as a Catalyst for Violence",
    "text": "But there were real consequences of revealing your gang status online. On two separate occasions, he was shot at in broad daylight. Several bystanders were killed, including a young man who was waiting at the same bus stop to go to his first day of a new job. But each time, Thomas got away. Although Thomas had survived the attacks, his online Young Pappy persona had to respond. So he did the only logical thing after two near- death incidents: he dropped another video on YouTube. “You don’t even know how to shoot,” he taunted his would-be killers. It was a hit, receiv- ing over 2 million views. The 20-year-old was now a star, both in social media and gangland. They killed Thomas a week later and just one block away from where he had recorded the video. Four days after that, a high school sopho- more shot another rival gang member. The reason? He’d made dispar- aging posts about the deceased Young Pappy. Shaquon Thomas’s fate has befallen thousands of other young men across the United States. His hometown of Chicago has famously be- come the epicenter of a new kind of battle that we would call “war” in any other nation. Indeed, more people were killed by gang violence in 2017 in Chicago than in all U.S. special operations forces across a de- cade’s worth of fighting in Iraq and then Syria. At the center of the strife is social media. “Most of the gang disputes have nothing to do with drug sales, or gang territory, and everything to do with settling personal scores,” ex- plains Chicago alderman Joe Moore, who witnessed one of the shoot- ings of Young Pappy. “Insults that are hurled on the social media.” Much of this violence starts with gangs’ use of social media to “cyber- tag” and “cyberbang.” Tagging is an update of the old-school practice of spray-painting graffiti to mark territory or insult a rival. The “cyber” version is used to promote your gang or to start a flame war by includ- ing another gang’s name in a post or mentioning a street within a rival 12 LikeWar gang’s territory. These online skirmishes escalate quickly. Anyone who posts about a person or a street belonging to a rival gang is making an online show of disrespect. Such a post is viewed as an invitation to “post up,” or retaliate. Digital sociologists describe how social media creates a new reality “no longer limited to the perceptual horizon,” in which an online feud can seem just as real as a face-to-face argument. The difference in being online, however, is that now seemingly the whole world is witnessing whether you accept the challenge or not. This phenomenon plays out at every level, and not just in killings; 80 percent of the fights that break out in Chicago schools are now instigated online. In time, these online skirmishes move to the “bang,” sometimes called “Facebook drilling.” (There are regional variants of this term. In Los Angeles, for instance, they use the descriptor “wallbanging.”) This is when a threat is made via social media. It might be as direct as one gang member posting to a rival’s Facebook wall, “I’m going to catch you. I’m going to shoot you.” Or it might be symbolic, like posting photos of rival gang members turned upside down. As with the distant lone wolf attacks of ISIS, cybertagging vastly in- creases the reach of potential violence. In the past, gangs battled with their neighbors; the “turf war” literally was about the border of their neighborhoods. Now, as journalist Ben Austen explained in an exhaus- tive investigation of the lives of young Chicago gangbangers, “the quar- rel might be with not just the Facebook driller a few blocks away but also the haters ten miles north or west.” You can be anywhere in the city and never have met the shooter, but “what started as a provocation on- line winds up with someone getting drilled in real life.” The decentralized technology thus allows any individual to ignite this cycle of violence.",
    "meta": {
      "theme": "Social media's role in escalating violence and blurring the lines between online and offline conflict.",
      "region": "Primarily United States (Chicago), with references to other locations.",
      "use_case": "Examining how social media facilitates gang violence, cyberbullying, and the spread of threats.",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "gang violence",
        "cyberbullying",
        "online threats",
        "violence"
      ],
      "influence_map": [],
      "chunk_index": 10
    },
    "id": "likewar_010"
  },
  {
    "section": "Introduction",
    "text": "In 1831, Marie von Clausewitz edited her husband Carl's writings into the treatise *On War*.  Clausewitz’s theories of warfare have become essential reading for militaries worldwide, shaping war planning for the past two centuries. Concepts like the “fog of war” and “friction” originate from his work.  His most famous observation is that war is politics by other means, a continuation of political intercourse with the addition of other means. War and politics are intertwined; war doesn't suspend political interaction but continues it through different means. Clausewitz argued that war is part of a continuum including trade, diplomacy, and other interactions between peoples and governments. This contradicted older military theorists who saw war as a separate reality with different rules. For Clausewitz, war is a way to achieve a political goal, an act of force to compel an enemy. Winning requires neutralizing the adversary’s “center of gravity,” often their army.  However, Clausewitz also emphasized the importance of moral elements in war, the spirit that permeates conflict. Shattering a rival’s spirit might win the war without direct confrontation. Modern warfare has seen numerous unsuccessful attempts to target enemy morale, such as the Blitz and the Rolling Thunder bombing campaign. Propaganda, another attempt to influence morale, has also proven historically ineffective.  However, social media has changed the landscape. Attacking an adversary's spirit no longer requires large-scale operations; it can be done through smartphones.  It's now possible to directly communicate with those you're at war with, influencing or debating with them online.  Social media can be used to identify sympathizers who can be manipulated into committing violence or to spark conflicts through nationalist brigades. These scenarios are not hypothetical; they are happening now. From powerful nations to individuals, social media is weaponized, turning the internet into a battlefield where information itself is the weapon.  This book examines this shift, charting its history, identifying its rules, and understanding its effects.  Our research draws on the history of communication and propaganda, journalism, open-source intelligence, internet psychology, social network dynamics, and artificial intelligence. We tracked conflicts across the globe, from YouTube battle clips to online propaganda campaigns. We interviewed diverse experts, visited government agencies and social media companies, and participated in online battles to understand the dynamics of this new form of conflict. We even became targets of disinformation campaigns ourselves.",
    "meta": {
      "theme": "The changing nature of warfare in the digital age",
      "region": "Global",
      "use_case": "Understanding information warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "information warfare",
        "social media",
        "propaganda",
        "modern warfare"
      ],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": [
          "Understanding online conflicts",
          "Combating disinformation"
        ]
      },
      "chunk_index": 11
    },
    "id": "likewar_011"
  },
  {
    "section": "Core Principles",
    "text": "Our research identified five core principles of this new digital battlefield. First, the internet has matured into the primary medium for global communication, commerce, and politics.  It has empowered new leaders, groups, and a corporate order that continuously expands its reach. Social media has amplified this influence, creating a truly global and instantaneous network. Second, the internet has become a battlefield used by militaries, governments, activists, and spies to wage borderless wars.  Every battle feels personal, but every conflict is global. Third, this battlefield transforms how conflicts are fought.  Social media makes secrets difficult to keep, but virality can manipulate truth. Power is measured by the command of attention, resulting in a contest of psychological and algorithmic manipulation. Fourth, the meaning of \"war\" is changing.  Winning online battles influences the physical world, blurring the lines between the digital and physical realms. \"War\" and \"politics\" are merging online, with tactics and players becoming increasingly indistinguishable.  However, it's Silicon Valley engineers, not politicians or generals, who are defining the rules of this new type of conflict.  Fifth, everyone online is part of this war. Your attention is contested territory, fought over in conflicts you may not even be aware of.  Your online actions become ammunition in an unending series of skirmishes. Whether or not you're interested in these conflicts, they are interested in you.",
    "meta": {
      "theme": "The five core principles of internet warfare",
      "region": "Global",
      "use_case": "Framing the digital battlespace",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "information warfare",
        "social media",
        "digital battlefield",
        "virality"
      ],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": [
          "Understanding online conflicts",
          "Developing strategies for digital engagement"
        ]
      },
      "chunk_index": 12
    },
    "id": "likewar_012"
  },
  {
    "section": "Introduction",
    "text": "Manipulating the swirling tide of information to steer its direction and flow can accomplish incredible good. It can free people, expose crimes, save lives, and seed far-reaching reforms. But it can also accomplish astonishing evil. It can foment violence, stoke hate, sow falsehoods, incite wars, and even erode the pillars of democracy itself. Which side succeeds depends, in large part, on how much the rest of us learn to recognize this new warfare for what it is. Our goal is to explain exactly what’s going on and to prepare us all for what comes next.",
    "meta": {
      "theme": "Information Warfare",
      "region": "Global",
      "use_case": "Understanding and preparing for the impact of information manipulation",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [],
      "influence_map": [],
      "chunk_index": 13
    },
    "id": "likewar_013"
  },
  {
    "section": "The Internet's Impact",
    "text": "Roughly half the world’s population is now linked by the internet. It is the beating heart of international communication and commerce. It supports and spreads global news, information, innovation, and discovery of every kind and in every place. It has become woven into almost everything we do, at home, at work, and at war. In the United States, internet usage is near-universal, with one-fifth of Americans admitting they are essentially always online.  But using the internet isn’t the same as understanding it. The “internet” isn’t just apps and websites. It's a galaxy of billions of ideas spreading through vast social media platforms, each pulsing with its own rhythm.  At the same time, it is a globe-spanning community, vaster and more diverse than anything before it, yet governed by a handful of Silicon Valley oligarchs. As revolutionary as the internet may seem, its development has followed familiar patterns etched by the printing press, telegraph, television, and other communications mediums. To understand the internet—the most consequential battlefield of the twenty-first century—one must understand how it works, why it was made, and whom it has empowered.",
    "meta": {
      "theme": "The Internet as a Battlefield",
      "region": "Global",
      "use_case": "Explaining the nature and development of the internet",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [],
      "influence_map": [],
      "chunk_index": 14
    },
    "id": "likewar_014"
  },
  {
    "section": "Early Visions and ARPANET",
    "text": "In 1968, J.C.R. Licklider and Robert W. Taylor predicted a future where computers captured and shared information, envisioning a vast constellation of interconnected computers called the Intergalactic Computer Network. They prophesied its effects: new jobs, interactive communities, and a new sense of place.  They foresaw the 'bit' as the fundamental unit of information and 'packet switching' as the method for transmitting information instantly across vast distances.  While not everyone recognized the potential, Licklider and Taylor, working for ARPA, saw the military application: a communication system resistant to decapitation by a nuclear strike.  The practical appeal for scientists was sharing costly computer time.  This led to ARPANET. On October 29, 1969, ARPANET connected a computer at UCLA to one at Stanford. The first message, intended to be 'LOGIN,' was truncated to 'LO' due to a system crash. This miscommunication marked the beginning of internet history.",
    "meta": {
      "theme": "Origins of the Internet",
      "region": "United States",
      "use_case": "Historical account of the development of ARPANET",
      "strategic_category": [
        "military_doctrine"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [],
      "influence_map": [],
      "chunk_index": 15
    },
    "id": "likewar_015"
  },
  {
    "section": "The Race to Communicate",
    "text": "The development of ARPANET was the culmination of a 5,000-year race to communicate. From writing on clay tablets in ancient Mesopotamia to the printing press, information had been a scarce commodity. Gutenberg's printing press revolutionized information dissemination, leading to the mass production of books. This technology transformed war, politics, and the world, as seen with the Protestant Reformation sparked by Martin Luther's printed pamphlets. The printing press also gave rise to newspapers, creating a market for information itself. However, the speed of communication remained limited by transportation.  The telegraph, invented in 1844, finally broke the tyranny of distance by harnessing electricity. ",
    "meta": {
      "theme": "History of Communication Technology",
      "region": "Global",
      "use_case": "Contextualizing the internet within the broader history of communication",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [],
      "influence_map": [],
      "chunk_index": 16
    },
    "id": "likewar_016"
  },
  {
    "section": "Every Wire a Nerve",
    "text": "in any communication technology now able to extend across political boundaries. Morse spent years lobbying the U.S. Congress for the $30,000 needed to lay the thirty-eight miles of wire between Washington, DC, and Baltimore for his first public test. Critics suggested the money might be better spent testing hypnotism as a means of long-distance communication. Fortunately, the telegraph won — by just six votes. This was the start of a telecommunications revolution. By 1850, there were 12,000 miles of telegraph wire and some 20 telegraph companies in the United States alone. By 1880, there would be 650,000 miles of wire worldwide — 30,000 miles under the ocean — that stretched from San Francisco to Bombay. This was the world that Morse’s brother had prophesied in a letter written while the telegraph was still under development: “The surface of the earth will be networked with wire, and every wire will be a nerve. The earth will become a huge animal with ten million hands, and in every hand a pen to record whatever the directing soul may dictate!” Morse would be applauded as “the peacemaker of the age,” the inventor of “the greatest instrument of power over earth which the ages of human history have revealed.” As observers pondered the prospect of a more interconnected world, they assumed it would be a gentler one. President James Buchanan captured the feeling best when marking the laying of the first transatlantic cable between the United States and Britain, in 1858. He expressed the belief that the telegraph would “prove to be a bond of perpetual peace and friendship between the kindred nations, and an instrument designed . . . to diffuse religion, liberty, and law throughout the world.” Within days, that transatlantic cable of perpetual peace was instead being used to send military orders. Like the printing press before it, the telegraph quickly became an important new tool of conflict, which would also transform it. Beginning in the Crimean War (1853–1856), broad instructions, traveling weeks by sea, were replaced — to the lament of officers in the field — by micromanaging battle orders sent by cable from the tearooms of London to the battlefields of Russia.",
    "meta": {
      "theme": "Impact of the Telegraph",
      "region": "Global",
      "use_case": "Communication, Military, Politics",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "communication",
        "warfare",
        "politics"
      ],
      "influence_map": [],
      "chunk_index": 17
    },
    "id": "likewar_017"
  },
  {
    "section": "Every Wire a Nerve",
    "text": "Some militaries proved more effective in exploiting the new technology than others. In the Wars of German Unification (1864–1871), Prussian generals masterfully coordinated far-flung forces to the bafflement of their foes, using real-time communications by telegraph wire to replace horseback couriers. As a result, the telegraph also spurred huge growth in war’s reach and scale. In the American Civil War (1861–1865), Confederate and Union soldiers, each seeking an edge over the other, laid some 15,000 miles of telegraph wire. The telegraph also reshaped the public experience and perception of conflict. One journalist marveled, “It gives you the news before the circumstances have had time to alter . . . A battle is fought three thousand miles away, and we have the particulars while they are taking the wounded to the hospital.” This intimacy could be manipulated, however. A new generation of newspaper tycoons arose, who turned sensationalism into an art form, led by Harvard dropout turned newspaper baron William Randolph Hearst. His “yellow journalism” (named for the tint of the comics in two competing New York dailies, Hearst’s New York Journal and Joseph Pulitzer’s New York World) was the kind of wild rumormongering American readers couldn’t get enough of — and that helped spark the Spanish-American War of 1898. When one of his photographers begged to return home from Spanish-controlled Cuba because nothing was happening, Hearst cabled back: “Please remain. You furnish the pictures and I’ll furnish the war.” Concern over the issue of telegraphed “fake news” grew so great that the St. Paul Globe even changed its motto that year: “Live News, Latest News, Reliable News — No Fake War News.”",
    "meta": {
      "theme": "Telegraph's Influence on Warfare and Public Perception",
      "region": "Global",
      "use_case": "Military, Media, Propaganda",
      "strategic_category": [
        "military_doctrine"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "warfare",
        "media",
        "propaganda",
        "misinformation"
      ],
      "influence_map": [],
      "chunk_index": 18
    },
    "id": "likewar_018"
  },
  {
    "section": "Every Wire a Nerve",
    "text": "The electric wire of the telegraph, though, could only speak in dots and dashes. To use them required not just the infrastructure of a telegraph office, but a trained expert to operate the machine and translate its coded messages for you. Alexander Graham Bell, an amateur tinkerer whose day job was teaching the deaf, changed this with the telephone in 1876. Sending sound by wire meant users could communicate with each other, even in their offices and homes. Within a year of its invention, the first phone was put in the White House. The number to call President Rutherford B. Hayes was “1,” as the only other phone line linked to it was at the Treasury Department. The telephone also empowered a new class of oligarchs. Bell’s invention was patented and soon monopolized by Bell Telephone, later renamed the American Telephone and Telegraph Company (AT&T). Nearly all phone conversations in the United States would be routed through this one company for the next century. Telegraphs and phones had a crucial flaw, though. They shrank the time and simplified the means by which a message could travel a great distance, but they did so only between two points, linked by wire. Guglielmo Marconi, a 20-year-old Irish-Italian tinkering in a secret lab in his parents’ attic, would be the first to build a working “wireless telegraphy” system, in 1894. Marconi’s radio made him a conflicted man. He claimed that radio would be “a herald of peace and civilization between nations.” At the same time, he aggressively peddled it to every military he could. He sold it to the British navy in 1901 and convinced the Belgian government to use it in the brutal colonization of the Congo. In the 1904–1905 Russo-Japanese War, both sides used Marconi radios.",
    "meta": {
      "theme": "Telephone and Early Radio",
      "region": "Global",
      "use_case": "Communication, Military, Colonization",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "communication",
        "warfare",
        "colonization"
      ],
      "influence_map": [],
      "chunk_index": 19
    },
    "id": "likewar_019"
  },
  {
    "section": "Every Wire a Nerve",
    "text": "Radio’s promise, however, went well beyond connecting two points across land or sea. By eliminating the need for wire, radio freed communications in a manner akin to the printing press. One person could speak to thousands or even millions of people at once. Unlike the telegraph, which conveyed just dots and dashes, radio waves could carry the human voice and the entire musical spectrum, turning them into the conveyor of not only mass information but also mass entertainment. The first radio “broadcast” took place in 1906, when an American engineer played “O Holy Night” on his violin. By 1924, there were an estimated 3 million radio sets and 20 million radio listeners in the United States alone. Quite quickly, radio waves collided with politics. Smart politicians began to realize that radio had shattered the old political norms. Speeches over the waves became a new kind of performance art crossed with politics. The average length of a political campaign speech in the United States fell from an hour to just ten minutes. And there was no better performer than Franklin Delano Roosevelt, elected president in 1932. He used his weekly Fireside Chats to reach directly into the homes of millions of citizens. (After the December 7, 1941, Pearl Harbor attack, four-fifths of American households listened to his speech live.) In so doing, he successfully went over the heads of the political bosses and newspaper editors who fought to deny him a third and fourth term. So powerful were FDR’s speeches that on the night of an important speech intended to rally listeners against Germany, the Nazis launched a heavy bombing raid against London to try to divert the news. But radio also unleashed new political horrors. “It would not have been possible for us to take power or to use it in the ways we have without the radio,” said Joseph Goebbels, who himself was something new to government, the minister of propaganda for Nazi Germany. Goebbels employed nearly a thousand propagandists to push Adolf Hitler’s brutal, incendiary, enrapturing speeches. Aiding the effort was a giveaway with a catch: German citizens were gifted special radios marked with swastikas, which could only receive Nazi-broadcasted frequencies.",
    "meta": {
      "theme": "Radio's Impact on Politics and Propaganda",
      "region": "Global, United States, Germany",
      "use_case": "Politics, Propaganda, Warfare",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "politics",
        "propaganda",
        "warfare",
        "media"
      ],
      "influence_map": [],
      "chunk_index": 20
    },
    "id": "likewar_020"
  },
  {
    "section": "Every Wire a Nerve",
    "text": "Just like the telegraph, radio would be used to foment war and become a new tool for fighting it. On the eve of the 1939 German invasion of Poland, Hitler told his generals, “I will provide a propagandistic casus belli. Its credibility doesn’t matter. The victor will not be asked whether he told the truth.” The following six years of World War II saw not just tanks, planes, and warships linking up by radio, but both sides battling back and forth over the airwaves to reshape what the opposing population knew and thought. As Robert D. Leigh, director of the Foreign Broadcast Intelligence Service, testified before Congress in 1944: Around the world at this hour and every hour of the 24, there is a constant battle on the ether waves for the possession of man’s thoughts, emotions, and attitudes — influencing his will to fight, to stop fighting, to work hard, to stop working, to resist and sabotage, to doubt, to grumble, to stand fast in faith and loyalty . . . We estimate that by short wave alone, you as a citizen of this radio world are being assailed by 2,000 words per minute in 40–45 different languages and dialects. Yet the reach and power of radio was soon surpassed by a technology that brought compelling imagery into broadcasts. The first working television in 1925 showed the face of a ventriloquist’s dummy named Stooky Bill. From these humble beginnings, television soon rewired what people knew, what they thought, and even how they voted. By 1960, television sets were in nine of ten American homes, showing everything from The Howdy Doody Show to that infamous presidential debate between Richard M. Nixon and John F. Kennedy, won by the more “telegenic” candidate. In the United States, television forged a new sense of cultural identity. With a limited number of broadcasts to choose from, millions of families watched the same events and news anchors; they saw the same shows and gossiped eagerly about them the next day.",
    "meta": {
      "theme": "Radio in WWII and the Rise of Television",
      "region": "Global, United States",
      "use_case": "Warfare, Propaganda, Media, Politics",
      "strategic_category": [
        "military_doctrine"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos"
      ],
      "usage_tags": [
        "warfare",
        "propaganda",
        "media",
        "politics"
      ],
      "influence_map": [],
      "chunk_index": 21
    },
    "id": "likewar_021"
  },
  {
    "section": "The Birth of the Internet",
    "text": "They were each setting their own rules about everything from how to maintain the network to how to communicate within it. Unless a common protocol could be established to govern a “network of networks” (or “internet”), the spread of information would be held back. This is when Vint Cerf entered the scene. While figures like J.C.R. Licklider and Robert W. Taylor had conceived ARPANET, Cerf is rightfully known as the “father of the internet.” As a teenager, he learned to code computer software by writing programs to test rocket engines. As a young researcher, he was part of the UCLA-Stanford team that connected the Pentagon’s new network. Recognizing the problem of compatibility would keep computerized communication from ever scaling, Cerf set out to find a solution. Working with his friend Robert Kahn, he designed the TCP/IP (transmission-control protocol/internet protocol), an adaptable framework that could track and regulate the transmission of data across an exponentially expanding network. Essentially, it is what allowed the original ARPANET to bind together all the mini-networks at universities around the world. It remains the backbone of the internet to this day.\nOver the following years, Cerf moved to work at ARPA and helped set many of the rules and procedures for how the network would evolve. He was aware of the futuristic visions that his predecessors had laid out. But it was hard to connect that vision to what was still just a way for scientists to share computing time. Considerations of the internet’s social or political impact seemed the stuff of fantasy. This changed one day in 1979 when Cerf logged on to his workstation to find an unopened message from the recently developed “electronic mail” system. Because more than one person was using each computer, the scientists had conceived of “e-mail” (now commonly styled “email”) as a way to share information, not just between computers but also from one person to another. But, just as with regular mail, they needed a system of “addresses” to send and receive the messages. The “@” symbol was chosen as a convenient “hack” to save typing time and scarce computer memory. The message on Cerf’s screen wasn’t a technical request, however. The email subject was “SF-lovers.” And it hadn’t been sent just to him. Instead, Cerf and his colleagues scattered across the United States were all asked to respond with a list of their favorite science fiction authors. Because the message had gone out to the entire network, everybody’s answers could then be seen and responded to by everybody else. Or users could send their replies to just one person or subgroup, generating scores of smaller discussions that eventually fed back into the whole. Over forty years later, Cerf still recalls the moment he realized the internet would be something more than every other communications technology before it. “It was clear we had a social medium on our hands,” he said. The thread was a hit. After SF-lovers came Yumyum, a mailing list to debate the quality of restaurants in Silicon Valley. Soon the network was also used to share not just opinions but news about both science and science fiction, such as plans for a movie revival of the 1960s TV show Star Trek.",
    "meta": {
      "theme": "Technological Development",
      "region": "United States",
      "use_case": "Communication, Information Sharing",
      "strategic_category": [
        "military_doctrine"
      ],
      "economic_category": [
        "development_models"
      ],
      "civilizational_category": [
        "cultural_ethos"
      ],
      "usage_tags": "ARPANET, TCP/IP, Email, Internet Protocol",
      "influence_map": {
        "influenced_works": "Modern Internet",
        "modern_applications": "Global Communication"
      },
      "chunk_index": 22
    },
    "id": "likewar_022"
  },
  {
    "section": "The Military and the Internet",
    "text": "The U.S. military budgeters wanted to ban all this idle chatter from their expensive new network. However, they relented when engineers convinced them that the message traffic was actually a good stress test for ARPANET’s machinery. Chain letters and freewheeling discussions soon proliferated across the network. ARPANET’s original function had been remote computer use and file transfer, but soon email was devouring two-thirds of the available bandwidth. No longer was the internet simply improving the transfer of files from one database to another. Now it was creating those “interactive communities” that Licklider and Taylor had once envisioned, transforming what entire groups of people thought and knew. Soon enough, it would even change how they spoke to each other. Perhaps no one — engineers included — understood by how much. At precisely 11:44 a.m. EST on September 19, 1982, computer scientist Scott Fahlman changed history forever. In the midst of an argument over a joke made on email, he wrote: I propose that [sic] the following character sequence for joke markers: :-) Read it sideways. Actually, it is probably more economical to mark things that are NOT jokes, given current trends. For this, use :-( And so the humble emoticon was born. But it illustrated something more. For all its promise, ARPANET was not the internet as we know it. It was a kingdom ruled by the U.S. government. And, as shown by the formal creation of the emoticon in the midst of an argument among nerds, its population was mostly PhDs in a handful of technical fields. Even the early social platforms these computer scientists produced were just digital re-creations of old and familiar things: the postal service, bulletin boards, and newspapers. The internet remained in its infancy. But it was growing fast. By 1980, there were 70 institutions and nearly 5,000 users hooked up to ARPANET. The U.S. military came to believe that the computer network its budget was paying for had expanded too far beyond its needs or interests. After an unsuccessful attempt to sell ARPANET to a commercial buyer (for the second time, AT&T said “no thanks”), the government split the internet in two. ARPANET would continue as a chaotic and fast-growing research experiment, while the military would use the new, secure MILNET. For a time, the worlds of war and the internet went their separate ways. This arrangement also paved the way for the internet to become a civilian — and eventually a commercial — enterprise. The National Science Foundation took over from the Pentagon and moved to create a more efficient version of ARPANET. Called NSFNET, it proved faster by an order of magnitude and brought in new consortiums of users. The 28,000 internet users in 1987 grew to nearly 160,000 by 1989. The next year, the now outdated ARPANET was quietly retired. Vint Cerf was there to deliver the eulogy.",
    "meta": {
      "theme": "Military Adoption and Divestment",
      "region": "United States",
      "use_case": "Research, Communication",
      "strategic_category": [
        "military_doctrine",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": "ARPANET, MILNET, NSFNET, Emoticon, Internet Growth",
      "influence_map": {
        "influenced_works": "Civilian Internet",
        "modern_applications": "Internet Infrastructure"
      },
      "chunk_index": 23
    },
    "id": "likewar_023"
  },
  {
    "section": "The World Wide Web and Commercialization",
    "text": "While the internet and the military were ostensibly dividing, other worlds were on the brink of colliding. Back in 1980, the British physicist Tim Berners-Lee had developed a prototype of something called “hypertext.” This was a long-theorized system of “hyperlinks” that could bind digital information together in unprecedented ways. Called ENQUIRE, the system was a massive database where items were indexed based on their relationships to each other. It resembled a very early version of Wikipedia. There was a crucial difference, however. ENQUIRE wasn’t actually part of the internet. The computers running this revolutionary indexing program couldn’t yet talk to each other. Berners-Lee kept at it. In 1990, he began designing a new index that could run across a network of computers. In the process, he and his team invented much of the digital shorthand still in use today. They wrote a new code to bind the databases together. Hypertext markup language (HTML) defined the structure of each item, could display images and video, and, most important, allowed anything to link to anything else. Hypertext transfer protocol (HTTP) determined how hypertext was sent between internet nodes. To give it an easy-to-find location, every item was then assigned a unique URI (uniform resource identifier), more commonly known as a URL (uniform resource locator). Berners-Lee dubbed his creation the World Wide Web.\nJust as ARPANET had shaped the systems that made online communication possible and Cerf and Kahn’s protocol had allowed the creation of a network of networks that spanned the globe, the World Wide Web — the layer on top that we now call the “internet” — shaped what this communication looked like. Forward-thinking entrepreneurs quickly set to building the first internet “browsers,” software that translated the World Wide Web into a series of visual “pages.” This helped make the internet usable for the masses; it could now be navigated by anyone with a mouse and a keyboard. During this same period, the U.S. government continued investment in academic research and infrastructure development, with the goal of creating an “information superhighway.” The most prominent sponsor of these initiatives was Senator Al Gore, leading to the infamous claim that he “invented” the internet. More accurately, he valuably sped up its development. The advent of the World Wide Web matched up perfectly with another key development that mirrored technology past: the introduction of profit-seeking. In 1993, early internet architects gathered to take their biggest step yet: privatizing the entire system and tying independent internet operators — of which there were thousands — into a single, giant network. At the same time, they also took steps to establish a common system of internet governance, premised on the idea that no one nation should control it. In 1995, NSFNET formally closed, and a longstanding ban on online commercial activity was lifted. The internet took off like a rocket. In 1990, there were 3 million computers connected to the internet. Five years later, there were 16 million. That number reached 360 million by the turn of the millennium. As with the technologies of previous eras, the internet’s commercialization and rapid growth paved the way for a gold rush. Huge amounts of money were to be made, not just in owning the infrastructure of the network but also in all the new business that sprang from it. Among the earliest to profit were the creators of Netscape Navigator, the easy-to-use browser of choice for three-quarters of all internet users. When Netscape went public in 1995, the company was worth $3 billion by the end of its first day, despite having never turned a profit. At that moment, the internet ceased to be the plaything of academics.",
    "meta": {
      "theme": "The Rise of the Web and Commercialization",
      "region": "Global",
      "use_case": "Information Access, Commerce",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [
        "development_models"
      ],
      "civilizational_category": [],
      "usage_tags": "World Wide Web, HTML, HTTP, Browsers, Commercialization, Netscape",
      "influence_map": {
        "influenced_works": "E-commerce, Online Businesses",
        "modern_applications": "Global Information Network"
      },
      "chunk_index": 24
    },
    "id": "likewar_024"
  },
  {
    "section": "The Zapatistas and the Power of the Network",
    "text": "Amid the flurry of new connections and ventures, the parallel world of the internet began to grow so fast that it became too vast for any one person to explore, much less understand. It was fortunate, then, that nobody needed to understand it. The explorers who would catalog the internet’s most distant reaches would not be people but “bots,” special programs built to “crawl” and index the web’s endless expanse. The first bots were constructed by researchers as fun lab experiments. But as millions of users piled online, web search became the next big business. The most successful venture was born in 1996, created by two Stanford graduate students, Larry Page and Sergey Brin. Their company’s name was taken from a mathematical term for the number 1 followed by 100 zeros. “Google” symbolized their idea to “organize a seemingly infinite amount of information on the web.”\nAs the web continued its blistering growth, it began to attract a radically different user base, one far removed from the university labs and tech enclaves of Silicon Valley. For these new digital arrivals, the internet wasn’t simply a curiosity or even a business opportunity. It was the difference between life and death. In early 1994, a ragtag force of 4,000 disenfranchised workers and farmers rose up in Mexico’s poor southern state of Chiapas. They called themselves the Zapatista National Liberation Army (EZLN). The revolutionaries occupied a few towns and vowed to march on Mexico City. The government wasn’t impressed. Twelve thousand soldiers were deployed, backed by tanks and air strikes, in a swift and merciless offensive. The EZLN quickly retreated to the jungle. The rebellion teetered on the brink of destruction. But then, twelve days after it began — as the Mexican military stood ready to crush the remnant — the government declared a sudden halt to combat. For students of war, this was a head-scratcher. But upon closer inspection, there was nothing conventional about this conflict. More than just fighting, members of the EZLN had been talking online. They shared their manifesto with like-minded leftists in other countries, declared solidarity with international labor movements protesting free trade (their revolution had begun the day the North American Free Trade Agreement, or NAFTA, went into effect), established contact with international organizations like the Red Cross, and urged every journalist they could find to come and observe the cruelty of the Mexican military firsthand. Cut off from many traditional means of communication, they turned en masse to the new and largely untested power of the internet.",
    "meta": {
      "theme": "The Internet as a Tool for Social Change",
      "region": "Global, Mexico",
      "use_case": "Activism, Political Mobilization",
      "strategic_category": [
        "diplomatic_posture"
      ],
      "economic_category": [
        "trade_tariff_systems"
      ],
      "civilizational_category": [],
      "usage_tags": "Zapatistas, EZLN, Internet Activism, NAFTA, Political Organizing",
      "influence_map": {
        "influenced_works": "Modern Protest Movements",
        "modern_applications": "Social Media Activism"
      },
      "chunk_index": 25
    },
    "id": "likewar_025"
  },
  {
    "section": "Part 1: The Dawn of the Internet and Social Media",
    "text": "“The war on the internet.” Everywhere, there were signs that the internet’s relentless pace of innovation was changing the social and political fabric of the real world. There was the invention of the webcam and the launch of eBay and Amazon; the birth of online dating; even the first internet-abetted scandals and crimes, one of which resulted in a presidential impeachment, stemming from a rumor first reported online. In 1996, Manuel Castells, among the world’s foremost sociologists, made a bold prediction: “The internet’s integration of print, radio, and audiovisual modalities into a single system promises an impact on society comparable to that of the alphabet.”\nYet the most forward-thinking of these internet visionaries wasn’t an academic at all. In 1999, musician David Bowie sat for an interview with the BBC. Rather than promote his albums, Bowie waxed philosophical about technology’s future. The internet wouldn’t just bring people together, he explained; it would also tear them apart. “Up until at least the mid-1970s, we really felt that we were still living under the guise of a single, absolute, created society — where there were known truths and known lies and there was no kind of duplicity or pluralism about the things that we believed in,” the artist once known as Ziggy Stardust said. “[Then] the singularity disappeared. And that I believe has produced such a medium as the internet, which absolutely establishes and shows us that we are living in total fragmentation.” The interviewer was mystified by Bowie’s surety about the internet’s powers. “You’ve got to think that some of the claims being made for it are hugely exaggerated,” he countered. Bowie shook his head. “No, you see, I don’t agree. I don’t think we’ve even seen the tip of the iceberg. I think the potential of what the internet is going to do to society, both good and bad, is unimaginable. I think we’re actually on the cusp of something exhilarating and terrifying . . . It’s going to crush our ideas of what mediums are all about.”\n“The goal wasn’t to create an online community, but a mirror of what existed in real life.” It’s a grainy 2005 video of a college-age kid sitting on a sofa in a den, red plastic cup in hand. He’s trying to describe what his new invention is and — more important — what it isn’t. It isn’t going to be just a place to hang out online, a young Mark Zuckerberg explains. It’s going to be a lot more than that.",
    "meta": {
      "theme": "The rise of the internet and social media",
      "region": "Global",
      "use_case": "Social interaction, information dissemination",
      "strategic_category": [],
      "economic_category": [
        "development_models"
      ],
      "civilizational_category": [
        "cultural_ethos",
        "temporal_orientation"
      ],
      "usage_tags": [
        "internet",
        "social media",
        "innovation",
        "social change",
        "early adopters"
      ],
      "influence_map": [],
      "chunk_index": 26
    },
    "id": "likewar_026"
  },
  {
    "section": "Part 2: The Birth of Facebook",
    "text": "Zuckerberg was part of the first generation to be born into a world where the internet was available to the masses. By the age of 12, he had built ZuckNet, a chat service that networked his dad’s dental practice with the family computer. Before he finished high school, he took a graduate-level course in computer science. And then one night in 2003, as a 19-year-old sophomore at Harvard, Zuckerberg began a new, ambitious project. But he did so with no ambition to change the world.\nAt the time, each Harvard house had “facebooks” containing student pictures. The students used them as a guide to their new classmates, as well as fodder for dorm room debates about who was hot or not. Originally printed as booklets, the facebooks had recently been posted on the internet. Zuckerberg had discovered that the online version could be easily hacked and the student portraits downloaded. So over a frenzied week of coding, he wrote a program that allowed users to rate which of two randomly selected student portraits was more attractive. He called his masterpiece “Facemash.” Visitors to the website were greeted with a bold, crude proclamation: “Were we let in on our looks? No. Will we be judged on them? Yes.” Facemash appeared online on a Sunday evening. It spread like wildfire, with some 22,000 votes being cast in the first few hours. Student outrage spread just as quickly. As angry emails clogged his inbox, Zuckerberg was compelled to issue a flurry of apologies. Hauled before a university disciplinary committee, he was slapped with a stern warning for his poor taste and violation of privacy. Zuckerberg was embarrassed — but also newly famous. Soon after, Zuckerberg was recruited to build a college dating site. He secretly channeled much of his energy in a different direction, designing a platform that would combine elements of the planned dating site with the lessons he’d learned from Facemash. On January 11, 2004, he formally registered TheFacebook.com as a new domain. Within a month, 20,000 students at elite universities around the country signed up, with tens of thousands more clamoring for Facebook to be made available at their schools. For those fortunate enough to have it, the elegant mix of personal profiles, public postings, instant messaging, and common-friend groups made the experience feel both intimate and wholly unique. Early users also experienced a new kind of feeling: addiction to Facebook. “I’ve been paralyzed in front of the computer ever since signing up,” one college freshman confessed to his student newspaper. That summer, Zuckerberg filed for a leave of absence from Harvard and boarded a plane to Silicon Valley. He would be a millionaire before he set foot on campus again and a billionaire soon thereafter.",
    "meta": {
      "theme": "The creation and early growth of Facebook",
      "region": "United States",
      "use_case": "Social networking, online community",
      "strategic_category": [],
      "economic_category": [
        "development_models"
      ],
      "civilizational_category": [
        "cultural_ethos"
      ],
      "usage_tags": [
        "facebook",
        "zuckerberg",
        "harvard",
        "social network",
        "online community",
        "growth"
      ],
      "influence_map": [],
      "chunk_index": 27
    },
    "id": "likewar_027"
  },
  {
    "section": "Part 1: The Mobile Revolution",
    "text": "the internet ​— ​ could swallow the world. THE WORLD WIDE WEB GOES MOBILE On January 9, 2007, Apple cofounder and CEO Steve Jobs introduced the iPhone. Although nobody knew it at the time, the introduction of the iPhone also marked a moment of destruction. Family dinners, vacations, awkward elevator conversations, and even basic notions of privacy ​— ​all would soon be endangered. The iPhone wasn’t the first mobile phone or internet-capable smartphone.  By comparison, the iPhone was sexy. Internet access was central to the iPhone’s identity.  The packed auditorium at the 2007 Macworld Expo whooped with excitement as Jobs ran through the features: a touchscreen; handheld integration of movies, television, and music; a high-quality camera; and major advances in call reception and voicemail. The iPhone’s most radical innovation was a speedy, next-generation browser that could shrink and reshuffle websites, making the entire internet mobile-friendly. A year later, Apple officially unveiled its App Store. This marked another epochal shift.  Suddenly, the floodgates were thrown open to any possibility, as long as they were channeled through a central marketplace. Developers eagerly launched their own internet-enabled games and utilities. With the launch of Google’s Android operating system and competing Google Play Store that same year, smartphones ceased to be the niche of tech enthusiasts, and the underlying business of the internet soon changed.  By 2020, the number of mobile broadband subscriptions is expected to reach 8 billion. In the United States, smartphones have long since replaced televisions as the most commonly used piece of technology. The smartphone combined with social media cleared the last major hurdle. Previously, users faced a choice: be in real life but away from the internet, or tend to their digital lives in isolation. Now, it became possible for people to maintain both identities simultaneously. Any thought spoken aloud could be just as easily shared in a quick post.  One of the earliest beneficiaries of the smartphone was Twitter.  This reflected the new sense that it was the network, rather than the content on it, that mattered. As smartphone use grew, so did Twitter.  Better web technology then offered users the chance to embed hyperlinks, images, and video. Soon enough, Twitter was transforming the news ​— ​not just how it was experienced, but how it was reported. Journalists used social media to record notes and trade information. Twitter became a place where people decided what merited news coverage. Twitter also offered a means for those being reported on to bypass journalists. Politicians and celebrities turned to it to get their own messages out. Blistering advancements in smartphone camera quality and mobile bandwidth also began to change what a social network could look like. Instagram launched in 2010, a next-generation photo-sharing service.  By 2017, Instagram was adding more than 60 million photographs a day. It was bought by Facebook, just as YouTube had been scooped up by Google. Before almost anyone realized it, mobile tech, app stores, and corporate consolidation had effected another massive change in the internet ​— ​who controlled it. After decades of freewheeling growth, companies that had been startups just a few years earlier had rapidly risen to rule vast digital empires. Even more important, this handful of companies provided the pillars on which almost all the millions of other online services depended.",
    "meta": {
      "theme": "The Rise of Mobile Internet and Social Media",
      "region": "Global",
      "use_case": "Communication, Information Dissemination, Social Interaction",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [
        "development_models"
      ],
      "civilizational_category": [
        "cultural_ethos",
        "temporal_orientation"
      ],
      "usage_tags": [
        "smartphone",
        "social media",
        "mobile internet",
        "technological disruption"
      ],
      "influence_map": [],
      "chunk_index": 28
    },
    "id": "likewar_028"
  },
  {
    "section": "Part 2: Consolidation and Control",
    "text": "Would-be rivals have been bought up. Even if smaller companies retain their independence, these titans now control the primary gateways through which hundreds of millions of people access the web.  In countries like Thailand and the Philippines, Facebook literally is the internet. For all the internet’s creative chaos, it has come to be ruled by a handful of digital kings. The outcome is an internet that is simultaneously familiar but unrecognizable to its founders, with deep ramifications for the future of politics and war.  As Tim Berners-Lee has written, the web has been compressed under the powerful weight of a few dominant platforms. This concentration of power creates a new set of gatekeepers.  It’s an echo of how earlier tech revolutions created new classes of tycoons. But it differs in the sheer breadth of the current companies’ control.  There is one more difference between this and earlier tech revolutions: not all of these new kings live in the West. WeChat, a social media model, arose in 2011. Engineered to meet the requirements of the Chinese internet, WeChat may be a model for the wider internet’s future.  Known as a “super app,” it is a combination of social media and marketplace, sustaining and steering a network of nearly a billion users. On WeChat, one can find and review businesses; order food and clothing; receive payments; hail a car; post a video; and talk to friends, family, and everyone else. It is an app so essential to modern living that Chinese citizens can’t do without it.",
    "meta": {
      "theme": "Centralization of Power in the Digital Realm",
      "region": "Global",
      "use_case": "Economic Power, Political Influence, Information Control",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [
        "economic_warfare",
        "resource_strategies"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "monopoly",
        "digital divide",
        "internet governance",
        "censorship"
      ],
      "influence_map": [],
      "chunk_index": 29
    },
    "id": "likewar_029"
  },
  {
    "section": "Part 3: Global Reach and Ubiquity",
    "text": "CHILDHOOD’S END Put simply, the internet has left adolescence. In the span of a generation, it has blossomed into a network that encompasses half the world’s population.  The typical internet user is no longer a white, male, American computer scientist. More than half of all users are now in Asia, with another 15 percent in Africa. Half of the world’s population is online, and the other half is quickly following.  This is happening for the most part in the developing world, where internet growth has overtaken the expansion of basic infrastructure.  As a result, the internet is also now inescapable.  All these people, in all these places, navigate an online world that has grown unfathomably vast. While the number of websites passed 1 billion sometime in 2014, millions more lurk in the “deep web.” If one counts all the pieces of content with a unique web address, the number of internet nodes rises into the high trillions. In some ways, the internet has gone the way of all communications mediums past.  But in other obvious ways, the internet is nothing like its precursors. A single online message can traverse the globe at the speed of light.  This is what the internet has become. It is the most consequential communications development since the advent of the written word. Yet, like its precursors, it is inextricably tied to the age-old human experiences of politics and war. It has also become a colossal information battlefield, one that has obliterated centuries’ worth of conventional wisdom about what is secret and what is known.",
    "meta": {
      "theme": "The Internet's Global Expansion and Impact",
      "region": "Global",
      "use_case": "Information Warfare, Global Communication, Cultural Exchange",
      "strategic_category": [
        "military_doctrine"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos"
      ],
      "usage_tags": [
        "globalization",
        "digital age",
        "information overload",
        "internet penetration"
      ],
      "influence_map": [],
      "chunk_index": 30
    },
    "id": "likewar_030"
  },
  {
    "section": "Part 1: The Accidental Liveblogger",
    "text": "OPERATION NEPTUNE SPEAR, the mission to get Osama bin Laden, was among the most secretive military missions in history. As the Navy SEAL team took off in the early morning of May 2, 2011, only a few dozen people around the world had been briefed on the operation. One group was clustered in a top-secret military tactical operations center, and the other was gathered around a table in the White House Situation Room. There, President Obama and his advisors tracked the SEALs’ progress from 7,600 miles away via a direct video link that was the sole source of information about the mission. Or at least it was supposed to be. No one had counted on @Really-Virtual. @ReallyVirtual wasn’t a spy. He wasn’t a journalist either. His real name was Sohaib Athar, a Pakistani tech geek and café owner, whose social media handle described him as “an IT consultant taking a break from the rat-race by hiding in the mountains with his laptops.” A few years earlier, Athar had moved from the busy city of Lahore to the more pleasant town of Abbottabad, a mountain tourist hub and home of the Pakistan Military Academy — as well as, now, the most wanted man in the world. Crashing on a late-night software project, Athar was distracted by the sound of helicopters overhead. So he did what millions of people do each day: he took to social media to complain. “Helicopter hovering above Abbottabad at 1AM (is a rare event),” he tweeted first. As the SEALs’ mission played out over the next several minutes, Athar posted a litany of complaints that doubled as news reports. When the first helicopter took off, carrying away bin Laden’s body and hard drives filled with data on Al Qaeda’s networks, he tweeted, “Go away helicopter — before I take out my giant swatter :-/.” As the remaining SEALs detonated a crashed helicopter and piled into a backup chopper, Athar shared the news of the explosion. “A huge window shaking bang here in Abbottabad . . . ,” he tweeted. “I hope its not the start of something nasty :-S.” Eight hours later, the traditional news media finally caught up to one of the most important stories in a decade. On NBC, The Celebrity Apprentice was airing. Just as Donald Trump was explaining his rationale for “rehiring” singer La Toya Jackson, the network cut away. In a surprise prime-time address, President Obama announced that a top-secret raid had taken place in Pakistan and that Osama bin Laden was dead. “Justice has been done,” he concluded. In cities around the United States, people danced in the streets. Thousands of miles away, Athar was coming to his own realization. “Uh oh,” he tweeted, “now I’m the guy who liveblogged the Osama raid without knowing it.” It was lunchtime in Abbottabad when the messages began pouring in — a trickle that swiftly transformed into a torrent. Athar’s Twitter follower count jumped from 750 to 86,000. He was deluged with calls for interviews and fan requests. Local journalists sped to his café to talk face-to-face. More worrying, a growing online mob accused him of spying for either the U.S. or Pakistani government. Surely, they argued, that was the only way that Athar could have known about such a top-secret military operation. But the truth was simpler and more profound: Sohaib Athar was just a guy who happened to be near something newsworthy, with a computer and a social media account at hand.",
    "meta": {
      "theme": "The impact of social media on information dissemination and secrecy",
      "region": "Global",
      "use_case": "Unintentional intelligence leaks",
      "strategic_category": [
        "military_doctrine",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "intelligence",
        "secrecy",
        "citizen journalism"
      ],
      "influence_map": [],
      "chunk_index": 31
    },
    "id": "likewar_031"
  },
  {
    "section": "Part 2: Disintermediation and the Rise of Citizen Journalism",
    "text": "When the internet first began to boom in the 1990s, internet theorists proclaimed that the networked world would lead to a wave of what they called “disintermediation.” They described how, by removing the need for “in-between” services, the internet would disrupt all sorts of long-standing industries. Disintermediation soon remade realms ranging from retail stores (courtesy of Amazon) and taxi companies (courtesy of Uber) to dating (courtesy of Tinder). Athar’s tale showed how the business of information gathering had undergone the same kind of disintermediation. No longer did a reporter need to be a credentialed journalist working for a major news organization. A reporter could be anyone who was in the right place at the right time. But this shift wasn’t just about reporting the news. It was also changing all the people who make use of this information, be they citizens, politicians, soldiers, or spies. There was one more lesson wrapped up in the surreal saga of Sohaib Athar, unnoticed by many at the time but painfully obvious to observers in the U.S. intelligence community. Operation Neptune Spear — among the most closely guarded operations in history — had nonetheless been documented in real time for anyone in the world to see. And this had happened accidentally, in a country where just 6 percent of the population had internet access at the time. What would the future hold as more and more people came online? Even more, how would intelligence agencies cope when it wasn’t just a lone night owl inadvertently sharing secrets, but organized groups of analysts dedicated to parsing social media to find the operations hidden in plain sight? “Secrets now come with a half-life,” one CIA official told us, with more than a twinge of regret.",
    "meta": {
      "theme": "Disintermediation of information gathering and its implications for intelligence",
      "region": "Global",
      "use_case": "Impact of internet on traditional journalism and intelligence gathering",
      "strategic_category": [
        "national_security",
        "military_doctrine"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "disintermediation",
        "citizen journalism",
        "intelligence",
        "open source intelligence"
      ],
      "influence_map": [],
      "chunk_index": 32
    },
    "id": "likewar_032"
  },
  {
    "section": "Part 3: The Macaca Moment and the Rise of Radical Transparency",
    "text": "“Let’s give a welcome to ‘Macaca’ here,” puffed the fleshy man in the blue shirt, pointing toward the camera. “Welcome to America and the real world of Virginia.” It was August 2006, and Senator George Allen was barnstorming for votes at a rural Virginia park. A darling of the conservative wing of the Republican Party, he was already looking past this reelection bid. He’d recently made exploratory trips to Iowa and New Hampshire, testing the waters before a potential presidential run. But although Allen didn’t know it yet, his political career had just ended in that single moment, all because of how the internet had changed. The man behind the camera was S. R. Sidarth, a 20-year-old volunteer for Allen’s opponent, who had taken to filming Allen’s events. Sidarth was also Indian American — and the only brown face amid the rally’s 100 attendees. And the name Allen had just called him, “Macaca,” is Portuguese for “monkey,” used as a racial slur for centuries. The history of politicians saying and doing horrible or stupid things on the campaign trail is as old as democracy itself. But the trajectory from a bad moment to a fatal gaffe previously required a professional journalist to be on the scene to document it. Then the moment would have to be reported via a newspaper or radio or TV station. In order for the gaffe to build truly national momentum, other professional journalists and their outlets would then have to pick it up. Unfortunately for Allen, social media had altered this process, propelling his words beyond the control of any politician or journalist. Sidarth’s minute-long recording was quickly posted on YouTube, the new video-sharing platform, scarcely a year old in 2006. This was an unusual decision at the time, because the video clip was unedited and unattached to any broader story. It proved an ingenious move, however, as the very nature of the clip was part of its appeal. Easy to view and share, Sidarth’s video went viral, with hundreds of thousands of people seeing it firsthand online, and the news media being able to report on and link to it. Allen’s advisors, skilled and experienced in the old model of political campaigning, were flummoxed. At first they denied that the incident had happened. Then they claimed that Allen had done nothing wrong, explaining that “Macaca” wasn’t meant as a slur. And then they pivoted to claiming that Allen had actually said “Mohawk,” referring to Sidarth’s hair. The problem with each explanation was that, unlike in the past, anyone who wanted to could now see the evidence for themselves. They could click “play” and hear the ugly word again and again. They could see that Allen was using it to describe the one brown-skinned person in a crowd of white people and suggesting that Sidarth wasn’t a “real” American. Allen’s lead in the polls plummeted, and he went on to lose a race in which his victory had been all but guaranteed. Instead of making a run for president, he never served in elected office again. As for Sidarth, he was named Salon’s person of the year: a “symbol of politics in the 21st century, a brave new world in which any video clip can be broadcast instantly everywhere and any 20-year-old with a camera can change the world.” What became known as the “Macaca moment” was a hint of the web-driven radical transparency that was just starting to change how information was gathered and shared — even the nature of secrecy itself.",
    "meta": {
      "theme": "Radical transparency and the changing nature of secrecy in the digital age",
      "region": "United States",
      "use_case": "Impact of social media on political campaigns and accountability",
      "strategic_category": [
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "transparency",
        "political campaigns",
        "accountability",
        "viral videos"
      ],
      "influence_map": [],
      "chunk_index": 33
    },
    "id": "likewar_033"
  },
  {
    "section": "Part 4: The Trillion Sensor World and the End of Secrecy",
    "text": "The relatively new digital camera that Sidarth used to document Allen’s fateful words has since been followed by some 9 billion digital devices that, importantly, are now linked online. By 2020, that number will soar to 50 billion, as devices ranging from smartphones to smart cars to smart toothbrushes all join in to feed the internet. Most significantly, all of the new items coming online carry something that the computers used by ARPANET, and even the one used by Mark Zuckerberg to create Facebook, lacked: “sensors,” devices for gathering information about the world beyond the computer. Some sensors are self-evident, like the camera of a smartphone. Others lurk in the background, like the magnometer and GPS that provide information about direction and location. These billions of internet-enabled devices, each carrying multiple sensors, are on pace to create a world of almost a trillion sensors. And any information put online comes with “metadata,” akin to digital stamps that provide underlying details of the point of origin and movement of any online data. Each tweet posted on Twitter, for instance, carries with it more than sixty-five different elements of metadata. This plethora of sensors and associated metadata is making real an idea that has long possessed (and frightened) humanity: the possibility of an ever-present watcher. The ancient Greeks imagined it as Argus Panoptes, a mythological giant with 100 eyes. During the Enlightenment, the English philosopher Jeremy Bentham turned the monster into the Panopticon — a hypothetical building in which all the occupants could be observed, but they never saw those watching them. Ominously, Bentham pitched his design as being useful for either a factory or a prison. George Orwell then gave the panoptic idea an even darker spin in his novel 1984. His futuristic totalitarian world was filled with “telescreens,” wall-mounted televisions that watched viewers while they watched the screens. Today, the combination of mass sensors and social media has rendered these bizarre fantasies an equally bizarre reality. Yet rather than gods or rulers, we are collectively the ones doing the watching. A decade after Allen flamed out, any politician worth their salt, gazing into a crowd of a hundred people, might reasonably assume they are the subject of no less than a half dozen videos and many more photographs, texts, and audio snippets, any of which might prompt scores of social media reactions. Indeed, they would likely be upset if no one posted about the event online. To ensure that didn’t happen, they would likely be doing it themselves. In the run-up to the 2018 U.S. midterm elections, some candidates were pushing out more than a dozen Facebook videos a day. None of this means that gaffes like Allen’s no longer happen, nor that racist comments are no longer made; rather the opposite. When everything can be recorded, everything is on the record.",
    "meta": {
      "theme": "The trillion sensor world and the implications for privacy and secrecy",
      "region": "Global",
      "use_case": "Ubiquitous surveillance and the erosion of privacy",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "sensors",
        "metadata",
        "surveillance",
        "privacy",
        "panopticon"
      ],
      "influence_map": [],
      "chunk_index": 34
    },
    "id": "likewar_034"
  },
  {
    "section": "Part 5: The Data Deluge and Unintentional Intelligence Leaks",
    "text": "The amount of data being gathered about the world around us and then put online is astounding. In a minute, Facebook sees the creation of 500,000 new comments, 293,000 new statuses, and 450,000 new photos; YouTube the uploading of more than 400 hours of video; and Twitter the posting of more than 300,000 tweets. And behind this lies billions more dots of added data and metadata, such as a friend tagging who appeared in that Facebook photo or the system marking what cellphone tower the message was transmitted through. In the United States, the size of this “digital universe” doubles roughly every three years. Each point of information might be from an observer consciously capturing a speech or a gun battle, or it might be unwittingly shared with the world, as was Athar’s coverage of the bin Laden raid. The most valuable information might even lurk in the background. Snapping tourist photos of a harbor, Chinese civilians once accidentally revealed secrets of their navy’s new aircraft carrier, under construction in the distance. Or an interesting tidbit might lie in the technical background. Exercise apps have inadvertently revealed everything from the movements of a murderer committing his crime to the location of a secret CIA “black site” facility in the Middle East. (A heat map made from tracing agents’ daily jogs around the perimeter of their base provided a near-perfect outline of one installation.) In 2017, General Mark Milley, chief of staff of the U.S. Army, summed up what this means for the military: “For the first time in human history, it is near impossible to be unobserved.” Consider that in preparation for D-Day in June 1944, the Allies amassed 2 million soldiers and tens of thousands of tanks, cannons, jeeps, trucks, and airplanes in the British Isles. Although German intelligence knew that the Allied forces were there, they never figured out where or when they would strike. That information came only",
    "meta": {
      "theme": "The data deluge and its impact on intelligence and military operations",
      "region": "Global",
      "use_case": "Unintentional intelligence leaks through data exhaust and metadata",
      "strategic_category": [
        "military_doctrine",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "big data",
        "metadata",
        "intelligence",
        "open source intelligence",
        "military operations"
      ],
      "influence_map": [],
      "chunk_index": 35
    },
    "id": "likewar_035"
  },
  {
    "section": "Part 1: The Unveiling",
    "text": "When the first Americans stormed Utah Beach, secrecy was paramount. Today, a single soldier’s or local civilian’s Facebook account could compromise an entire operation. Even digital silence might be suspicious, a gap in the pervasive social media fabric.  This unveils not just troop movements, but can pinpoint individuals geographically.  Ashley Madison, a social network for infidelity, uses social media to target business travelers at hotels, predicting their likelihood to cheat. Similarly, Russian intelligence pinpointed Ukrainian soldiers on the front lines via their smartphones, sending them chilling messages before artillery strikes.  The key difference is that this information explosion is largely self-generated.  Starting with Facebook’s 2006 status update feature, we've become chronic over-sharers, documenting everything from grocery lists to childbirth.  The selfie epitomizes this, with millennials projected to take thousands in their lifetimes.  Even fighter pilots and refugees take selfies, blurring the lines between personal and public. These postings now convey weighty policy issues.  World leaders, from Stephen Harper to Mahmoud Ahmadinejad, have embraced social media. Government agencies, from national embassies to elementary schools, share their news.  Militaries publicize their presence, from official accounts to updates on individual operations, even hosting Reddit AMAs.",
    "meta": {
      "theme": "Information Age Warfare and Social Media",
      "region": "Global",
      "use_case": "Military Operations, Social Engineering, Political Communication",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": "OSINT, social media analysis, psychological warfare",
      "influence_map": [],
      "chunk_index": 36
    },
    "id": "likewar_036"
  },
  {
    "section": "Part 2: The End of Forgetting",
    "text": "This constant churn of information has a lasting impact.  Nothing truly disappears online, creating a permanent record.  Donald Trump, as a reality TV star and social media enthusiast, entered politics with a vast digital trail. This archive, including thousands of hours of video and tens of thousands of tweets, provides unprecedented insight into his personality and decision-making.  Intelligence agencies recognize the value of this data, reportedly using it to build psychological profiles. Trump’s online presence, while extensive, covers only a decade of his later life. Future leaders will likely have even larger datasets from much earlier ages, potentially impacting their careers.  This online sharing goes beyond daily activities, offering glimpses into our psychological states.  Researchers like Luke Stark suggest that online postings resemble medical or psychiatric data.  Even seemingly trivial details, like Instagram filter choices, can reveal underlying conditions like depression.",
    "meta": {
      "theme": "Data Permanence and Psychological Profiling",
      "region": "Global",
      "use_case": "Intelligence Gathering, Political Analysis, Psychological Research",
      "strategic_category": [
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "temporal_orientation"
      ],
      "usage_tags": "digital footprint, data mining, psychological profiling",
      "influence_map": [],
      "chunk_index": 37
    },
    "id": "likewar_037"
  },
  {
    "section": "Part 3: The Electric Brain Awakens",
    "text": "The 2008 Mumbai attacks marked a turning point in news dissemination and analysis.  While only a small number of Twitter users existed globally, Mumbai's tech-savvy population provided real-time updates during the attacks.  Tweets documented explosions, gunshots, and warnings, offering immediate insights.  Users far from Mumbai relayed information from those trapped inside. With authorities overwhelmed, this spontaneous network became a primary news source.  Amateur photos from Flickr filled newspaper front pages.  However, this also spread rumors and misinformation.  Online communities emerged to sift through the data, separating fact from fiction.  A Wikipedia page for the attacks was created within hours, with numerous editors contributing. Google Maps allowed for the plotting of attacks in real time, creating a dynamic operational history.  This unprecedented transparency extended to the attackers themselves, who reportedly used social media to track events. The online crowd, realizing this, urged others to stop posting about security force movements. Some even sent taunting messages to the terrorists.  A new form of emergency coordination arose, with calls for blood donations and tip lines spreading rapidly online.  The Mumbai attacks demonstrated the power of crowdsourcing, a concept previously limited to software development.  It showed how the internet could empower the many, distributing influence previously held by the few.",
    "meta": {
      "theme": "Crowdsourcing and Real-Time Information in Crisis",
      "region": "India (Mumbai), Global",
      "use_case": "Crisis Reporting, Emergency Response, Information Verification",
      "strategic_category": [
        "national_security",
        "military_doctrine"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": "crowdsourcing, citizen journalism, information warfare",
      "influence_map": [],
      "chunk_index": 38
    },
    "id": "likewar_038"
  },
  {
    "section": "Crowdsourcing and Warfare",
    "text": "A fundraising juggernaut in the 2016 U.S. presidential election, raking in $218 million online.  Crowdsourcing has also been bent to the demands of war. A generation ago, Al Qaeda was started by the son of a Saudi billionaire. By the time of the Syrian civil war and the rise of ISIS, the internet was the “preferred arena for fundraising” for terrorism, for the same reasons it has proven so effective for startup companies, nonprofits, and political campaigns. It doesn’t just allow wide geographic reach. It expands the circle of fundraisers, seemingly linking even the smallest donor with their gift target on a personal level.  This was one of the key factors that fueled the years-long Syrian civil war. Fighters sourced needed funds by learning “to crowdfund their war using Instagram, Facebook and YouTube. In exchange for a sense of what the war was really like, the fighters asked for donations via PayPal. In effect, they sold their war online.” Just as any digital marketing guru would advise, Syrian fighting groups have molded their message to reflect the donor pool’s interest. Many of Syria’s early rebel fighters sought to establish a free, secular democracy. But this prospect didn’t excite the fundamentalist donors from the wealthy Arab states. So, to better sell their effort online, even secular fighters grew impressively long beards and made sure to pepper their battle videos with repetitions of “Allahu Akbar” (God is great). Fundraisers also got creative through what became known as “financial jihad.” Some clerics argued that online pledges allowed donors to fulfill their religious duties in the same way they would if they had actually served in battle.  You could sponsor a rocket-propelled grenade (RPG) launcher for a Syrian rebel (it went for $800). Or you could back the rebels’ opponents. Hezbollah, the Iranian-sponsored terror group that allied with the Syrian regime, ran an “equip a mujahid” campaign on Facebook and Twitter. It similarly allowed online supporters to fulfill their religious obligations by buying weapons and ammunition for the war.",
    "meta": {
      "theme": "Crowdsourcing & Terrorist Financing",
      "region": "Middle East, Global",
      "use_case": "Fundraising, Propaganda, Recruitment",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "terrorism",
        "warfare"
      ],
      "influence_map": [],
      "chunk_index": 39
    },
    "id": "likewar_039"
  },
  {
    "section": "Radical Transparency and Crowdsourced Violence",
    "text": "As radical transparency merges with crowdsourcing, the result can wander into the grotesque. In 2016, a hard-line Iraqi militia took to Instagram to brag about capturing a suspected ISIS fighter. The militia then invited its 75,000 online fans to vote on whether to kill or release him. Eager, violent comments rolled in from around the world, including many from the United States. Two hours later, a member of the militia posted a follow-up selfie; the body of the prisoner lay in a pool of blood behind him. The caption read, “Thanks for vote.”  This represented a bizarre evolution in warfare: “A guy on the toilet in Omaha, Nebraska, could emerge from the bathroom with the blood of some 18-year-old Syrian on his hands.” The rapidity with which these bloodthirsty votes came in illustrates how the speed at which these spontaneous online collectives form is accelerating apace with the information environment.",
    "meta": {
      "theme": "Online Violence and Public Participation",
      "region": "Iraq, Global",
      "use_case": "Public executions, Propaganda",
      "strategic_category": [
        "military_doctrine"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "violence",
        "warfare",
        "propaganda"
      ],
      "influence_map": [],
      "chunk_index": 40
    },
    "id": "likewar_040"
  },
  {
    "section": "The Accelerated News Cycle and Presentism",
    "text": "In 2008, the online mosaic of the Mumbai terror attacks was pieced together in a matter of hours. Five years later, at the Boston Marathon Bombing of April 15, 2013, this timeline had shifted by an order of magnitude. It took about thirty seconds for Boston’s emergency coordination center to learn of the attack that killed 3 people and wounded nearly 300 more — a fact that it would proudly document in an after-action report commissioned a year later. But the news was already online. The very moment when Boston police officers and firefighters were shouting into their radios, @KristenSurman tapped out a frantic message to her Twitter followers: “Holy shit! Explosion!” Seconds later, @Boston_to_a_T uploaded the first photo of the attack, taken mid-fireball. It took three minutes for the terror attack to be reported by a professional media outlet. The coverage came via a quick tweet from Fox Sports Radio — but not in Boston; in Washington State. By contrast, it took nearly an hour for Boston police to formally confirm the bombing. Since then, the size and reach of this online audience has continued to grow exponentially, while the number of global smartphone users has more than doubled. Virtually any event leaves a digital trail that can be captured, shared, and examined by hungry internet users. As the audience eagerly rushes from one development to the next, it drives new developments of its own. Less and less is there a discrete “news cycle.” Now there is only the news, surrounding everyone like the Force in Star Wars, omnipresent and connected to all. The best way to describe the feeling that results is a term from the field of philosophy: “presentism.” In presentism, the past and future are pinched away, replaced by an incomprehensibly vast now. If you’ve ever found yourself paralyzed as you gaze at a continually updating Twitter feed or Facebook timeline, you know exactly what presentism feels like. Serious reflection on the past is hijacked by the urgency of the current moment; serious planning for the future is derailed by never-ending distraction. Media theorist Douglas Rushkoff has described this as “present shock.” Buffeted by a constant stream of information, many internet users can feel caught in a struggle just to avoid being swept away by the current.",
    "meta": {
      "theme": "The Impact of Real-Time Information on Perception",
      "region": "Global",
      "use_case": "Information dissemination, Situational awareness",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "temporal_orientation"
      ],
      "usage_tags": [
        "social media",
        "information warfare",
        "news cycle",
        "presentism"
      ],
      "influence_map": [],
      "chunk_index": 41
    },
    "id": "likewar_041"
  },
  {
    "section": "Part 1: Citizen Journalism and the Rise of OSINT",
    "text": "So Beware of Them.” It showed a group, whom ISIS claimed to be the reporters and their families, being paraded in front of cameras and then hanged from a tree. Raqqa Is Being Slaughtered Silently then reported these executions, sadly noting that ISIS had killed the wrong people. Eventually, ten members of the network were found and killed. One woman, Ruqia Hassan, dashed off a quick Facebook post shortly before ISIS police captured and executed her. “It’s okay because they will cut my head,” she wrote. “And I have dignity, it’s better than I live in humiliation.” For both its bravery and novelty, the group was awarded a 2015 International Press Freedom Award.\nA common thread runs through all of these stories. From favela life to cartel bloodlettings to civil wars, social media has erased the distinction between citizen, journalist, activist, and resistance fighter. Anyone with an internet connection can move seamlessly between these roles. Often, they can play them all at once. This communications revolution has been complemented by another shift, easier to miss but perhaps even more consequential. Just as the people who document and reveal secrets to the world have changed, so, too, have the people who traditionally work behind the scenes collecting and analyzing this information. They’re called “intelligence analysts,” or, more colloquially, “spies.” And today, they look (and work) quite a bit different indeed.",
    "meta": {
      "theme": "The changing landscape of information gathering and dissemination in the digital age.",
      "region": "Global",
      "use_case": "Citizen journalism, open-source intelligence, conflict reporting",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "citizen journalism",
        "OSINT",
        "conflict reporting"
      ],
      "influence_map": [],
      "chunk_index": 42
    },
    "id": "likewar_042"
  },
  {
    "section": "Part 2: The Downfall of MH17 and the Birth of Bellingcat",
    "text": "WORK-FROM-HOME SHERLOCK HOLMES\nAs he boarded his long-haul flight from the Netherlands to Malaysia on July 17, 2014, the Dutch musician Cor Pan snapped a picture of the waiting Boeing 777 and uploaded it to Facebook. “In case we go missing, here’s what it looks like,” he wrote. It was supposed to be a joke. Instead, it would become one of the last digital echoes of a terrible tragedy. A few hours later, the plane was flying over eastern Ukraine…\n…Bellingcat posted their findings online, mapping out the odyssey of the weapon that had killed 298 people, as well as showing its Russian origin.",
    "meta": {
      "theme": "The power of open-source intelligence in investigating complex events.",
      "region": "Ukraine, Russia, Netherlands",
      "use_case": "Open-source investigation, aircraft downing, international criminal investigation",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "OSINT",
        "Bellingcat",
        "MH17",
        "social media investigation",
        "conflict analysis"
      ],
      "influence_map": [],
      "chunk_index": 43
    },
    "id": "likewar_043"
  },
  {
    "section": "Part 3: The Expanding Reach of Open-Source Intelligence",
    "text": "The weapon and even its unit had been found, but who had pulled the trigger?\nHere the answer was provided by the shooters themselves. Searching through Russian soldiers’ profiles on VKontakte, or VK (essentially a Russian version of Facebook), the Bellingcat team found images of military equipment, dour group photographs, and hundreds of angsty selfies…\n…In revealing these secrets, OSINT showed how its ability to unveil what was once hidden can be a powerful potential force for good. It can not only catch people cutting corners (quite literally, OSINT analysts found that one of every five racers in the 2017 Mexico City Marathon cheated, including several politicians hoping to tout their endurance), but also shine a light on the world’s worst crimes. The manner in which Hitler and Pol Pot were able to kill en masse, unbeknownst to the",
    "meta": {
      "theme": "The democratization of intelligence gathering and its potential applications.",
      "region": "Global",
      "use_case": "Open-source intelligence, social media analysis, criminal investigations, accountability",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "OSINT",
        "social media analysis",
        "criminal investigation",
        "accountability",
        "transparency"
      ],
      "influence_map": [],
      "chunk_index": 44
    },
    "id": "likewar_044"
  },
  {
    "section": "Part 1: The OSINT Revolution and Its Uses",
    "text": "The world without secrets, once a dystopian fantasy, is now a reality thanks to the explosion of open-source intelligence (OSINT).  Groups like Bellingcat have demonstrated its power, using publicly available information to document war crimes in Ukraine and chemical weapons use in Syria.  The International Criminal Court's indictment of Mahmoud Al-Werfalli in 2017, based solely on social media evidence, marked a new frontier in international law.  However, this same technology can be exploited for malicious purposes. Terrorists can use OSINT for reconnaissance and networking, while criminals employ it for virtual and physical kidnappings, gathering information from social media to target victims.  OSINT also offers insights into previously opaque areas like arms trafficking. Monitoring online arms trades on platforms like Facebook can reveal not only impending conflicts but also evidence of policy failures, such as the online trade of U.S.-supplied weapons originally intended for the Iraqi army and Syrian rebels.  Furthermore, OSINT is being used for predictive analysis. Companies like Predata, founded by former CIA agent James Shinn, analyze social media feeds to forecast events like riots and wars, providing insights to hedge funds and intelligence agencies.  Even North Korean nuclear tests have been predicted by analyzing online chatter. The sheer volume of social media data is becoming so revealing that it can anticipate future events.",
    "meta": {
      "theme": "The rise of open-source intelligence and its dual-use nature.",
      "region": "Global",
      "use_case": "Intelligence gathering, criminal activity, predictive analysis",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "OSINT",
        "social media",
        "war crimes",
        "terrorism",
        "arms trafficking",
        "predictive analysis"
      ],
      "influence_map": [],
      "chunk_index": 45
    },
    "id": "likewar_045"
  },
  {
    "section": "Part 2:  The Intelligence Community Adapts (and Resists)",
    "text": "The explosion of publicly available information is transforming the global intelligence system, impacting tools, organization, and institutional practices.  OSINT, while having roots in World War II, was traditionally viewed with skepticism by intelligence agencies. During the Cold War, despite massive OSINT collection efforts like the Foreign Broadcast Information Service (FBIS), intelligence chiefs prioritized classified sources. The FBIS was eventually overwhelmed by the sheer volume of online data and shut down in 2005.  However, some intelligence officers recognized OSINT's growing importance. They envisioned a future where open-source data, accessible to everyone, would be the primary source of intelligence. This shift required a fundamental change in thinking and agency practices, challenging established norms and budget priorities. One such officer was Michael Thomas Flynn.  Flynn, rising through the ranks of Army intelligence, recognized the need for a shift towards open-source data during his time with the Joint Special Operations Command (JSOC) tracking Al Qaeda in Iraq.  He advocated for a “net fisherman” approach, targeting entire networks rather than individual nodes.  Promoted to lead the Defense Intelligence Agency (DIA) in 2012, Flynn attempted to prioritize OSINT and computational analysis, facing resistance from the agency's bureaucracy.  His efforts ultimately led to his dismissal after just a year and a half.",
    "meta": {
      "theme": "The impact of OSINT on traditional intelligence gathering and the challenges of adapting to a new information landscape.",
      "region": "Global, with focus on the United States",
      "use_case": "Intelligence reform, organizational change, bureaucratic resistance",
      "strategic_category": [
        "military_doctrine",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "OSINT",
        "intelligence agencies",
        "Cold War",
        "FBIS",
        "DIA",
        "bureaucracy",
        "Michael Flynn"
      ],
      "influence_map": [],
      "chunk_index": 46
    },
    "id": "likewar_046"
  },
  {
    "section": "Part 3: Flynn's Fall from Grace",
    "text": "Following his forced retirement, Flynn became a vocal critic of the Obama administration, gaining media attention and lucrative speaking engagements. He also entered the world of political consulting, signing a questionable deal with a Turkish-linked company and accepting speaking fees from the Russian government. His association with Vladimir Putin raised concerns within the U.S. security establishment.  Flynn's rising profile caught the attention of Donald Trump, and he became a fervent campaign surrogate, lending national security credibility to the then-candidate. However, Flynn's engagement with social media took a dark turn. His Twitter feed became a platform for hate speech, conspiracy theories, and attacks on political opponents.  Despite his earlier cautions about the importance of accuracy and judgment in the online world, Flynn himself embraced misinformation, gaining a large following in the process.  After Trump's election victory, Flynn was appointed National Security Advisor but was quickly fired due to his misleading statements about contacts with Russian officials, marking the shortest tenure in that position in American history. He later pleaded guilty to lying to the FBI.",
    "meta": {
      "theme": "The dangers of embracing misinformation and the consequences for a once-respected intelligence officer.",
      "region": "United States, Russia, Turkey",
      "use_case": "Political campaigning, social media manipulation, misinformation",
      "strategic_category": [
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "Michael Flynn",
        "Donald Trump",
        "social media",
        "misinformation",
        "conspiracy theories",
        "Russia"
      ],
      "influence_map": [],
      "chunk_index": 47
    },
    "id": "likewar_047"
  },
  {
    "section": "Part 1: The Illusion of Freedom",
    "text": "admit to making, in his words, “false, fictitious, and fraudulent statements.” As it all played out, we were reminded of one more piece of wisdom Flynn had imparted to us before his downfall. He’d spoken of the importance of piercing through the “fog” of the modern information environment; of getting to the “golden nuggets” of actionable intelligence that lurked in the mists of social media. The right bit of data was already out there, he explained. You just had to know where to look. The general was right. The internet has indeed exposed the golden nuggets — the truth — for anyone to find. But, as his story also shows, scattered among these bits of truth is pyrite, “fool’s gold,” cleverly engineered to distract or even destroy us. It is harder than ever to keep a secret. But it is also harder than ever to separate the truth from lies. In the right hands, those lies can become powerful weapons.\n“INFORMATION WANTS TO BE FREE,” declared web pioneer and counterculture icon Stewart Brand at the world’s first Hackers Conference in 1984. This freedom wouldn’t just sound the death knell of censorship; it would also mark the end of authoritarian regimes that relied on it. After all, what government could triumph against a self-multiplying network of information creators and consumers, where any idea might mobilize millions in a heartbeat? John Gilmore, an early cyber-activist and cofounder of the Electronic Frontier Foundation, put it simply in a 1993 interview: “The Net interprets censorship as damage and routes around it.” For many years, this seemed to be the case. In a dispatch for the newly launched Wired magazine, reporter Bruce Sterling described the key role of an early freedom fighter. In 1989, a mysterious digital Johnny Appleseed appeared in Czechoslovakia. Activists would credit him with helping to spark the uprisings that spread across Soviet-ruled Eastern Europe. But at the time, he was known simply as “the Japanese guy.” Without any warning or fanfare, some quiet Japanese guy arrived at the university with a valise full of brand-new and unmarked 2400-baud Taiwanese modems. The astounded Czech physics and engineering students never did quite get this gentleman’s name. He just deposited the modems with them free of charge, smiled cryptically, and walked off diagonally into the winter smog of Prague, presumably in the direction of the covert-operations wing of the Japanese embassy. They never saw him again. The Czech students distributed the new networking technology, using it to circulate manifestos and disseminate daily news updates. They were able to expand their revolutionary circles in a way never before possible, while evading the old methods of monitoring and censorship.",
    "meta": {
      "theme": "Information Warfare",
      "region": "Global",
      "use_case": "Propaganda and Counter-Propaganda",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "disinformation",
        "censorship",
        "internet_freedom",
        "social_media"
      ],
      "influence_map": [],
      "chunk_index": 48
    },
    "id": "likewar_048"
  },
  {
    "section": "Part 2: The Rise and Fall of Internet Revolutions",
    "text": "As the internet continued its blistering growth, the power of democratic dissidents followed. The first so-called internet revolution shook Serbia in 1996. Cut off from state media, young people used mass emails to plan protests against the regime of President Slobodan Milošević. Although the initial protests failed, they returned stronger than ever in 2000, being organized even more online. Serbia’s youth won out and kicked off a series of “color revolutions,” which soon spread throughout the former Soviet bloc, toppling rulers in Georgia, Ukraine, and Kyrgyzstan. Then, in 2009, anger against a rigged election swept across theocratic Iran. While the front pages of Iranian newspapers were full of blank spaces (where government censors had blotted out reports), young people took to social media to organize and share the news. An astounding 98 percent of the links posted on Twitter that week were about Iran. Photos showed tens of thousands of Iranian youth pouring into the streets, a smartphone in nearly every hand. “The Revolution Will Be Twittered,” declared one excited headline. Wired magazine’s Italian edition nominated the internet for a Nobel Peace Prize. In 2010, Mohamed Bouazizi, a 26-year-old Tunisian, touched off the next outbreak of web-powered freedom. Each morning for ten years, he had pushed a cart to the city marketplace, selling fruit to support his widowed mother and five siblings. Every so often, he had to navigate a shakedown from the police — the kind of petty corruption that had festered under the two-decade-long rule of dictator Zine el-Abidine Ben Ali. But on December 17, 2010, something inside Bouazizi snapped. After police confiscated his wares and he was denied a hearing to plead his case, Bouazizi sat down outside the local government building, doused his clothes with paint thinner, and lit a match. Word of the young man’s self-immolation spread quickly through the social media accounts of Tunisians. His frustration with corruption was something almost every Tunisian had experienced. Dissidents began to organize online, planning protests and massive strikes. Ben Ali responded with slaughter, deploying snipers who shot citizens from rooftops. Rather than retreat, however, some protesters whipped out their smartphones. They captured grisly videos of death and martyrdom. These were shared tens of thousands of times on Facebook and YouTube. The protests transformed into a mass uprising. On January 14, 2011, Ben Ali fled the country. The conflagration soon leapt across national borders. While the Egyptian dictator Hosni Mubarak ordered censorship of the events in Tunisia, Wael Ghonim, a 30-year-old Google executive, used Facebook to organize similar protests in Cairo. When the first 85,000 people pledged online to march with him, Time magazine asked, “Is Egypt about to have a Facebook Revolution?” It was and it did. The trickle of pro-democracy protests turned to a raging torrent. Hundreds of thousands of demonstrators braved tear gas and bullets to demand Mubarak’s resignation. His thirty-year reign ended in a matter of days. In the geopolitical equivalent of the blink of an eye, Egypt became a free nation. A euphoric Ghonim gave credit where credit seemed due. “The revolution started on Facebook,” he said. “We would post a video on Facebook that would be shared by 60,000 people . . . within a few hours. I’ve always said that if you want to liberate a society, just give them the Internet.” Elsewhere, he said, “I want to meet Mark Zuckerberg one day and thank him.” Another Egyptian revolutionary gave thanks in a more unorthodox way, naming his firstborn baby girl “Facebook.” Political unrest soon rocked Syria, Jordan, Bahrain, and a dozen more nations. In Libya and Yemen, dictators who had ruled for decades through the careful control of their population and its sources of information saw their regimes crumble in a matter of days. Tech evangelists hailed what was soon called the Arab Spring as the start of a global movement that would end the power of authoritarian regimes around the world, perhaps forever. The Arab Spring seemed the perfect story of the internet’s promise fulfilled. Social media had illuminated the shadowy crimes through which dictators had long clung to power, and offered up a powerful new means of grassroots mobilization. In the words of technology writer Clay Shirky, online social networks gave activists a way to “organize without organizations.” Through Facebook events and Twitter hashtags, protests grew faster than the police could stamp them out. Each time the autocrats reacted violently, they created new online martyrs, whose deaths sparked further outrage. Everywhere, it seemed, freedom was on the march, driven by what Roger Cohen of the New York Times extolled as “the liberating power of social media.”",
    "meta": {
      "theme": "The Internet and Political Change",
      "region": "Middle East, North Africa, Eastern Europe",
      "use_case": "Revolution and Counter-Revolution",
      "strategic_category": [
        "geopolitical_strategy",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems",
        "historical_memory"
      ],
      "usage_tags": [
        "arab_spring",
        "color_revolutions",
        "social_movements",
        "authoritarianism"
      ],
      "influence_map": [],
      "chunk_index": 49
    },
    "id": "likewar_049"
  },
  {
    "section": "Part 3: The Counter-Revolution and Control of the Internet",
    "text": "Yet not everyone felt so sure. The loudest dissenter was Evgeny Morozov. Born in 1984 in the former Soviet bloc nation of Belarus, Morozov had been raised in an environment where a strongman had clung to power for nearly three decades. Like others his age, Morozov had enthusiastically embraced the internet as a new means to strike back against authoritarianism. “Blogs, social networks, wikis,” he remembered. “We had an arsenal of weapons that seemed far more potent than police batons, surveillance cameras, and handcuffs.” But it never seemed to be enough. Not only did the activists fail to sustain their movement, but they noticed, to their horror, that the government began to catch up. Tech-illiterate bureaucrats were replaced by a new generation of enforcers who understood the internet almost as well as the protesters. They no longer ignored online sanctuaries. Instead, they invaded them, not just tracking down online dissidents, but using the very same channels of liberation to spread propaganda. More alarming, their tactics worked. Years after the first internet revolutions had sent shivers down dictators’ spines, the Belarusian regime actually seemed to be strengthening its hand. Morozov moved to the United States and set his sights squarely on the Silicon Valley dreamers, whom he believed were leading people astray. In a scathing book titled The Net Delusion, he coined a new term, “cyber-utopianism.” He decried “an enthusiastic belief in the liberating power of technology,” made worse by a “stubborn refusal to acknowledge its downside.” When his book was released at the height of the Arab Spring, those he attacked as “cyber-utopians” were happy to laugh him off. If newly freed populations were literally naming their kids after social media, who could doubt its power for good? As it turned out, the Arab Spring didn’t signal the first steps of a global, internet-enabled democratic movement. Rather, it represented a high-water mark. The much-celebrated revolutions began to fizzle and collapse. In Libya and Syria, digital activists would soon turn their talents to waging internecine civil wars. In Egypt, the baby named Facebook would grow up in a country that quickly turned back to authoritarian government, the new regime even more repressive than Mubarak’s. Around the world, information had been freed. But so had a countering wave of authoritarianism using social media itself, woven into a pushback of repression, censorship, and even violence. The web’s unique strengths had been warped and twisted toward evil ends. In truth, democratic activists had no special claim to the internet. They’d simply gotten there first.",
    "meta": {
      "theme": "The Dark Side of Internet Freedom",
      "region": "Global",
      "use_case": "Authoritarian Adaptation and Repression",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "cyber-utopianism",
        "internet_control",
        "propaganda",
        "censorship",
        "authoritarianism"
      ],
      "influence_map": [],
      "chunk_index": 50
    },
    "id": "likewar_050"
  },
  {
    "section": "Part 4: Controlling the Signal",
    "text": "CONTROL THE SIGNAL\nLiu was a new arrival to the city of Weifang, China. He was new, too, to the city’s traditions. One balmy August evening, he stumbled upon a neighborhood square dance. It looked like fun, and Liu — tired from another day of hunting for work — decided to join in the festivities. Too late, Liu noticed the laughter and pointed fingers from the audience, the smartphones snapping his photo. He realized that nearly all the other dancers were middle-aged women. Liu fled the scene, flushed with embarrassment. He became petrified that his picture would be shared online for others to mock. So he did the only thing that made sense to him: he decided to destroy the internet. Liu prowled the city looking for optical cable receivers, the big boxes of coiled wire that relay internet data to individual households. Each time he found one, he forced it open and tore the receiver apart by hand. By the time Liu was caught, he’d caused $15,000 worth of damage. Liu was sent to prison, but the internet — although temporarily disrupted across parts of Weifang — kept right on chugging. We know this because we read about him in an online report that made its way around the world. While Liu failed in his mission, he actually had the right idea. After all, the internet isn’t really a formless, digital “cloud.” It is made up of physical things. His problem was that these “things” include billions of computers and smartphones linked to vast server farms that play host to all the world’s online services. These are then bound together through an ever-growing network of everything from fiber-optic cable that runs twenty-five times the circumference of the earth, to some 2,000 satellites that circle the planet. No one human could hope to control so monumental a creation. But governments are a different story. For all the immensity of today’s electronic communications network, the system remains under the control of only a few thousand internet service providers (ISPs), the firms that run the backbone, or “pipes,” of the internet. Just a few ISPs supply almost all of the world’s mobile data. Indeed, because two-thirds of all ISPs reside in the United States, the average number per country across the rest of the globe is relatively small. Many of these ISPs hardly qualify as “businesses” at all. They are state-sanctioned monopolies or crony sanctuaries directed by the whim of local officials. Liu would never have been able to “destroy” the internet. Neither can any one government. But regimes can control when the internet goes on (or off) and what goes on it. Designed as an open system and built on trust, the web remains vulnerable to governments that play by different rules. In less-than-free nations around the world, internet blackouts are standard practice. All told, sixty-one countries so far have created mechanisms that allow for national-level internet cutoffs. When the Syrian uprising began, for instance, the government of Bashar al-Assad compelled Syria’s main ISP to cut off the internet on Fridays, as that was the day people went to mosques and organized",
    "meta": {
      "theme": "Internet Infrastructure and Control",
      "region": "Global, China, Syria",
      "use_case": "Censorship and Information Control",
      "strategic_category": [
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "internet_infrastructure",
        "internet_service_providers",
        "internet_blackouts",
        "censorship"
      ],
      "influence_map": [],
      "chunk_index": 51
    },
    "id": "likewar_051"
  },
  {
    "section": "Protests and Internet Shutdowns",
    "text": "Internet shutdowns are increasingly used by governments to control information flow, especially during protests. This isn't limited to wartime; in 2016, Algeria shut down internet access for three days during national high school tests due to leaked exam questions. Many suspected this was a test of censorship tools. These blackouts are costly. A 2016 study showed Algeria lost $20 million, and Saudi Arabia lost $465 million during similar shutdowns. Governments are now investing in more targeted control.  India cut mobile connections in Rohtak district for a week during protests, costing $190 million. Bahrain instituted an “internet curfew” in specific villages, even targeting individual users and IP addresses.  Another tactic is “throttling,” slowing down connections to hinder coordination while being harder to detect. Iran's internet conveniently slows during planned protests. Governments also aim to control internet infrastructure through “data localization” or “balkanization,” creating national networks. Iran's National Internet Project exemplifies this, aiming for a “clean” internet isolated from the outside world.  Despite censorship, people find ways around it, using identity-masking technologies and satellite communications. Syrian rebels, for instance, maintained social media presence through Turkey's mobile network. Except for North Korea's closed intranet, the goal is not to completely stop information flow, but to weaken it, making access more difficult and hindering mass mobilization.",
    "meta": {
      "theme": "Internet Censorship and Control",
      "region": "Global, with specific examples from Algeria, Saudi Arabia, India, Bahrain, Iran, North Korea, Syria, and Turkey.",
      "use_case": "Government control of information and suppression of dissent.",
      "strategic_category": [
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "internet shutdown",
        "throttling",
        "censorship",
        "protests",
        "information control",
        "balkanization"
      ],
      "influence_map": [],
      "chunk_index": 52
    },
    "id": "likewar_052"
  },
  {
    "section": "Control the Body: The Case of Dion Nissenbaum",
    "text": "The power of online speech can have real-world consequences, as journalist Dion Nissenbaum discovered in Turkey. During the 2016 attempted coup, social media played a vital role in mobilizing citizens against the plotters. The mayor of Ankara used Twitter to rally people to the streets, and a newspaper's digital coordinator used Facebook to report events when the printing press was seized.  However, after the coup's failure, President Erdoğan used the opportunity to purge political opponents. Thousands were arrested, and media outlets were shut down.  Nissenbaum retweeted an OSINT report about ISIS executing Turkish soldiers.  This led to online backlash from Turkish nationalists, threats, and calls for his deportation. Turkish police arrested Nissenbaum, held him in isolation for three days, and then abruptly released him.  Nissenbaum's experience highlights the volatile nature of social media and the real-world consequences of online actions. While he was fortunate to be released, many Turks faced imprisonment for online speech. His case demonstrates the power governments wield to control online narratives, even as the internet amplifies the reach of information.",
    "meta": {
      "theme": "Government Control and Repression of Online Speech",
      "region": "Turkey",
      "use_case": "Arrest and detention for online activities, demonstrating the power of states to control narratives even in the face of increased information flow.",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "arrest",
        "detention",
        "social media",
        "censorship",
        "political repression",
        "journalism"
      ],
      "influence_map": [],
      "chunk_index": 53
    },
    "id": "likewar_053"
  },
  {
    "section": "Censorship in the Name of Religion, Culture, and National Unity",
    "text": "Governments often justify online censorship under the guise of religion, culture, or national unity. Iran polices its “clean” internet for threats to “public morality,” targeting human rights activists. Saudi Arabia punishes those challenging the monarchy, with harsh sentences for online mockery or criticism of the government. Pakistan even issued a death sentence for online speech related to religious disputes.  Thailand enforces lèse majesté laws, threatening imprisonment for insulting the royal family, even extending to those viewing unflattering images online.  These regimes actively search for online dissent, using tactics like friend requests to monitor users. Thailand's “Cyber Scouts” program encourages children to report online wrongdoing.  Appeals to national strength and unity are also used to justify censorship.  A Kazakh criticizing Putin online was imprisoned for inciting “hatred.” A Russian woman sharing negative stories about the Ukraine invasion faced hard labor for “discrediting the political order.”  This power extends to controlling companies running the networks, demonstrating that real people behind these organizations are vulnerable to state pressure.",
    "meta": {
      "theme": "Justifications and Methods of Online Censorship",
      "region": "Global, with examples from Iran, Saudi Arabia, Pakistan, Thailand, Kazakhstan, and Russia.",
      "use_case": "Censorship and control of online narratives using justifications of religion, culture, and national unity.",
      "strategic_category": [
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "censorship",
        "religion",
        "culture",
        "national unity",
        "surveillance",
        "political repression"
      ],
      "influence_map": [],
      "chunk_index": 54
    },
    "id": "likewar_054"
  },
  {
    "section": "Part 1: Control and Self-Censorship",
    "text": "arm of the law — or other means. VKontakte is the most popular social network in Russia. After anti-Putin protesters used VK in the wake of the Arab Spring, the regime began to take a greater interest in it and the company’s young, progressive-minded founder, Pavel Durov. When the man once known as “the Mark Zuckerberg of Russia” balked at sharing user data about his customers, armed men showed up at his apartment. He was then falsely accused of driving his Mercedes over a traffic cop’s foot, a ruse to imprison him. Getting the message, Durov sold his shares in the company to a Putin crony and fled the country. Over time, such harsh policing of online speech actually becomes less necessary as self-censorship kicks in. Communications scholars call it the “spiral of silence.” Humans continually test their beliefs against those of the perceived majority and often quietly moderate their most extreme positions in order to get along better with society as a whole. By creating an atmosphere in which certain views are stigmatized, governments are able to shape what the majority opinion appears to be, which helps steer the direction of actual majority opinion. Although plenty of dissenters still exist in authoritarian states, like those seeking to circumvent web bans and throttling, they now have to work harder. Their discussions have migrated from open (and easily monitored) social media platforms to secure websites and encrypted message applications, where only true believers can find them. Yet there is more. Through the right balance of infrastructure control and enforcement, digital-age regimes can exert remarkable control over not just computer networks and human bodies, but the minds of their citizens as well. No nation has pursued this goal more vigorously — or successfully — than China.",
    "meta": {
      "theme": "Control of Online Speech",
      "region": "Russia, China",
      "use_case": "Authoritarian Regimes' Digital Strategies",
      "strategic_category": [
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "censorship",
        "self-censorship",
        "spiral of silence",
        "surveillance"
      ],
      "influence_map": [],
      "chunk_index": 55
    },
    "id": "likewar_055"
  },
  {
    "section": "Part 2: China's Great Firewall and Cadence",
    "text": "CONTROL THE SPIRIT “Across the Great Wall we can reach every corner in the world.” So read the first email ever sent from the People’s Republic of China, zipping 4,500 miles from Beijing to Berlin. The year was 1987. Chinese scientists celebrated as their ancient nation officially joined the new global internet. Other milestones soon followed. In 1994, China adopted the same TC/IP system that powered the World Wide Web. Almost overnight, the dour research tool of Chinese scientists became a digital place, popping with colorful websites and images. Two years later, the internet was opened to Chinese citizens, not just research institutions. A trickle of new users turned into a flood. In 1996, there were just 40,000 Chinese online; by 1999, there were 4 million. In 2008, China passed the United States in number of active internet users: 253 million. Today, that figure has tripled again to nearly 800 million (over a quarter of all the world’s netizens), and, as we saw in chapter 2, they use some of the most vibrant and active forms of social media. Yet it was also clear from the beginning that for the citizens of the People’s Republic of China, the internet would not be — could not be — the freewheeling, crypto-libertarian paradise pitched by its American inventors. China has remained a single, cohesive political entity for 4,000 years. The country’s modern history is defined by two critical periods: a century’s worth of embarrassment, invasion, and exploitation by outside nations, and a subsequent series of revolutions that unleashed a blend of communism and Chinese nationalism. For these reasons, Chinese authorities treasure harmony above all else. Harmony lies at the heart of China’s meteoric rise and remains the underlying political doctrine of the Chinese Communist Party (CCP), described by former president Hu Jintao as the creation of a “harmonious society.” Dissent, on the other hand, is viewed as only harmful to the nation, leaving it again vulnerable to the machinations of foreign powers. Controlling ideas online has thus always been viewed as a vital, even natural, duty of the Chinese state. Unity must be maintained; harmful ideas must be stamped out. Yuan Zhifa, a former senior government propagandist, described this philosophy in 2007. “The things of the world must have cadence,” he explained. His choice of words was important. Subtly different from “censorship,” “cadence” means managing the “correct guidance of public opinion.” From the beginning, the CCP made sure that the reins of the internet would stay in government hands. In 1993, when the network began to be seen as something potentially important, officials banned all international connections that did not pass through a handful of state-run telecommunications companies. The Ministry of Public Security was soon tasked with blocking the transmission of all “subversive” or “obscene” information, working hand in hand with network administrators. In contrast to the chaotic web of international connections emerging in the rest of the globe, the Chinese internet became a closed system. Although Chinese internet users could build their own websites and freely communicate with other users inside China, only a few closely scrutinized strands of cable connected them to the wider world. Far from surmounting the Great Wall, the “Chinese internet” had become defined by a new barrier: the Great Firewall.",
    "meta": {
      "theme": "China's Internet Control Strategy",
      "region": "China",
      "use_case": "Maintaining Social Harmony and National Unity",
      "strategic_category": [
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "historical_memory"
      ],
      "usage_tags": [
        "Great Firewall",
        "censorship",
        "cadence",
        "internet control",
        "harmonious society"
      ],
      "influence_map": [],
      "chunk_index": 56
    },
    "id": "likewar_056"
  },
  {
    "section": "Part 1: China's Digital Mass Line",
    "text": "A phalanx of internet commenters differs from a traditional crowdsourcing network due to the level of organization provided by a state bureaucracy, complete with pay scales, quotas, guidelines, examinations, and official job certifications.  These commenters, dubbed the “50-Cent Army,” were rumored to receive 50 Chinese cents per post (a term China later banned from social media).  Early advertisements for the 50-Cent Army linked performance, based on posts and replies, to awards in municipal publicity work. By 2008, the 50-Cent Army had roughly 280,000 members. Today, estimates suggest up to 2 million members generating at least 500 million social media posts annually. This model of organized online positivity has become so successful that many members no longer require payment, and it has been adopted by various organizations in China, from PR companies to schools.\n\nThis system of firewalls, surveillance, keyword censorship, arrests, and crowdsourced propagandists aims to merge the consciousness of 1.4 billion people with the state's consciousness. While some view this as Orwellian, it resonates with Mao Zedong's “mass line.”  When Mao broke with the Soviet Union, he criticized Stalin and Soviet communism for their focus on “individualism.”  Mao envisioned a political cycle where the masses' will, filtered through Marxism, shaped policy, which was then returned to the people for refinement. This process aimed to forge a single, shared vision among all Chinese people.\n\nThis ideal proved difficult, and such thinking was blamed for the Cultural Revolution's purges in the 1960s and 1970s, ultimately repudiated after Mao’s death. However, the Chinese internet has facilitated a resurgence of this mass-line philosophy.  President Xi Jinping has praised these technologies for realizing Mao’s vision of “condensing” public opinion into a powerful consensus.",
    "meta": {
      "theme": "Digital Authoritarianism, Propaganda, Social Engineering",
      "region": "China",
      "use_case": "Control of public opinion, political consolidation",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems",
        "historical_memory"
      ],
      "usage_tags": [
        "internet censorship",
        "propaganda",
        "social media manipulation",
        "mass surveillance"
      ],
      "influence_map": [
        "Mao Zedong's Mass Line",
        "Modern applications in social media control"
      ],
      "chunk_index": 57
    },
    "id": "likewar_057"
  },
  {
    "section": "Part 2: China's Social Credit System and Global Influence",
    "text": "To achieve this goal, even stronger control programs are emerging.  In Xinjiang, residents are forced to install the Jingwang (web-cleansing) app, which allows message tracking and blocking, and grants authorities remote access to phones and home networks. Police checkpoints ensure compliance by inspecting phones for the app’s presence.  The most ambitious realization of the mass line is China’s “social credit” system. Unveiled in 2015, the system aims to create an “upward, charitable, sincere and mutually helpful social atmosphere” characterized by loyalty to the state.  All citizens receive a numerical score reflecting their “trustworthiness” across all aspects of life.  Like a financial credit score, this “social credit” is calculated by compiling personal information and computing a single score measuring societal usefulness. This is facilitated by the near-universal reliance on mobile services like WeChat, which integrates social networking, chatting, consumer reviews, money transfers, and everyday tasks, revealing vast amounts of personal data. This data informs sweeping moral judgments. Buying too many video games might suggest idleness and lower a score, while regularly buying diapers might suggest parenthood and raise it. Political proclivities also play a role; “positive” online contributions enhance scores, while dissent lowers them.  The system even rewards reporting acts of “breach of trust.” Scores are also influenced by friends and family, incentivizing behavioral shaping within social networks.\n\nThe system's power lies in its rewards and risks. Slated for full deployment in 2020, it's already used in job applications and for micro-rewards. Low scores can restrict access to train berths and welfare benefits. It's even integrated into online matchmaking services, linking government-defined value to romantic prospects. China's success in subordinating the internet to the state is unique due to its head start and investment scale. However, other nations, including Thailand, Vietnam, Zimbabwe, and Cuba, have reportedly explored similar systems.  Russia's President Putin has signed a pact for Chinese censors to train Russian engineers in web control mechanisms.  China is exporting its censorship expertise, just as U.S. tech companies once helped build its Great Firewall. These programs demonstrate that the internet has become a tool for authoritarian regimes to maintain power through visible controls and sophisticated social engineering.",
    "meta": {
      "theme": "Digital Authoritarianism, Surveillance, Social Control",
      "region": "China, Global",
      "use_case": "Social engineering, political control, global influence",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture",
        "geostrategic_positioning"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social credit system",
        "surveillance state",
        "internet censorship",
        "technology export"
      ],
      "influence_map": [
        "Influence on other authoritarian regimes",
        "Global spread of internet censorship techniques"
      ],
      "chunk_index": 58
    },
    "id": "likewar_058"
  },
  {
    "section": "Part 3: Russia's Disinformation Playbook",
    "text": "A young philosophy major, tempted by “easy work and good money,” found himself writing over 200 blog posts and comments daily, assuming fake identities, hijacking conversations, and spreading lies for the Russian government.  He was a soldier in a global war of censorship by disinformation. Russia's history with disinformation (dezinformatsiya) dates back to the Soviet era, used both for ideological battles abroad and population control at home.  One anecdote describes the KGB inventing the word “disinformation” to disguise its Russian origins. During the Cold War, the KGB conducted over 10,000 disinformation operations, ranging from creating front groups and media outlets to spreading fake stories and conspiracy theories.  Operation INFEKTION, the false claim that the U.S. military created AIDS, is a notorious example.  Launched in 1983 through a KGB-planted article in the Indian newspaper Patriot (itself a KGB front), the story was given further credence by fake scientists.  Amplified by Soviet media, the story spread to Western outlets, demonstrating the operation’s success, albeit after four years.\n\nThe fall of the Soviet Union seemingly ended such initiatives, and Russia’s new constitution guaranteed free information access. However, disinformation didn't disappear.  With the rise of social media and the ascension of former KGB officer Vladimir Putin, the spread of lies became even more attractive.  Through crony capitalism and forced buyouts, Russia’s major media networks fell under the control of oligarchs financially linked to the state.  The Kremlin disseminates its positions through press releases and private conversations, dutifully reported by Russian media regardless of the necessary spin. Unlike the “grave, deliberate tones” of Soviet propaganda, the new propaganda is colorful and exciting, mixing moralizing, angry diatribes, celebrations of traditional values, and scantily clad women.  Pop stars and rappers promote pro-government messages, while a constant drumbeat of anxiety about terrorism, the CIA, and the West permeates the media landscape.",
    "meta": {
      "theme": "Disinformation, Propaganda, Media Control",
      "region": "Russia",
      "use_case": "Political control, undermining opponents, foreign influence",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "historical_memory",
        "value_systems"
      ],
      "usage_tags": [
        "disinformation campaigns",
        "propaganda",
        "media manipulation",
        "kompromat"
      ],
      "influence_map": [
        "Soviet disinformation tactics",
        "Modern applications in social media and traditional media"
      ],
      "chunk_index": 59
    },
    "id": "likewar_059"
  },
  {
    "section": "Part 4: Russia's Controlled Opposition and Journalist Suppression",
    "text": "Unlike the Soviet Union or China, Russia allows political opposition, but within unspoken rules.  “Good” opponents, like Vladimir Zhirinovsky, entertain and make Putin seem more sensible. “Bad” opponents, like Boris Nemtsov, who advocated reform and investigated corruption, faced harsher consequences, including assassination.  Between 2014 and 2017, at least thirty-eight prominent Putin opponents died under suspicious circumstances.  Dissent is also permitted among independent journalists, but within limits.  Those who become too vocal face harassment, disinformation campaigns, and “scandals” involving kompromat. More forceful methods, including murder, ensure silence; dozens of independent journalists have been killed since Putin consolidated power. This creates an illusion of free speech while effectively silencing meaningful dissent.",
    "meta": {
      "theme": "Authoritarianism, Media Control, Repression",
      "region": "Russia",
      "use_case": "Political control, suppression of dissent",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "political repression",
        "journalist safety",
        "censorship",
        "disinformation"
      ],
      "influence_map": [
        "Soviet-era repression tactics",
        "Modern application in a networked information environment"
      ],
      "chunk_index": 60
    },
    "id": "likewar_060"
  },
  {
    "section": "The Kremlin's Control and Response to Uprisings",
    "text": "Within a newfangled Potemkin village, the Kremlin aims to control all political discourse, preventing independent movements.  As Peter Pomerantsev, author of *Nothing Is True and Everything Is Possible*, writes, “Moscow can feel like an oligarchy in the morning and a democracy in the afternoon, a monarchy for dinner and a totalitarian state by bedtime.” This control extends beyond Russia's borders.  After the color revolutions and the Arab Spring, similar enthusiasm inspired protests in Russia in 2011.  Perceiving these movements as Western attacks, Russia decided to fight back.",
    "meta": {
      "theme": "Information Warfare and Political Control",
      "region": "Russia, Eastern Europe, Middle East",
      "use_case": "Suppression of dissent, manipulation of public opinion",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [],
      "influence_map": [],
      "chunk_index": 61
    },
    "id": "likewar_061"
  },
  {
    "section": "The Gerasimov Doctrine",
    "text": "Russia's new strategy, articulated by General Valery Gerasimov, emphasized nonmilitary means to achieve political goals, surpassing the effectiveness of weapons.  Gerasimov proposed restructuring the Russian state to exploit the internet's asymmetrical possibilities.  These observations, known as the Gerasimov Doctrine, were incorporated into Russian military strategy.  Russian theorists considered this a defensive strategy—a “war on information warfare against Russia.” This power required strategic investment and organization, contrasting with the West's view of the internet as chaotic and organic. A conglomerate of institutions studied and weaponized information, coordinated by the Federal Security Service. This radical approach aimed to neutralize adversaries before they threatened Russia.",
    "meta": {
      "theme": "Information Warfare Theory and Strategy",
      "region": "Russia",
      "use_case": "Defensive information warfare, preemptive neutralization of threats",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [],
      "influence_map": [],
      "chunk_index": 62
    },
    "id": "likewar_062"
  },
  {
    "section": "Russia's Information Warfare Tactics and Outlets",
    "text": "Ben Nimmo described Russia's strategy as the “4 Ds”: dismiss the critic, distort the facts, distract from the main issue, and dismay the audience. Russia began using propaganda, notably through Rossiya Segodnya (RT). Initially a traditional outlet, RT transformed into a contrarian media empire with the motto “Question More.”  Its budget increased significantly, reflecting its role as a “weapons system” of influence. RT's connection to the Kremlin is evident.  It broadcasts globally and has a vast online presence.  Its goal shifted from sharing Russia with the world to highlighting other countries' flaws. It publishes stories attacking Russia's opponents and supports divisive forces within adversary nations.",
    "meta": {
      "theme": "Propaganda and Disinformation Tactics",
      "region": "Global",
      "use_case": "Undermining adversaries, influencing public opinion",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [],
      "influence_map": [],
      "chunk_index": 63
    },
    "id": "likewar_063"
  },
  {
    "section": "The Spread of Disinformation and Manipulation of News",
    "text": "RT's success led to the creation of other Russian outlets like Sputnik International and Baltica, often outperforming local media.  This network rapidly spreads disinformation. For example, a U.S. Army training exercise was falsely reported as a massive deployment against Russia.  This falsehood originated from Donbass News International and spread through various outlets, including seemingly reputable ones, before being amplified by RT. This process, similar to Operation INFEKTION, now takes hours instead of years and reaches a wider audience.  This strategy also blunts harmful news by spreading false headlines.  For instance, after the MH17 crash, Russia initially denied involvement, then pushed alternative explanations, blaming the Ukrainian government, the Malaysian airline, and finally claiming victimhood.",
    "meta": {
      "theme": "Disinformation Campaigns and Manipulation of Narratives",
      "region": "Global",
      "use_case": "Creating confusion, discrediting adversaries, manipulating public perception",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [],
      "influence_map": [
        "Operation INFEKTION"
      ],
      "chunk_index": 64
    },
    "id": "likewar_064"
  },
  {
    "section": "The MH17 Case Study and Modern Censorship",
    "text": "Despite evidence of Russia's involvement in the MH17 shootdown, Russian media presented forged satellite images showing a Ukrainian fighter jet attacking the airliner.  This forgery was easily debunked, but the point was to instill doubt.  This tactic is akin to Edgar Allan Poe's “The Purloined Letter,” where hiding something in plain sight is the best way to conceal it. Modern censorship involves burying information under half-truths and imitations.",
    "meta": {
      "theme": "Disinformation and Censorship Tactics",
      "region": "Global",
      "use_case": "Creating confusion, manipulating public perception, obscuring truth",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [],
      "influence_map": [],
      "chunk_index": 65
    },
    "id": "likewar_065"
  },
  {
    "section": "Web Brigades and Troll Factories",
    "text": "Beyond the media network, Russia employs “web brigades,” an online army of paid commenters who sow “civil unrest” among Russia’s foes. This tactic originated with the pro-Kremlin youth group Nashi, which praised Putin and attacked his opponents online.  The Kremlin then incentivized private companies to offer similar services, leading to the creation of “troll factories.” These trolls assume fake identities and post on social media to hijack conversations and spread lies.",
    "meta": {
      "theme": "Social Media Manipulation and Troll Farms",
      "region": "Russia",
      "use_case": "Sowing discord, manipulating online conversations, spreading disinformation",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [],
      "influence_map": [],
      "chunk_index": 66
    },
    "id": "likewar_066"
  },
  {
    "section": "Part 1",
    "text": "during an average twelve-hour day, to “post on news articles 50 times. Each blogger is to maintain six Facebook accounts publishing at least three posts a day and discussing the news in groups at least twice a day. By the end of the first month, they are expected to have won 500 subscribers and get at least five posts on each item a day. On Twitter, they might be expected to manage 10 accounts with up to 2,000 followers and tweet 50 times a day.” The hard work of a sockpuppet takes three forms, best illustrated by how they operated during the 2016 U.S. election. One is to pose as the organizer of a trusted group. @Ten_GOP called itself the “unofficial Twitter account of Tennessee Republicans” and was followed by over 136,000 people (ten times as many as the official Tennessee Republican Party account). Its 3,107 messages were retweeted 1,213,506 times. Each retweet then spread to millions more users, especially when it was disseminated by prominent Trump campaign figures like Donald Trump Jr., Kellyanne Conway, and Michael Flynn. On Election Day 2016, it was the seventh most retweeted account across all of Twitter. Indeed, Flynn followed at least five such documented accounts, sharing Russian propaganda with his 100,000 followers at least twenty-five times. The second sockpuppet tactic is to pose as a trusted news source. With a cover photo image of the U.S. Constitution, @tpartynews presented itself as a hub for conservative fans of the Tea Party to track the latest headlines. For months, the Russian front pushed out anti-immigrant and pro-Trump messages and was followed and echoed out by some 22,000 people, including Trump’s controversial advisor Sebastian Gorka. Finally, sockpuppets pose as seemingly trustworthy individuals: a grandmother, a blue-collar worker from the Midwest, a decorated veteran, providing their own heartfelt take on current events (and who to vote for). Another former employee of the Internet Research Agency, Alan Baskayev, admitted that it could be exhausting to manage so many identities. “First you had to be a redneck from Kentucky, then you had to be some white guy from Minnesota who worked all his life, paid taxes and now lives in poverty; and in 15 minutes you have to write something in the slang of [African] Americans from New York.” Baskayev waxed philosophic about his role in American politics. “It was real postmodernism. Postmodernism, Dadaism and Sur[realism].” Yet, far from being postmodern, sockpuppets actually followed the example of classic Cold War “active measures” by targeting the extremes of both sides of American politics during the 2016 election. The fake accounts posed as everything from right-leaning Tea Party activists to “Blacktivist,” who urged those on the left to “choose peace and vote for Jill Stein. Trust me, it’s not a wasted vote.” A purported African American organizer, Blacktivist, was actually one of those Russian hipsters sitting in St. Petersburg, whose Facebook posts would be shared an astounding 103.8 million times before the company shut the account down after the election.",
    "meta": {
      "theme": "Disinformation and Social Media Manipulation",
      "region": "Global, focus on United States and Russia",
      "use_case": "Political Influence Operations",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "sockpuppets",
        "propaganda",
        "social media",
        "election interference"
      ],
      "influence_map": [],
      "chunk_index": 67
    },
    "id": "likewar_067"
  },
  {
    "section": "Part 2",
    "text": "By cleverly leveraging readers’ trust, these engineers of disinformation induced thousands — sometimes millions — of people each day to take their messages seriously and spread them across their own networks via “shares” and retweets. This sharing made the messages seem even more trustworthy, since they now bore the imprimatur of whoever shared them, be it a distinguished general or a family friend. As the Russians moved into direct advertising, this tactic enabled them to achieve an efficiency that digital marketing firms would kill for. According to a dataset of 2016 Facebook advertisements purchased by Russian proxies, the messages received engagement rates as high as 24 percent — far beyond the single digits to which marketing firms usually aspire. The impact of the operation was further magnified by how efforts on one social media platform could complement (and amplify) those on another. Russian sockpuppets ran rampant on services like Instagram, an image-sharing platform with over 800 million users (larger than Twitter and Snapchat combined) and more popular among youth than its Facebook corporate parent. Here, the pictorial nature of Instagram made the disinformation even more readily shareable and reproducible. In 2017, data scientist Jonathan Albright conducted a study of just twenty-eight accounts identified as having been operated by the Russian government. He found that this handful of accounts had drawn an astounding 145 million “likes,” comments, and plays of their embedded videos. They’d also provided the visual ammunition subsequently used by other trolls who stalked Facebook and Twitter. These messages gained even greater power as they reached beyond social media, taking advantage of how professional news outlets — feeling besieged by social media — had begun embedding the posts of online “influencers” in their own news stories. In this, perhaps no one matched the success of @Jenn_Abrams. A sassy American teen, who commented on everything from Kim Kardashian’s clothes to the need to support Donald Trump, her account amassed nearly 70,000 Twitter followers. That was impressive, but not nearly as impressive as the ripple effect of her media efforts. “Jenn” was quoted in articles in the BBC News, BET, Breitbart, Business Insider, BuzzFeed, CNN, The Daily Caller, The Daily Dot, the Daily Mail, Dallas News, Fox News, France24, Gizmodo, HuffPost, IJR, the Independent, Infowars, Mashable, the National Post, the New York Daily News, New York Times, The Observer, Quartz, Refinery29, Sky News, the Times of India, The Telegraph, USA Today, U.S. News and World Report, the Washington Post, Yahoo Sports, and (unsurprisingly) Russia Today and Sputnik. Each of these articles was then read and reacted to, spreading her views even further and wider. In 2017, “Jenn” was outed by Twitter as yet another creation of Russia’s Internet Research Agency.",
    "meta": {
      "theme": "Disinformation and Social Media Manipulation",
      "region": "Global, focus on United States and Russia",
      "use_case": "Political Influence Operations",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "sockpuppets",
        "propaganda",
        "social media",
        "election interference",
        "virality"
      ],
      "influence_map": [],
      "chunk_index": 68
    },
    "id": "likewar_068"
  },
  {
    "section": "Part 3",
    "text": "The Russian effort even turned the social media firms’ own corporate strategies against their customers. As a way to draw users deeper into its network, Facebook automatically steered people to join groups, where they could find new friends who “share their common interests and express their opinion.” The Russian sockpuppets learned to create and then manipulate these online gatherings. One of the more successful was Secured Borders, an anti–Hillary Clinton Facebook group that totaled over 140,000 subscribers. It, too, was actually run out of the St. Petersburg office of the Internet Research Agency. By combining online circulation with heavy ad buys, just one of its posts reached 4 million people on Facebook and was “liked” more than 300,000 times. Much like the harassment campaigns inside Russia, sockpuppets also targeted Putin critics abroad. The most extreme efforts were reserved for those who investigated the disinformation campaigns themselves. After journalist Jessikka Aro published an exposé of the fake accounts, sockpuppets attacked her with everything from posts claiming she was a Nazi and drug dealer to messages pretending to be from her father, who had died twenty years earlier. When another group of Western foreign affairs specialists began to research the mechanics of disinformation campaigns, they found themselves quickly savaged on the professional networking site LinkedIn. One was labeled a “pornographer,” and another was accused of harassment. Such attacks can be doubly effective, not only silencing the direct targets but also discouraging others from doing the sort of work that earned such abuse. While the sockpuppets were extremely active in the 2016 election, it was far from their only campaign. In 2017, data scientists searched for patterns in accounts that were pushing the theme of #UniteTheRight, the far-right protests that culminated in the killing of a young woman in Charlottesville, Virginia, by a neo-Nazi. The researchers discovered that one key account in spreading the messages of hate came to life each day at 8:00 a.m. Moscow time. Realizing they’d unearthed a Russian sockpuppet, they dug into its activities before the Charlottesville protests. For four years, it had posted around a hundred tweets a day, more than 130,000 messages in all. At first, the chief focus was support for UKIP, a far-right British party. Then it shifted to pushing Russia’s stance on the Ukraine conflict. Then it pivoted to a pro-Brexit stance, followed by support for Trump’s candidacy. After his election, it switched to white nationalist “free speech” protests. The efforts of these networks continue to this day, ever seeking to sow anger and division within Russia’s foes.",
    "meta": {
      "theme": "Disinformation and Social Media Manipulation",
      "region": "Global, focus on United States and Russia",
      "use_case": "Political Influence Operations",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "sockpuppets",
        "propaganda",
        "social media",
        "election interference",
        "harassment",
        "division"
      ],
      "influence_map": [],
      "chunk_index": 69
    },
    "id": "likewar_069"
  },
  {
    "section": "Part 4",
    "text": "Indeed, a full three years after the flight MH17 tragedy, we tested the strength of the Russian disinformation machine for ourselves by setting what’s known as a “honeypot.” The term traditionally referred to a lure — in fiction, usually a sexy female agent — which enemy operatives couldn’t resist. Think Vesper Lynd’s seduction of James Bond in Casino Royale, or her real-life counterpart, Anna Chapman, the redheaded KGB agent who worked undercover in New York and then, after she was caught by the FBI and deported back to Russia, began a second career as a Facebook lingerie model. We posted something even more enticing on Twitter: one of Bellingcat’s reports. Within minutes, an account we’d had no prior link with reached out, inundating us with images disputing the report as “#Bellingcrap.” The account’s history showed it, day after day, arguing against Russia’s role in MH17, while occasionally mixing things up with anti-Ukrainian conspiracy theories and tweets in support of far-right U.S. political figures. In trying to persuade us, our new online friend had instead provided a window into a fight over “truth” that will likely continue to rage for as long as the internet exists. Success breeds imitators. Just as some nations have begun to study China’s internet engineering, many others are copying Russian techniques. In Venezuela, the nominally elected “president,” Nicolas Maduro, enjoys an online cult of personality in which loyal (and paid) supporters quickly suppress critical headlines. In Azerbaijan, “patriotic trolls” launch coordinated attacks to discredit pro-democratic campaigners. Even in democratic India, rumors fly of shadowy online organizations that exist to defend the party of Prime Minster Narendra Modi. They applaud each new government policy and circulate “hit lists” to dig up dirt on opponents and pressure them into silence. If no incriminating material exists, they simply invent it. A 2017 study from Oxford University’s Computational Propaganda Research Project found that, all told, at least twenty-nine regimes have followed this new model of censorship to “steer public opinion, spread misinformation, and undermine critics.” Even more worrisome, in 2017 at least eighteen national-level elections were targeted by such social media manipulation. As more governments become attuned to the internet’s dark possibilities, this figure will only grow. Perhaps the most pernicious effect of these strategies, however, is how they warp our view of the world around us. It is a latter-day incarnation of the phenomenon explored in Gaslight, a 1938 play that was subsequently turned into a movie. In the story, a husband seeks to convince his new wife that she’s going mad (intending to get her committed to an asylum and steal her hidden jewels). He makes small changes to her surroundings — moving a painting or walking in the attic — then tells her that the things she is seeing and hearing didn’t actually occur. The play’s title comes from the house’s gas lighting, which dims and brightens as he prowls the house late at night. Slowly but surely, he shatters his wife’s sense of reality. As she says of her mounting self-doubt and resulting self-censorship, “In the morning when the sun rises, sometimes it’s hard to believe there ever was a night.” Since the 1950s, the term “gaslighting” has been used to describe relationships in which one partner seeks control over another by manipulating or even denying the truth. We’re now seeing a new form of gaslighting, perpetrated repeatedly and successfully through social media on the global stage. In the words of writer Lauren Ducca, “Facts . . . become interchangeable with opinions, blinding us into arguing amongst ourselves, as our very reality is called into question.” All the while, a new breed of authoritarians tighten their grip on the world. Yet sinister as they might be, even the strongest dictators cannot force someone to believe that the earth is flat. Nor can the accumulated weight of 100,000 online comments so much as bend a blade of grass unless someone chooses to act on them. There’s another piece of the puzzle still unaccounted for, perhaps the information battlefield’s most dangerous weapon of all. Our own brains.",
    "meta": {
      "theme": "Disinformation and Social Media Manipulation",
      "region": "Global, focus on United States, Russia, Venezuela, Azerbaijan, and India",
      "use_case": "Political Influence Operations,  Censorship, and Control",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "sockpuppets",
        "propaganda",
        "social media",
        "election interference",
        "honeypot",
        "gaslighting",
        "censorship",
        "control"
      ],
      "influence_map": [],
      "chunk_index": 70
    },
    "id": "likewar_070"
  },
  {
    "section": "Part 5",
    "text": "The Unreality Machine The Business of Veracity vs. Virality When all think alike, no one thinks very much. — Walter Lippmann, The Stakes of Diplomacy NEVER BEFORE COULD THESE TEENAGE BOYS have afforded the $100 bottles of Moët champagne that they sprayed across the nightclub floor. But that was before the gold rush, before their lives were flooded with slick wardrobes and fancy cars and newly available women. In the rusted old industrial town of Veles, Macedonia, they were the freshly crowned kings. They worked in “media.” More specifically, they worked in American social media. The average U.S. internet user was basically a",
    "meta": {
      "theme": "The Economics of Disinformation",
      "region": "Macedonia, United States",
      "use_case": "Profit-driven Disinformation",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "fake news",
        "social media",
        "profit",
        "disinformation"
      ],
      "influence_map": [],
      "chunk_index": 71
    },
    "id": "likewar_071"
  },
  {
    "id": "likewar_072",
    "section": "Extracted Content",
    "text": "walking bag of cash, worth four times the advertising dollars of anyone else in the world — and they were very gullible. In a town with 25 percent unemployment and an annual income of under $5,000, these young men had discovered a way to monetize their boredom and decent English-language skills. They set up catchy websites, peddling fad diets and weird health tips, and relying on Facebook “shares” to drive traffic. With each click, they got a small slice of the pie from the ads running along the side. Soon the best of them were pulling in tens of thousands of dollars a month. But there was a problem. As word got out, competition swelled. More and more Veles teens launched websites of their own. Fortunately, these young tycoons had timed their business well. The American political scene soon brought them a virtually inexhaustible source of clicks and resulting fast cash: the 2016 U.S. presidential election. The Macedonians were awed by Americans’ insatiable thirst for political stories. Even a sloppy, clearly plagiarized jumble of text and ads could rack up hundreds of thousands of “shares.” The number of U.S. politics–related websites operated out of Veles ballooned into the hundreds. As U.S. dollars poured into the local economy, one nightclub even announced that it would hold special events the same day Google released its advertising payouts. “Dmitri” (a pseudonym) was one of the successful entrepreneurs. He estimated that in six months, his network of fifty websites attracted some 40 million page views driven there by social media. It made him about $60,000. The 18-year-old then expanded his media empire. He outsourced the writing to three 15-year-olds, paying each $10 a day. Dmitri was far from the most successful of the Veles entrepreneurs. Several became millionaires. One even rebranded himself as a “clickbait coach,” running a school where he taught dozens of others how to copy his success. Some 5,000 miles from actual American voters, this small Macedonian town had become a cracked mirror of what Mark Zuckerberg had pulled off just a decade earlier. Its entrepreneurs had pioneered a new industry that created an unholy amount of cash and turned a legion of young computer nerds into rock stars. As one 17-year-old girl explained at the nightclub, watching the teen tycoons celebrate from her perch at the bar, “Since fake news started, girls are more interested in geeks than macho guys.” The viral news stories pumped out by these young, hustling Macedonians weren’t just exaggerations or products of political spin; they were flat-out lies. Sometimes, the topic was the long-sought “proof” that Obama had been born in Kenya or revelations that he was planning a military coup. Another report warned that Oprah Winfrey had told her audience that “some white people have to die.” In retrospect, such articles seem unbelievable, but they were read on a scale that soared past reports of the truth. A study of the top election news–related stories found that false reports received more engagement on Facebook than the top stories from all the major traditional news outlets combined. As with their peddling of fad diets, the boys turned to political lies for the sole reason that this was what their targets seemed to want. “You see they like water, you give water,” said Dmitri. “[If] they like wine, you give wine.” There was one cardinal rule in the business,",
    "meta": {
      "theme": "unspecified",
      "region": "unspecified",
      "use_case": "doctrine_selector",
      "strategic_category": {},
      "economic_category": {},
      "civilizational_category": {},
      "usage_tags": [],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": []
      },
      "chunk_index": 72
    }
  },
  {
    "section": "The Power of Homophily and Confirmation Bias",
    "text": "The longer you linger in a particular community, the more its claims will be repeated until they become truisms—even if they remain the opposite of the truth.  Homophily doesn’t just sustain crazy online echo chambers; its effects can sow deadly consequences for society. A prime example is the anti-vaccine movement...\n\n...In California, the percentage of parents applying a “personal belief exception” to avoid vaccinating their kindergartners quadrupled between 2000 and 2013, and disease transmittal rates among kids soared as a result. Cases of childhood illnesses like whooping cough reached a sixty-year high, while the Disneyland resort was rocked by an outbreak of measles that sickened 147 children. Fighting an infectious army of digital conspiracy theorists, the State of California eventually gave up arguing and passed a law requiring kindergarten vaccinations, which only provided more conspiracy theory fodder.\n\nTempting as it may be to blame the internet for this, the real source of these digital echo chambers is again deeply rooted in the human brain. Put simply, people like to be right; they hate to be proven wrong. In the 1960s, an English psychologist isolated this phenomenon and put a name to it: “confirmation bias.” Other psychologists then discovered that trying to fight confirmation bias by demonstrating people’s errors often made the problem worse. The more you explain with facts that someone is mistaken, the more they dig in their heels. What the internet does do is throw this process into overdrive, fueling the brain’s worst impulses and then spreading them to countless others. Social media transports users to a world in which their every view seems widely shared. It helps them find others just like them. After a group is formed, the power of homophily then knits it ever closer together. U.S. Army colonel turned historian Robert Bateman summarizes it pointedly: “Once, every village had an idiot. It took the internet to bring them all together.”\n\nThanks to this combination of internet-accelerated homophily and confirmation bias, civil society can be torn into fragments. Each group comes to believe that only its members know the truth and that all others are ignorant or, even worse, evil. In fragile states, the situation can become untenable.",
    "meta": {
      "theme": "Social Dynamics & Disinformation",
      "region": "Global",
      "use_case": "Spread of Misinformation",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "homophily",
        "confirmation bias",
        "echo chambers",
        "anti-vaccine movement",
        "social media"
      ],
      "influence_map": [],
      "chunk_index": 73
    },
    "id": "likewar_073"
  },
  {
    "section": "Polarization and the Erosion of Facts",
    "text": "A 2016 study from George Washington University’s Institute for Public Diplomacy and Global Communication explored this phenomenon in the context of the Arab Spring..., helping to explain how these democratic uprisings were so quickly exploited by authoritarianism. ...\n\n...Although the main case study was Egypt, they could well have been describing the plight of any nation on earth.\n\nThe outcome is a cruel twenty-first-century twist on one of the classic quotes of the twentieth century. “Everyone is entitled to his own opinion, but not his own facts,” declared the legendary sociologist and New York senator Daniel Patrick Moynihan in a widely attributed axiom. ... In Moynihan’s time, such noble words rang true. Today, they’re a relic. Fact, after all, is a matter of consensus. Eliminate that consensus, and fact becomes a matter of opinion. Learn how to command and manipulate that opinion, and you are entitled to reshape the fabric of the world. As a Trump campaign spokesperson famously put it in 2016, “There’s no such thing, unfortunately, anymore as facts.” It was a preposterous claim, but in a certain way, it is true. And yet there’s another disturbing phenomenon at work. On social media, everyone may be entitled to their own facts, but rarely do they form their own opinions. There’s someone else manufacturing the beliefs that go viral online.",
    "meta": {
      "theme": "Information Warfare & Political Polarization",
      "region": "Global, with focus on Egypt & Arab Spring",
      "use_case": "Political Manipulation, Authoritarianism",
      "strategic_category": [
        "geopolitical_strategy",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "polarization",
        "Arab Spring",
        "social media manipulation",
        "erosion of facts",
        "information warfare"
      ],
      "influence_map": [],
      "chunk_index": 74
    },
    "id": "likewar_074"
  },
  {
    "section": "The Pizzagate Case Study: Super Spread of Lies",
    "text": "The families were just sitting down for lunch on December 4, 2016, when the man with the scraggly beard burst through the restaurant door. Seeing him carrying a Colt AR-15 assault rifle...\n\n...#Pizzagate shows how online virality—far from a measure of sincere popularity—is a force that can be manipulated and sustained by just a few influential social media accounts. In internet studies, this is known as “power law.” It tells us that, rather than a free-for-all among millions of people, the battle for attention is actually dominated by a handful of key nodes in the network. Whenever they click “share,” these “super",
    "meta": {
      "theme": "Disinformation Campaigns & Manipulation",
      "region": "United States",
      "use_case": "Political Manipulation, Conspiracy Theories",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "Pizzagate",
        "disinformation",
        "conspiracy theories",
        "social media manipulation",
        "power law"
      ],
      "influence_map": [],
      "chunk_index": 75
    },
    "id": "likewar_075"
  },
  {
    "section": "The Power of Super-Spreaders and the Toxicity of Conspiracy Theories",
    "text": "“Spreaders” wield significant influence online, directing the attention of vast portions of the internet. A study of Chinese Weibo users revealed that a small number of accounts guided the opinions of millions. This power often comes with a disregard for truth, as sensationalized information attracts more attention.  Episodes like #Pizzagate and figures like Posobiec exemplify this phenomenon.  Belief in one conspiracy theory increases susceptibility to others, creating an “HIV of online misinformation.”  This combination fuels extremism, racist attitudes, and even political violence. Studies show that false stories spread significantly faster and wider than true ones.  Social media amplifies the power and pervasiveness of lies and grand conspiracy theories, making them more potent weapons in the political arsenal.",
    "meta": {
      "theme": "Misinformation and Social Media",
      "region": "Global",
      "use_case": "Political Manipulation, Social Engineering",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "propaganda",
        "disinformation",
        "social media manipulation"
      ],
      "influence_map": [],
      "chunk_index": 76
    },
    "id": "likewar_076"
  },
  {
    "section": "The 2016 US Election: A Case Study in Online Disinformation",
    "text": "The 2016 U.S. presidential election unleashed an unprecedented flood of falsehoods.  Fake websites, populated with fabricated stories, proliferated, and fake news headlines were shared more frequently on Facebook than real ones.  A similar trend was observed on Twitter, with “junk news” lacking news value but infused with elements designed to make it irresistible, like “junk food.” This phenomenon confirmed the dangers of online information consumption, leading to the spread of content detrimental to individuals and society. The term “fake news,” initially used to describe verifiably untrue information, was co-opted and weaponized, transforming from an objective measure to a subjective opinion.",
    "meta": {
      "theme": "Misinformation and Elections",
      "region": "United States",
      "use_case": "Political Campaigns, Election Interference",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "propaganda",
        "disinformation",
        "election interference"
      ],
      "influence_map": [],
      "chunk_index": 77
    },
    "id": "likewar_077"
  },
  {
    "section": "The Rise of Hyperpartisan Platforms and the Blurring of Truth",
    "text": "Individuals like Posobiec and Coler profited from the fake news ecosystem. Coler, initially intending to expose right-wing gullibility, built a network of websites generating fabricated stories for profit.  The media environment surrounding these individuals became increasingly intertwined with partisan politics.  Research revealed that liberal and conservative news consumers existed in parallel universes online, driven by homophily and virality. The right-leaning social media universe coalesced around Breitbart, a hyperpartisan platform that embraced social media as a “weapon of war.” Breitbart became the platform for the alt-right, a movement rejecting democratic ideals and utilizing social media to promote its views.  This platform fostered a closed network of far-right platforms, creating an echo chamber that amplified misinformation and blurred the lines between truth and hateful disinformation.",
    "meta": {
      "theme": "Hyperpartisan Media and Disinformation",
      "region": "United States",
      "use_case": "Political Polarization, Ideological Warfare",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "propaganda",
        "disinformation",
        "political polarization"
      ],
      "influence_map": [],
      "chunk_index": 78
    },
    "id": "likewar_078"
  },
  {
    "section": "The Spread of Disinformation Beyond the 2016 Election",
    "text": "The phenomenon of online misinformation extended beyond the 2016 U.S. election, impacting elections in France, Germany, Spain, and Italy.  It also manifested in other contexts, such as the 2016 incident involving Pakistan and Israel, where a false online report nearly triggered a nuclear confrontation. This example highlighted the potential for online misinformation to escalate real-world tensions and conflicts. The trend of sharing without clicking further contributed to the spread of disinformation, becoming a form of political activism with a druglike effect on internet partisans.  Traditional media outlets followed suit, prioritizing sensationalism over policy discussions.  The spread of misinformation continued after the election, with attempts to create “Breitbart of the left” and the rise of new liberal rumor mills. The misinformation economy persisted, demonstrating its pervasive and enduring nature.",
    "meta": {
      "theme": "Global Impact of Disinformation",
      "region": "Global",
      "use_case": "International Relations, Political Instability",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "propaganda",
        "disinformation",
        "international conflicts"
      ],
      "influence_map": [],
      "chunk_index": 79
    },
    "id": "likewar_079"
  },
  {
    "id": "likewar_080",
    "section": "Part 1: The Unreality Machine and Global Impact",
    "text": "Rival armies of South Sudan’s president and vice president had settled into an uneasy truce after years of civil war. But when the vice president paid a visit to the presidential palace, his spokesperson published a false Facebook update that he had been arrested. Reading the post, the vice president’s men paid an angry (and heavily armed) visit to the palace to rescue him. The president’s bodyguards in turn opened fire — igniting a series of battles that would leave over 300 dead and plunge the nation back into conflict. Even after a cease-fire was declared by both sides, social media then fueled a new cycle of sectarian and ethnic violence, helped by a heavy dose of online hate speech and false accusations. The same echo chambers that have swung elections saw rival Sudanese Facebook groups allege nonexistent attacks that inspired extremists on both sides to commit real and deadly acts of revenge.\nA combination of viral falsehood and the “cyberbanging” problem escalated to nationwide conflict. What played out in South Sudan has been echoed around the world. In India, riots erupted in 2017 over fake stories pushed by the Indian equivalent of Breitbart. These prompted a new round of fake stories about the riots and their instigators, which reignited the real cycle of violence. That same year in Myanmar, a surge in Facebook rumormongering helped fuel genocide against the nation’s Rohingya Muslim minority. The following year in Sri Lanka, wild (and viral) allegations of a “sterilization” plot led a frenzied Buddhist mob to burn a Muslim man alive. “The germs are ours,” a Sri Lankan official explained of his country’s religious tensions, “but Facebook is the wind.”\nThe online plague of misinformation has even become a problem for some of the least sympathy-inducing groups in the world. In El Salvador, the MS-13 gang faced an unexpected crisis when false stories spread that it was murdering any woman who had dyed blond hair and wore leggings (the hair and leggings were a trademark look of the rival Los Chirizos gang). “We categorically deny the rumor that has been circulated,” read the gang’s official statement, itself posted online. The criminals solemnly denounced the stories that “only create alarm and increase fear and anxiety in the poor population that live in the city center.” Even the unrepentantly barbaric Islamic State had to deal with false headlines. When ISIS instituted its repressive, fundamentalist government after the seizure of Mosul, reports circulated that it would force genital mutilation on 4 million Iraqi women and girls. Subsequent news stories were shared tens of thousands of times. ISIS propagandists and supporters were aggrieved. Although they’d happily held public beheadings and reinstituted crucifixion as a form of punishment, female genital mutilation wasn’t their policy. An ISIS Twitter account, whose Arabic username translated to “Monster,” offered a terse rebuttal denouncing the fake news and demanding that the media retract its claims.",
    "meta": {
      "theme": "Misinformation and Social Media",
      "region": "Global",
      "use_case": "Impact of fake news on conflict and social unrest",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "misinformation",
        "social media",
        "conflict",
        "violence",
        "extremism",
        "propaganda"
      ],
      "influence_map": [],
      "chunk_index": 80
    }
  },
  {
    "section": "Botnet Manipulation in Politics",
    "text": "Although botnets have been used to market everything from dish soap to albums, they’re most common in the political arena. For authoritarian regimes around the world, botnets are powerful tools in their censorship and disinformation strategies. When Syria began to disintegrate into civil war in 2011, the Assad regime used Twitter bots to flood its opponents’ hashtags with random soccer statistics. Those searching for vital information to fight the regime were instead greeted with a wall of nonsense. At the same time, the #Syria news hashtag was flooded with beautiful landscape images. A year later, when international attention turned to the plight of Chinese-occupied Tibet, the Chinese government did the same. Thousands of bots hijacked hashtags like #FreeTibet, overpowering activists with random photographs and snippets of text.\n\nBotnets have proven just as appealing to the politicians and governments of democratic nations. Among the first documented uses was in 2010, when Massachusetts held a special election to fill the seat vacated by the late Senator Ted Kennedy.  Fake accounts across Facebook and Twitter trumpeted Brown’s name as often as possible, seeking to manipulate search results. Most novel was what was then called a “Twitterbomb.” Twitter users interested in the election began to receive automated replies supporting Brown. Importantly, these solicitations hit users beyond Massachusetts, greatly enriching Brown’s coffers. When Brown became the first Republican to win a Massachusetts Senate seat since 1952, political analysts were both floored and fascinated. Bots had enabled an election to be influenced from afar. They had also shown how one could create the appearance of grassroots support and turn it into reality, a tactic that became known as “astroturfing.” Botnets would become a part of every major election thereafter.\n\nWhen Newt Gingrich’s promise to build a moon base didn’t excite voters in the 2012 U.S. presidential primaries, his campaign reportedly bought more than a million fake followers, to try to create the sense of national support. In Italy, a comedian turned populist skyrocketed to prominence with the help of bot followers. The next year, a scandal hit South Korea when it was revealed that a massive botnet — operated by military cyberwarfare specialists — had transmitted nearly 25 million messages intended to keep the ruling party in power. Often, botnets can play the role of political mercenaries, readily throwing their support from one cause to the next. During Brexit, Britain’s contentious 2016 referendum to leave the European Union, researchers watched as automated Twitter accounts that had long championed Palestinian independence abruptly shifted their attention to British politics.",
    "meta": {
      "theme": "Political Manipulation and Disinformation",
      "region": "Global",
      "use_case": "Elections and Political Campaigns",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "botnets",
        "disinformation",
        "censorship",
        "political manipulation",
        "astroturfing"
      ],
      "influence_map": [],
      "chunk_index": 81
    },
    "id": "likewar_081"
  },
  {
    "section": "2016 US Presidential Election & Bot Manipulation",
    "text": "The 2016 U.S. presidential race, however, stands unrivaled in the extent of algorithmic manipulation. On Twitter alone, researchers discovered roughly 400,000 bot accounts that fought to sway the outcome of the race — two-thirds of them in favor of Donald Trump. Sometimes, these bots were content simply to chirp positive messages about their chosen candidate. Other times, they went on the offensive. Like the suppressive tactics of the Syrian regime, anti-Clinton botnets actively sought out and “colonized” pro-Clinton hashtags, flooding them with virulent political attacks. As Election Day approached, pro-Trump bots swelled in intensity and volume, overpowering pro-Clinton voices by (in another echo of Brexit) a five-to-one ratio. To an untrained eye, Trump’s bots could blend in seamlessly with real supporters. This included the eye of Trump himself. In just the first three months of 2016, the future president used his Twitter account to quote 150 bots extolling his cause — a practice he would continue in the White House.\n\nBehind this massive bot army lay a bizarre mix of campaign operatives, true believers, and some who just wanted to watch the world burn. The most infamous went by the online handle “MicroChip.”  When his machine was firing on all cylinders, MicroChip could produce more than 30,000 retweets in a single day, each of which could reach orders of magnitude more users. He took particular joy in using his army of fake accounts to disseminate lies, including #Pizzagate. “I can make whatever claims I want to make,” he bragged. “That’s how this game works.”\n\nWhere bots became truly weaponized, though, was in how they expanded the work of Russian sockpuppets prosecuting their “information war” from afar. In 2017, growing public and congressional pressure forced the social media firms to begin to reveal the Russian campaign that had unfolded on their platforms during the 2016 election. The numbers, once begrudgingly disclosed, were astounding. The bot accounts were putting the disinformation campaign on steroids, allowing it to reach a scale impossible with just humans at work. Overall, Facebook’s internal analysis estimated that 126 million users saw Russian disinformation on its platform during the 2016 campaign. The automated messaging was overwhelmingly pro-Trump.",
    "meta": {
      "theme": "Political Manipulation and Disinformation",
      "region": "United States, Russia",
      "use_case": "2016 US Presidential Election",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "botnets",
        "disinformation",
        "Russian interference",
        "social media manipulation"
      ],
      "influence_map": [],
      "chunk_index": 82
    },
    "id": "likewar_082"
  },
  {
    "section": "Impact of Bots on Language and Online Discourse",
    "text": "The effects of this industrial-scale manipulation continue to ripple across the American political system. Its success has also spawned a legion of copycat efforts in elections from France to Mexico, where one study found over a quarter of the posts on Facebook and Twitter about the 2018 Mexican election were created by bots and trolls. And yet this may not be the most unsettling part. These artificial voices managed to steer not just the topics of conversation, but also the human language within it, even changing the bounds of what ideas were considered acceptable.\n\nAfter the 2016 election, data scientists Jonathon Morgan and Kris Schaffer analyzed hundreds of thousands of messages spread across conservative Twitter accounts, Facebook pages, and the Breitbart comments section, charting the frequency of the 500,000 most-used words. They were shocked to find something sinister at work.  As Morgan and Schaffer wrote, “Tens of thousands of bots and hundreds of human-operated, fake accounts acted in concert to push a pro-Trump, nativist agenda across all three platforms in the spring of 2016.” When the researchers explored what else these accounts were pushing beyond pro-Trump or anti-Clinton messaging, their origin became clearer. The accounts that exhibited these repetitive language patterns were four times as likely to mention Russia, always in a defensive or complimentary tone. The analysis uncovered an even more disturbing pattern. April 2016 also saw a discernible spike in anti-Semitic language across all three platforms. This discovery carries implications that transcend any particular case or country. The way the internet affects its human users makes it hard enough for them to distinguish truth from falsehood. Yet these 4 billion flesh-and-blood netizens have now been joined by a vast number of digital beings, designed to distort and amplify, to confuse and distract. The attention economy may have been built by humans, but it is now ruled by algorithms — some with agendas all their own. Today, the ideas that shape battles, votes, and even our views of reality itself are propelled to prominence by this whirring combination of filter bubbles and homophily — an endless…",
    "meta": {
      "theme": "Impact of Bots on Language and Discourse",
      "region": "Global",
      "use_case": "Online Discourse and Public Opinion",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "bots",
        "language manipulation",
        "online discourse",
        "filter bubbles",
        "homophily"
      ],
      "influence_map": [],
      "chunk_index": 83
    },
    "id": "likewar_083"
  },
  {
    "section": "6. Win the Net, Win the Day: The New Wars for Attention...and Power",
    "text": "Media weapons [can] actually be more potent than atomic bombs. —Propaganda Handbook of the Islamic State\n\n“YOU CAN SIT AT HOME AND play Call of Duty or you can come here and respond to the real call of duty . . . the choice is yours.” It would be an unusual slogan for any army, much less the fanatical forces of the Islamic State. But Junaid Hussain was an unusual recruiter. As a stocky Pakistani boy raised in Britain, he was what one would call a nerd. But in the underground world of hackers, he was cool. “He had hacker cred,” one of his old acquaintances recalled. “He had swagger. He had fangirls.” But Hussain was also reckless—and he got caught. In 2012, at the age of 18, he was jailed for breaking into the emails of an assistant to former British prime minister Tony Blair. In prison, Hussain was transformed into a holy warrior. He became consumed with radical beliefs, and when his sentence was up, he fled to Syria, becoming an early volunteer for the jihadist group that would eventually become ISIS. He also took a new online handle, “Abu Hussain al-Britani,” and posted a new profile picture of himself cradling an AK-47. But the rifle was only a prop. The weapons that were far more valuable to ISIS were his good English, his swagger, and his easy familiarity with the internet. He helped organize the Islamic State’s nascent “Cyber Caliphate” hacking division, and he scoured Twitter for potential ISIS recruits.\n\nHussain’s online persona was infused with charm, pop culture, and righteous indignation. He persuaded hardened radicals and gullible teenagers alike to travel to Syria. It was a striking contrast to how Al Qaeda, the predecessor of ISIS, had bolstered its ranks. The original members of Al Qaeda had been personally known and vetted by bin Laden and his lieutenants. Indeed, the name “Al Qaeda,” translated as “the base,” had been taken from the name for the Afghan mountain camps where they’d all trained together. By contrast, some 30,000 recruits, urged on by Junaid Hussain and his team of recruiters, would travel from around the world to join a group that they’d never met in person. Hussain also reached out to people who pledged allegiance to the Islamic State but never left home. He recruited at least nine ISIS converts in the United States who would later be killed or arrested there. From thousands of miles away, Hussain served as a bizarre mix of leader, recruiter, and life coach. In one case, he directly organized a shooting at a Texas community center by two self-proclaimed “soldiers of the Caliphate.” “The knives have been sharpened,” Hussain bragged on Twitter scarcely an hour before the attack began. “Soon we will come to your streets with death and slaughter!”\n\nBecoming, in effect, a super-spreader of the terror virus, Hussain achieved celebrity status. He even took a wife—a British punk rock musician in her early 40s, whom he met online. However, his growing fame also made him infamous in U.S. military circles. By 2015, the 21-year-old Hussain had risen to become the third most important name on the Pentagon’s “kill list” of ISIS leaders, ranking only behind the group’s self-declared caliph and top battlefield commander. Ironically, it was Hussain’s nonstop internet use that enabled his execution. The hacker formerly known as “TriCk” was reportedly tricked into clicking a link that had been compromised by British intelligence. His web use allowed him to be geolocated and dispatched by a Hellfire missile fired by a drone. Working at an internet café late at night, Hussain had thought it safe to leave his stepson—whom he frequently used as a human shield—at home.",
    "meta": {
      "theme": "Terrorism and Propaganda in the Digital Age",
      "region": "Middle East, Global",
      "use_case": "Recruitment, Propaganda Dissemination, Information Warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "terrorism",
        "propaganda",
        "ISIS",
        "cyber warfare",
        "recruitment"
      ],
      "influence_map": [],
      "chunk_index": 84
    },
    "id": "likewar_084"
  },
  {
    "section": "Seventh-Century Cyber-Revolutionaries",
    "text": "In the case of Junaid Hussain can be seen the wider paradox of the Islamic State. When ISIS first seized global attention with its 2014 invasion of Mosul, many observers were flummoxed. The word of the day became “slick.” Indeed, terrorism analysts Jessica Stern and J. M. Berger found “slick” was used more than 5 million times online to describe the Islamic State’s well-doctored images and videos. How could a group of jihadists from a war-torn corner of the world be so adept at using all the tricks of modern viral marketing?\n\nThe answer was grounded in demography—and one made almost inevitable by social media’s wildfire spread. On the one hand, ISIS was a religious cult that subscribed to a medieval, apocalyptic interpretation of the Quran. It was led by a scholar with a PhD in Islamic theology, its units commanded by men who had been jihadists since the 1980s. But on the other hand, ISIS was largely composed of young millennials. Its tens of thousands of eager recruits, most drawn from Syria, Iraq, and Tunisia, had grown up with smartphones and Facebook. The result was a terrorist group with a seventh-century view of the world that, nonetheless, could only be understood as a creature of the new internet. “Terrorism is theater,” declared RAND Corporation analyst Brian Jenkins in a 1974 report that became one of terrorism’s foundational studies. Command enough attention and it didn’t matter how weak or strong you were: you could bend populations to your will and cow the most powerful adversaries into submission. This simple principle has guided terrorists for millennia. Whether in ancient town squares, in colonial wars, or via ISIS’s carefully edited beheadings, the goal has always been the same: to send a message.\n\nIf there was any great difference between the effectiveness of the Islamic State and that of terror groups past, it wasn’t in the brains of ISIS fighters; it was in the medium they were using. Mobile internet access could be found even in the remote deserts of Syria; smartphones were available in any bazaar. Advanced video and image editing tools were just one illegal download away, and an entire generation was well acquainted with their use. For those who weren’t, they could easily find free online classes offered by a group called Jihadi Design. It promised to take ISIS supporters “from zero to professionalism” in just a few sessions. Distributing a global message, meanwhile, was as easy as pressing “send,” with the dispersal facilitated by a network of super-spreaders beyond any one state’s control. This was the most dramatic change from terrorism past. Aboud Al-Zomor was one of the founders of the Egyptian Islamic Jihad terror group and a mastermind of the 1981 assassination of Egyptian president Anwar Sadat. Thirty years later, he wondered if—had social media had been around at the time—the entire plot might have been unnecessary. “With the old methods,” the aged killer explained, “it was difficult to gather so many people with so much force.” Back then, it took a dramatic, high-profile death to seize public attention. Now all you needed was YouTube. Viral marketing thus became the Islamic State’s greatest weapon.",
    "meta": {
      "theme": "The Role of Social Media in ISIS Propaganda and Recruitment",
      "region": "Middle East, Global",
      "use_case": "Propaganda, Recruitment, Information Warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "terrorism",
        "propaganda",
        "ISIS",
        "viral marketing",
        "information warfare"
      ],
      "influence_map": [],
      "chunk_index": 85
    },
    "id": "likewar_085"
  },
  {
    "section": "Win the Net, Win the Day",
    "text": "losses and greatly exaggerated its gains. Far from the battlefields of the Middle East, it could take credit for killings that it had nothing to do with — such as the 2017 Las Vegas shootings in the United States and a mass murder in the Philippines — simply by issuing a claim after the fact. Soon ISIS had so penetrated the popular imagination that any seemingly random act of violence across Europe or the United States brought the group immediately to mind. Daniel Benjamin, a former U.S. counterterrorism official, noted that mental health had ceased to factor into discussions of Muslims who committed violent crimes. “If there is a mass killing and there is a Muslim involved,” he concluded, “all of a sudden it is, by definition, terrorism.”\n\nBy successfully translating its seventh-century ideology into social media feeds, ISIS proved its finesse in what its supporters described as the “information jihad,” a battle for hearts and minds as critical as any waged over territory. It did so through a clear, consistent message and a global network of recruiters. It also did so through a steady rain of what it called media “projectiles,” online content intended to “shatter the morale of the enemy” (or sometimes simply to anger its critics). In the process, ISIS did more than establish a physical state; it also built an unassailable brand. “They have managed to make terrorism sexy,” declared a corporate branding expert, who likened ISIS to a modern-day Don Draper, the Kennedy-era adman of the TV series Mad Men.\n\nISIS’s legacy will live on long after the group has lost all its physical territory, because it was one of the first conflict actors to fuse warfare with the foundations of attention in the social media age. It mastered the key elements of narrative, emotion, authenticity, community, and inundation, each of which we’ll explore in turn. Importantly, none of these elements are unique to terrorism or the Middle East. Indeed, anyone — digital marketers, conspiracy theorists, internet celebrities, politicians, and national militaries — can employ them. Whatever or wherever the conflict, these are the weapons that win LikeWar.",
    "meta": {
      "theme": "Information Warfare",
      "region": "Global",
      "use_case": "Terrorist Propaganda",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "propaganda",
        "terrorism"
      ],
      "influence_map": [],
      "chunk_index": 86
    },
    "id": "likewar_086"
  },
  {
    "section": "NARRATIVE: SPIN A TALE",
    "text": "Spencer Pratt is Southern California personified: blond-haired and blue-eyed, a bro who speaks in bromides. But beneath his surfer-dude appearance, Spencer is also a keen student of people: how they act, how they think, and how to keep their attention. “I always wanted to work for the CIA growing up,” he explained. “I’d be a CIA operative in Hollywood that made movies to manipulate the masses.\n\n“But then,” he added with a laugh, “I became a reality star.” By his freshman year at USC, he’d figured out how to make $50,000 for a photo he’d taken of Mary-Kate Olsen. But what fascinated him back then in the early 2000s was the bizarre, emerging landscape of reality television. “I saw The Osbournes on MTV,” Spencer recalls. “I saw that they were getting 60 million viewers to watch — with due respect to Ozzy — a British guy mumbling and his wife yelling, cleaning up dog poop. I was like, ‘This is what reality television is? I could make one of these shows.’ ” And so he did.\n\nPratt became the creator and producer of The Princes of Malibu, an early reality show on Fox that followed two rich brothers who were notable only because of their celebrity father, Bruce (now Caitlyn) Jenner. The show fizzled after a few episodes, but not before unleashing the brothers’ stepfamily, the Kardashians, upon the world. As he faced the prospect of going back to college, Pratt had a better idea. He was telegenic, charming, and shameless. Why not try to be in one of those shows instead? The year was 2006, and MTV was in the midst of launching another reality-television saga, The Hills, about four young women trying to make it big in Beverly Hills. So Pratt sought out the venues where The Hills was filming. At a nightclub called Privilege, the intrepid hustler sat himself in a booth, surrounded by Playboy Playmates. This tableau caught the eye of Heidi Montag, The Hills blonde costar; she stole him away from the Playmates for a dance. They hit it off, and Spencer Pratt and Heidi Montag soon became “Speidi.”\n\nPratt had gotten on TV, but now he had to figure out how to stay there. So he gave the supposed reality show what it had lacked: a villain. In short order, The Hills’ storyline shifted to a seemingly psychopathic boyfriend and a woman who kept coming back to him. Each episode brought new shocks and new lows. He flirted with other women in front of Montag and gleefully scorned her family. He stoked rumors about a costar and a supposed sex tape, which was roundly condemned by the entertainment press, but which generated a season’s worth of fireworks as friendships exploded. Of course, the vast majority of it was fake, as most of the “reality” show was staged. Still, it worked and ratings soared.",
    "meta": {
      "theme": "Narrative Construction and Manipulation",
      "region": "United States",
      "use_case": "Reality Television",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos"
      ],
      "usage_tags": [
        "media manipulation",
        "attention economy",
        "celebrity culture"
      ],
      "influence_map": [],
      "chunk_index": 87
    },
    "id": "likewar_087"
  },
  {
    "section": "Narrative and Emotion in Social Media Warfare",
    "text": "The first rule of narrative is simplicity. A simple narrative is easy to understand (think of good versus evil, or us versus them) and (most important) easily shared. It is also influential, helping inspire the Sharknado franchise. The second rule of narrative is resonance. Nearly all effective narratives conform to what social scientists call “frames,” products of particular language and culture that feel instantly and deeply familiar. In the American experience, think of plotlines like “rebel without a cause” or “small-town kid trying to make it in the big city.” Some frames are so common and enduring that they might well be hardwired into our brains. […] These three traits — simplicity, resonance, and novelty — determine which narratives stick and which fall flat. It’s no coincidence that everyone from far-right political leaders to women’s rights activists to the Kardashian clan speaks constantly of “controlling the narrative.” To control the narrative is to dictate to an audience who the heroes and villains are; what is right and what is wrong; what’s real and what’s not.  […] And yet, as we’ll see, narrative isn’t the only factor that drives virality, nor are narratives forever fixed in place.",
    "meta": {
      "theme": "Social Media Warfare",
      "region": "Global",
      "use_case": "Information Warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "narrative warfare",
        "information operations",
        "social media manipulation"
      ],
      "influence_map": [],
      "chunk_index": 88
    },
    "id": "likewar_088"
  },
  {
    "section": "The Power of Emotion in Online Virality",
    "text": "“When we do not know, or when we do not know enough, we tend always to substitute emotions for thoughts.”  T. S. Eliot […] What captures the most attention on social media isn’t content that makes a profound argument or expands viewers’ intellectual horizons. Instead, it is content that stirs emotions. Amusement, shock, and outrage determine how quickly and how far a given piece of information will spread through a social network. […] But the bigger picture is grim. If attention is the thing that matters most online — and as we saw in the last chapter, it is — brazen self-promoters will go to any lengths to achieve it. Because anger is so effective at building and sustaining an audience, those who seek viral fame and power have every reason to court controversy and adopt the most extreme positions possible, gaining rewards by provoking fury in others.",
    "meta": {
      "theme": "Emotional Manipulation in Social Media",
      "region": "Global",
      "use_case": "Information Warfare, Political Campaigning",
      "strategic_category": [
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "emotional contagion",
        "virality",
        "online manipulation",
        "anger",
        "outrage"
      ],
      "influence_map": [],
      "chunk_index": 89
    },
    "id": "likewar_089"
  },
  {
    "section": "Trolling and the Weaponization of Anger",
    "text": "“Anger leads to hate; hate leads to suffering,” observed the wise Master Yoda. And that suffering leads to the Dark Side: what is better known on the internet as trolling. Although the word “troll” conjures images of beasts lurking under bridges and dates back to Scandinavian folklore, its modern internet use actually has its roots in the Vietnam War. […]  The modern version is perhaps best expressed by one of the internet’s better-known trolls, “Ironghazi,” who explained, “The key to being a good troll is being just stupid enough to be believable, keeping in mind that the ultimate goal is making people mad online.”  […] After people have trolled once, they’re twice as likely",
    "meta": {
      "theme": "Trolling and Online Harassment",
      "region": "Global",
      "use_case": "Information Warfare, Disinformation Campaigns",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "trolling",
        "online harassment",
        "disinformation",
        "anger",
        "manipulation"
      ],
      "influence_map": [],
      "chunk_index": 90
    },
    "id": "likewar_090"
  },
  {
    "section": "Trolling Contagion and Its Real-World Impact",
    "text": "There’s no doubt that trolling makes the internet a worse place. Trolling targets livelihoods and ruins lives. It silences voices and drives people into hiding, reserving special cruelty for women and racial minorities. Even those who escape the trolls’ ire must still contend with a digital environment that amplifies outrage and effectively mutes everything else. The power of trolls — which really represents the power of anger — transforms the internet into a caustic, toxic swamp. But the worst online trolling doesn’t necessarily stay online. Think back to the online battles of American street gangs — their “cybertagging” and “Facebook drilling” — or the deliberate antagonism of people from one government or ethnic group against another. These angry flame wars are trolling by another name, intended to grab attention and stir outrage. Such trolling too often ends in real-life violence and tragedy. Or it can yield political power. Whether the case is swaggering street-fighters or the everyday people who revel in harassing someone after a tweet falls flat, anger is the force that binds them together. Anger is exciting. Anger is addictive. Indeed, in a digital environment suffused with liars and fakes, anger feels raw and real in a way that so many other things never do. This authenticity carries an additional power of its own.",
    "meta": {
      "theme": "The negative impact of online trolling",
      "region": "Global",
      "use_case": "Understanding online behavior and its consequences",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "internet culture",
        "social media",
        "cyberbullying",
        "online harassment",
        "political polarization"
      ],
      "influence_map": [],
      "chunk_index": 91
    },
    "id": "likewar_091"
  },
  {
    "section": "Taylor Swift's Authentic Performance and Brand Building",
    "text": "Taylor Swift’s Instagram comments fell with the power of precision air strikes. “You have the prettiest, wildest, most child like eyes,” the superstar wrote to a young fan dealing with boy troubles. “Feel good about being the kind of person who loves selflessly. I think someday you’ll find someone who loves you in that exact way.” And to another, a 16-year-old fan who’d just gotten her driver’s license: “YES! You passed!!!!!!!! So stoked for you. ‘Don’t text and drive’ is an obvious piece of advice but people usually forget to tell you 1) don’t eat and drive 2) don’t apply mascara and drive 3) never let a small animal such as a cat roam free in your car. I’m not saying any of this from personal experience. I repeat. None of that happened to me.” Comments like these felt real because they were real. It really was Taylor Swift scrolling through her Instagram feed, learning about the lives of her fans, and tapping out thoughtful comments. She even coined her own hashtag to describe this practice: #Taylurking. It also was a strategy designed around Swift’s intuitive grasp of how social media had changed the cultural landscape. Reflecting on her first record-label meetings, Swift explained how she’d wowed the stodgy music executives by “explaining to them that I had been communicating directly with my fans on this new site called Myspace.” She added, “In the future, artists will get record deals because they have fans — not the other way around.” By recognizing this change, Swift transformed from a young millennial with a smartphone and a great voice into the ruler of a billion-dollar music empire, empowered by millions of “Swifties,” her army of fervent online fans (a name she strategically copyrighted). She sold 40 million albums, shattered digital streaming records, and, at 26 years old, was named the youngest of Forbes magazine’s wealthiest self-made women. Was her virtual authenticity all an act? It was certainly true that Swift penned her Instagram missives with the knowledge that anyone could read them. All those “candid” shots of her celebrity-stuffed parties weren’t very candid at all. And whenever Swift fell into a feud that stirred anger online, it was cleverly folded into the marketing for her next album. “Asking whether or not Taylor Swift is genuine is like asking if Kylie Jenner’s had plastic surgery, or if Calvin Harris is a real musician,” mused entertainment reporter Amy Zimmerman. “There’s no simple answer out there — just a whole lot of conflicting opinions.” Yet Swift’s online success also showed that question didn’t matter. “Authenticity” was becoming as dual in meaning as “fact” or “reality.” It really was her dropping in on a World War II veteran (and Swift superfan) for an impromptu concert or sending out random Christmas gifts with sweet, handwritten notes. But it was also true that each of these actions fed and expanded her juggernaut brand. Swift had married her fame to a sense of intimacy and openness, to a cascade of endless surprises. As she explained, “I think forming a bond with fans in the future will come in the form of constantly providing them with the element of surprise. No, I did not say ‘shock’; I said ‘surprise.’ I believe couples can stay in love for decades if they just continue to surprise each other, so why can’t this love affair exist between an artist and their fans?” Swift hadn’t built a fake life; she’d built a performative one. She could approach her fans on their level, and fit the perception of her life into theirs, by uploading a post that spotlighted what made her most relatable: fun with friends, thoughts on the nature of love, and lots of cat pictures. In so doing, Swift harnessed the power of online authenticity and cemented her fame. She also cleared a path toward viral success that today’s enterprising marketers — celebrities, corporations, politicians, livestreamers, and terrorists — all seek to follow.",
    "meta": {
      "theme": "The power of online authenticity in building a brand",
      "region": "Global",
      "use_case": "Marketing and public relations",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [
        "development_models"
      ],
      "civilizational_category": [
        "cultural_ethos"
      ],
      "usage_tags": [
        "social media marketing",
        "celebrity branding",
        "fan engagement",
        "online persona",
        "viral marketing"
      ],
      "influence_map": [],
      "chunk_index": 92
    },
    "id": "likewar_092"
  },
  {
    "section": "Authenticity, Community, and Extremist Groups",
    "text": "Achieving a sense of authenticity has become an important milestone for any online operation. In bland corporate jargon, this is called “brand engagement” — extending an organization’s reach by building a facsimile of a relationship between an impersonal brand and its followers. The Islamic State, for instance, expanded its influence not just through propagandists like Junaid Hussain, but through a general sense of authenticity — a feeling that the terrorist group was somehow more “real” than its rival militant organizations. ISIS fighters proved this by living their lives online, posting images not just of their battles but also of their birthday parties and (naturally) their cats. Like Taylor Swift’s clever marketing, ISIS’s professionally choreographed videos were complemented by chaotic, seemingly candid footage — albeit taken from Syrian battlefields instead of celebrity-studded Fourth of July parties. And like Swift’s strategy, this mix of carefully curated media promotion and surprisingly roughshod moments eventually merged, becoming part of the same identity. These qualities lay at the heart of ISIS’s success in online recruiting. Its fighters would talk up the glory of the caliphate but also muse about their sadness over the death of the actor Robin Williams and their childhood love of his character in the movie Jumanji. This authenticity won and inspired followers in a way that government press releases could not. Plenty of radicalized Westerners, pulled back from the brink of recruitment, described online relationships that unspooled over weeks or months. In time, the jihadists living on the other side of the world seemed less like recruiters than friends. Where this internet-age authenticity has proven most crucial, however, is in electoral politics. Since their very invention in ancient Greece, democracies have been guided by a special class of people discussed in Aristotle’s Politika: politicians, people who seek to rise above their fellow citizens and to lead them. But this created an enduring paradox of democracy. To gain power over their peers, politicians have often had to make themselves seem like their peers. In the United States especially — a nation whose aversion to a noble class is written into its Constitution — the politician who seems most down-to-earth has long carried the day. The irony, of course, is that most people who run for political office aren’t very relatable at all. They’re quite often rich, elitist, and sheltered from voters’ daily problems. As a result, American politics has long been a tug-of-war over who seems most authentic. In the nineteenth century, even the wealthiest candidates published newspaper biographies that played up their humble farmer’s roots. The twentieth century saw the birth of “photo ops” — first painfully staged photographs, then even more painfully staged televised campaign stops, taking place in a seemingly limitless number of Iowa diners. With the rise of social media, however, the fight to be real turned to what it meant to be real online. When Trump first stormed into the 2016 U.S. presidential race, few political analysts took his run seriously. He broke all the cardinal rules of American politics: he didn’t try to be an “everyman”; he bragged about being rich; he violated every social taboo he could find; he made outlandish statements; and he never, ever apologized. As “expert” analysts shook their heads in disgust, however, millions of American voters perked up and paid attention. This was a politician who was well and truly authentic. At the heart of Trump’s authenticity was his Twitter account. Clearly his own creature, it was unpredictable and hyperbolic and full of id.",
    "meta": {
      "theme": "Authenticity in online operations and political campaigns",
      "region": "Global / United States",
      "use_case": "Political analysis and understanding online radicalization",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "online radicalization",
        "terrorism",
        "political campaigns",
        "social media",
        "authenticity",
        "brand engagement"
      ],
      "influence_map": [],
      "chunk_index": 93
    },
    "id": "likewar_093"
  },
  {
    "section": "The Power of Online Community and Extremist Groups",
    "text": "Internet-age authenticity doesn’t just empower an idea or person. It also draws us into contact with others who think and act as we do. “In the end, what people want is to be united in something bigger than them . . . a sense of belonging,” explained a 43-year-old Canadian postal worker when asked why he’d joined a close-knit, 50,000-person Facebook group called La Meute. After all, Facebook’s very mission statement is to “bring the world closer together.” But this meeting of the minds illustrated a larger problem: La Meute (The Pack) was an ultra-right-wing extremist group based in Canada and dedicated to fighting Islam and immigrants via paramilitary tactics and hate speech. It was exactly the sort of “interactive community” once prophesied by Licklider and Taylor back in 1968 — except that it was one bonded by hate. The term “community” connotes a group with shared interests and identities that, importantly, make them distinct from the wider world. In the past, a community resided in a specific location. Now it can be created online, including (and perhaps especially) among those who find a common sense of fellowship in the worst kinds of shared identities that exclude others. As it has with so many other movements, social media has revolutionized white nationalist, white supremacist, and neo-Nazi groups, spiking their membership and allowing their views to move back into mainstream discourse. In the United States, the number of Twitter followers of such groups ballooned 600 percent between 2012 and 2016, and the Southern Poverty Law Center now tracks some 1,600 far-right extremist groups. Through the web, these groups can link up globally, American neo-Nazis connecting with Hungarian anti-Semites and British fascists. As these extremists have banded together, they have carved out online spaces where they are encouraged and empowered to “be themselves.” They have found warmth and joy in each other’s company, even as they advocate for the forced deportation of those whose skin color or religion is different from their own. Beyond hatred of immigrants and Muslims, they have few consistent positions. But hate is enough to draw these communities together and propel some of their members toward lethal violence. In the United States alone, from 2014 to the end of 2017 fifty people were killed and another eighty-two injured by young white men fueled by alt-right ideology and white nationalist social media. Ironically, in their aggressive recruiting, inspiration of lone wolf killers, and effective use of authenticity to build a community, these far-right extremists resemble nothing so much as the Islamic State. In northern Europe, the mothers of children who ran away to join the Islamic State recalled how their sons and daughters — reckoning with the social isolation that faces the offspring of many Middle Eastern migrants — looked to ISIS to fill the void. A lonely girl in Washington State — a volunteer Sunday school teacher and part-time babysitter — described how ISIS recruiters gave her the attentive friends she’d always craved. (Only a sharp-eyed grandmother stopped her from boarding a plane to Syria.) ISIS promised adventure and a sense of belonging. “It’s a closed community — almost a clique,” explained terrorism analyst Seamus Hughes. “They share memes and inside jokes, terms and phrases you’d only know if you were a follower.” In each case, recruits to extremist causes are lured by a warmth and camaraderie that seems lacking in their own lonely lives. In each case, such recruits build communities that attract people from across the globe.",
    "meta": {
      "theme": "Online communities and extremist groups",
      "region": "Global/ North America / Europe",
      "use_case": "Understanding online radicalization and community formation",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "online communities",
        "extremism",
        "radicalization",
        "social media",
        "hate speech",
        "terrorism"
      ],
      "influence_map": [],
      "chunk_index": 94
    },
    "id": "likewar_094"
  },
  {
    "section": "Part 1: Isolation and Radicalization",
    "text": "world but that show almost no diversity of thought. “Isolation may be the beginning of terror,” political theorist Hannah Arendt wrote in a 1953 essay about the origins of totalitarianism. “It certainly is its most fertile ground.” If people come to believe that their radical notions are unassailably true—and if they believe that only other people who share the same opinions are “real” or worth protecting—they open the door to violence and bloodshed. Not by coincidence, the field of study that seeks to counter this process of radicalization, known as countering violent extremism (CVE), also focuses on the powers of community-building.\n\nFarah Pandith is a pioneer of this field. Born in the restive Kashmir region of India, Pandith moved to Massachusetts as a young girl. Two moments changed the trajectory of her life. One took place at Smith College, where as a student in 1989 Pandith gave a speech attended by school alumnae, including Barbara Bush. The First Lady was impressed and soon became her pen pal. The other occurred a few years later, back in her birthplace of Srinagar, Kashmir. One family member, who was working to bring peace to the region, was assassinated by extremists. Then, the very same day, another died in violence that broke out during the funeral procession. Pandith’s life became guided by a simple question: How could she prevent such tragedy from happening to others?\n\nWith the help of her new friend in the White House, Pandith joined the U.S. government. Over the next two decades, she served in various roles in both Republican and Democratic administrations, eventually being appointed the first-ever U.S. special representative to Muslim communities. In this position, established to engage in the post-9/11 “battle of ideas,” Pandith traveled to eighty countries and met with thousands of young, disaffected Muslims in places ranging from the slums of Düsseldorf to the mosques of Mali. She foresaw a crisis of identity that would soon sweep the Middle East, culminating in the rise of ISIS. But she also saw something else. “Only peer-to-peer relations can change minds,” she concluded. The only way to prevent radicalization was to assemble a crowd of authentic voices to fight back.",
    "meta": {
      "theme": "Countering Violent Extremism",
      "region": "Global",
      "use_case": "Combating Terrorism",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "radicalization",
        "community building",
        "social media",
        "CVE"
      ],
      "influence_map": [],
      "chunk_index": 95
    },
    "id": "likewar_095"
  },
  {
    "section": "Part 2: Winning the Net",
    "text": "Pandith determined that social media would be the key battleground in this fight. She became one of the first high-level U.S. officials to use Facebook in her work. She learned that it was not just a megaphone but also a means to keep her connected to the youth she met around the world, and, even more important, to connect them with each other. “Because I was fully focusing on millennials, I needed to be able to show them in real time what I was hearing from others,” she explained. “I wanted to connect the kid I met in Germany with a kid in Australia. The conversation I was having in Mauritania with the cool thing in the Pamir mountains [of Tajikistan] that they were doing.” Each could become an ally to the other—and part of a broad collective to push back against the specter of extremism.\n\nFrustrated by a bureaucracy that couldn’t get out of its own way and realizing that a teenager’s heart and mind are places where “no government is credible,” Pandith has since left government. But she hasn’t quit the fight. Instead, she has worked to assemble groups around the world into a CVE version of what she has dubbed a “Dumbledore’s Army.” The name is taken from the Harry Potter series, in which a group of teens mobilize to fight evil. In recent years, a number of these sorts of CVE organizations have arisen. There’s the Online Civil Courage Initiative, which links more than a hundred anti-hate organizations across Europe, and Gen Next, which seeks to “deprogram” former jihadists. There’s even Creative Minds for Social Good, which has enlisted Middle East YouTube and Instagram stars to visit mosques and churches, sharing interfaith exchanges with their millions of followers. As Pandith explained, the community is seeking to empower those who know best how to speak to youth: their peers. They can “swarm the content of the extremists online with credible voices that will diminish their standing and showcase a whole host of alternative narratives.” For instance, if a 16-year-old girl “is getting more and more interested in what’s happening with the ‘superhero’ guy who’s fighting for [ISIS], in real time she’ll see her peers push back, ‘That’s dumb. That’s stupid. That doesn’t make sense.’ ”\n\nThis community-building has hardly erased the specter of terrorism. But it represents a far more personal and effective approach than staid government broadcasts and press releases. It is also just one example of a new kind of conflict fought largely with bite-sized social media broadcasts, what communications scholar Haroon Ullah has described as “digital world war.” Whether it is politicians or pop stars, hate groups or those that tell haters to “shake it off,” the new winners are those who have mastered the power of narrative and primed their audiences with emotion, who have fostered a sense of authenticity and engaged in the community-building that goes with it. But they have another trick up their sleeve. Not only do they do it all on a massive scale—they do it again and again and again at the most personal level.",
    "meta": {
      "theme": "Digital Influence and Counter-Narrative",
      "region": "Global",
      "use_case": "Combating Terrorism and Online Radicalization",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "CVE",
        "online narratives",
        "digital influence",
        "peer-to-peer"
      ],
      "influence_map": [],
      "chunk_index": 96
    },
    "id": "likewar_096"
  },
  {
    "section": "Part 3: Trump's Digital Army",
    "text": "INUNDATION: DROWN THE WEB, RUN THE WORLD\nIt was the biggest surprise in internet history. One data scientist found that in the twenty-four hours that followed Donald Trump’s election night win of November 8, 2016, the word “fuck” appeared nearly 8 million times on Twitter. Trump’s victory was just as much of a shock to the political system. As the writer Jason Pargin observed, “Trump ran against the most well-funded, well-organized political machine in the history of national politics . . . All of the systems that are supposed to make sure one side wins failed. He smashed a billion-dollar political machine to pieces.”\n\nAnd yet in retrospect, perhaps it shouldn’t have been all that surprising, for it was evident at the time that Trump had put to better use the new machine that had already smashed communications and the economy. Indeed, by almost any social media measure, Trump didn’t just have more online power than both his Republican and Democratic opponents; he was a literal superpower. He had by far the most social media followers, effectively as many as all his Republican rivals for the GOP nomination combined. He deployed this network to scale, pushing out the most messages, on the most platforms, to the most people. Importantly, Trump’s larger follower pool was made up of not just real-world voters, but—as we’ve discussed previously—a cavalcade of bots and sockpuppet accounts from around the world that amplified his every message and consequently expanded his base of support. With his Twitter loudspeaker, Trump could drive the national conversation at a pace and volume that left both journalists and his opponents scrambling to keep up. It allowed him not just to dominate the web-borne portion of the 2016 election, but to dominate all other forms of media through it, thus capturing $5 billion worth of “free” media coverage (nearly twice that of Clinton). As Republican communications strategist Kevin Madden explained, “Trump understands one important dynamic: In a world where there is a wealth of information, there is always a poverty of attention, and he has this ability to generate four or five story lines a day . . . He is always in control.” In an interview shortly after the election, Trump reflected on how he had won. “I think that social media has more power than the money they spent, and I think . . . I proved that.”\n\nBut Trump’s power lay not just in @realDonaldTrump but in the wider online army mobilized behind it. In his quest for the White House, Trump attracted the regular coalition of evangelical conservatives and traditional Republican partisans. But his crucial, deciding force was a new group: a cohort of mostly tech-savvy angry, young, white men who inhabited the deepest bowels of internet culture. While many had gotten their start on 4chan, a notorious image board where anonymous users fight an endless battle of profane one-upmanship, the group is better understood through what is known as “Poe’s Law.” This is an internet adage that emerged from troll-infested arguments on the website Christian Forums. The law states, “Without a winking smiley or other blatant display of humor, it is utterly impossible to parody a [fundamentalist] in such a way that someone won’t mistake it for the genuine article.” In other words, there is a point at which the most sincere profession of faith becomes indistinguishable from a parody; where a simple, stupid statement might actually be considered an act of profound meta-irony. Taken to its logical conclusion, Poe’s Law could lead to a place of profound nihilism, where nothing matters and everything is a joke. And this was exactly where many of these internet denizens took it. From the beginning, many of these lifelong trolls found something to admire in Trump.",
    "meta": {
      "theme": "Political Communication and Disinformation",
      "region": "United States",
      "use_case": "Election Campaigning",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "disinformation",
        "political campaigns",
        "online trolls",
        "bots"
      ],
      "influence_map": [],
      "chunk_index": 97
    },
    "id": "likewar_097"
  },
  {
    "section": "Campaign Strategy",
    "text": "Brad Parscale, a former web designer, spearheaded Trump's 2016 digital campaign, which was unprecedented in scale.  Central to this was Project Alamo, leveraging a massive database encompassing donor information, RNC data, and data from Cambridge Analytica. This controversial firm, linked to Steve Bannon, provided extensive data points on American voters, some controversially obtained from Facebook.  This data, combined with psychometric analysis, allowed for micro-targeting of voters and tailoring messages based on psychological profiles.  The campaign ran millions of ad variations, constantly experimenting and refining messaging based on real-time feedback. This data-driven approach informed campaign decisions, from travel to rally topics.",
    "meta": {
      "theme": "Digital Campaigning",
      "region": "United States",
      "use_case": "Election Campaign",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "big data",
        "psychometrics",
        "micro-targeting",
        "social media",
        "data analytics"
      ],
      "influence_map": [],
      "chunk_index": 98
    },
    "id": "likewar_098"
  },
  {
    "section": "BuzzFeed Model and Scaled Messaging",
    "text": "The Trump campaign's digital strategy drew parallels to BuzzFeed's approach to content creation. BuzzFeed's success relied on generating vast amounts of content and using real-time data to optimize its reach.  This model, focused on scale and experimentation, mirrored the Trump campaign's approach to online advertising and resonated with how Russian propagandists and ISIS employed similar tactics on social media. The key takeaway was the power of inundation, coupled with tailored messaging, to achieve widespread influence. This fusion of narrative, emotion, authenticity, community, and inundation was crucial for online success, whether in minor disputes or significant political battles.",
    "meta": {
      "theme": "Online Influence and Propaganda",
      "region": "Global",
      "use_case": "Information Warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "viral marketing",
        "content creation",
        "propaganda",
        "information warfare",
        "social media manipulation"
      ],
      "influence_map": [],
      "chunk_index": 99
    },
    "id": "likewar_099"
  },
  {
    "section": "The Changing Landscape of Conflict",
    "text": "The internet has fundamentally altered communication between nations and individuals.  Early internet researchers, like Arquilla and Ronfeldt, predicted the rise of 'cyberwar' and 'netwar,' where information becomes a strategic weapon. They foresaw conflicts being fought not just with physical force, but through the manipulation of information online.  This shift was exemplified in World War I, where control over transatlantic cables allowed Britain to shape the narrative about Germany in the United States, influencing public opinion and ultimately America's entry into the war. The internet, however, democratized access to information, creating a new battlespace where anyone can leverage these tactics.",
    "meta": {
      "theme": "Information Warfare and the Internet",
      "region": "Global",
      "use_case": "International Relations, Warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "cyberwar",
        "netwar",
        "information control",
        "propaganda",
        "international relations"
      ],
      "influence_map": [],
      "chunk_index": 100
    },
    "id": "likewar_100"
  },
  {
    "section": "Part 1: The Rise of Netwar and Weaponized Information",
    "text": "By the late 1990s, the “weaponization” of online information was essentially a dead topic. Instead, early netwar became the province of far-left activists and democratic protesters, beginning with the 1994 Zapatista uprising in Mexico and culminating in the 2011 Arab Spring. In time, terrorists and far-right extremists also began to gravitate toward netwar tactics.  Arquilla and Ronfeldt, still at work tracking conflict trends, began to liken what had happened to the Roman deity Janus, the two-faced god of beginnings and endings (as well as war and peace). There was no exact moment when the balance shifted. For disenchanted activists like the Belarusian Evgeny Morozov, it came when dictators learned to use the internet to strengthen their regimes. For us, the moment came when we saw how ISIS militants used the internet not just to sow terror across the globe, but to win its battles in the field. For Putin’s government, it came when the Russian military reorganized itself to strike back against what it perceived as a Western information offensive. For many in American politics and Silicon Valley, it came when that same Russian effort poisoned their networks with a flood of disinformation, bots, and hate.\nToday, online battles are no longer just the stuff of science fiction or wonky think tank reports, but an integral part of global conflict. As a result, governments around the world have begun to adapt to it. Russia is the most obvious example ​— ​a government whose state media, troll factories, and botnets all conspire to wage (in the words of its own military doctrine) “global information warfare.” Echoing the language of ISIS propagandists, Russian military strategists describe how a strong information offensive can have a strategic impact on a par with the release of an atomic bomb.",
    "meta": {
      "theme": "Netwar and Information Warfare",
      "region": "Global",
      "use_case": "Military and Political Conflict",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "information warfare",
        "propaganda",
        "disinformation",
        "netwar"
      ],
      "influence_map": [],
      "chunk_index": 101
    },
    "id": "likewar_101"
  },
  {
    "section": "Part 2: Global Adoption of Netwar Tactics",
    "text": "They warn of the power of foreign information to “blur the traditional Russian spiritual and moral values,” and argue instead for “a system of spiritual and patriotic education” (aka censorship) and the development of “informational . . . measures aiming to pre-empt or reduce the threat of destructive actions from an attacking state.” In this line of reasoning, the Russian government doesn’t resort to netwar because it wants to. Rather, it sees no other choice. The best defense, after all, is a good offense. China’s Great Firewall, social engineering, and online armies of positivity can be seen in much the same light. But one shouldn’t think that there isn’t an offensive side. Since 2003, the Chinese military has followed an information policy built on the “three warfares”: psychological warfare (manipulation of perception and beliefs), legal warfare (manipulation of treaties and international law), and public opinion warfare (manipulation of both Chinese and foreign populations). Where China is strong, its strengths must be amplified even further in the public imagination; where China is weak, attention must be diverted. China must be seen as a peaceful nation, bullied by powerful adversaries and “reluctantly” responding by building its armies and laying claim to new lands. China’s critics must be confused and scattered, even as its own people are forged into a singular, iron will. In 2015, China’s official military strategy would put the challenge even more starkly: “War is accelerating its evolution to informatization.”\nEven the United States, birthplace of the free and open internet, has started to accept netwar as a matter of policy. In 2011, DARPA’s research division, which once created the internet itself, launched the new Social Media in Strategic Communications program to study online sentiment analysis and manipulation.",
    "meta": {
      "theme": "Netwar and Information Warfare",
      "region": "Global (Focus on Russia, China, and US)",
      "use_case": "Military and Political Conflict",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "information warfare",
        "censorship",
        "psychological warfare",
        "three warfares"
      ],
      "influence_map": [],
      "chunk_index": 102
    },
    "id": "likewar_102"
  },
  {
    "section": "Part 3: The Blurring Lines of War and Politics",
    "text": "Around the same time, the U.S. military’s Central Command began overseeing Operation Earnest Voice, a several-hundred-million-dollar effort to fight jihadists across the Middle East by distorting Arabic social media conversations. One part of this initiative was the development of an “online persona management service” ​— ​essentially sockpuppet software ​— ​“to allow one U.S. serviceman or woman to control up to 10 separate identities based all over the world.” And, beginning in 2014, the U.S. State Department poured vast amounts of resources into CVE efforts, building an array of online organizations that sought to counter ISIS by launching information offensives of their own. The initiatives have begun to spread through governments around the world. In 2015, Britain formed the 1,500-soldier-strong 77th Brigade, intended to be an “agent of change through targeted Information Activity and Outreach.” The NATO alliance launched its Strategic Communications Centre of Excellence, focused specifically on “the weaponization of social media.” Add to this the impressive digital arm of the Israeli Defense Forces (IDF), Turkey’s growing patriotic troll army, the burgeoning botnets of the Mexican government, and the cyber-propaganda initiatives of dozens of other countries.\nBut there’s a second revolution at work ​— ​even stranger and more pressing than the one foreseen by Arquilla and Ronfeldt. As national militaries have reoriented themselves to fight global information conflicts, the domestic politics of these countries have also morphed to resemble netwars. And the two spheres have become linked. Just as rival states and conflict actors use the internet to manipulate and deceive, so, too, do political candidates and activists of all stripes. Online, there’s little difference in the information tactics required to “win” either a violent conflict or a peaceful campaign. Often, their battles are not just indistinguishable in their form but also directly linked in their activities (such as the alignment of Russian sockpuppets and alt-right activists). The realms of war and politics have begun to merge. In essence, every LikeWar is a battle for attention with a specific objective in mind (promoting a candidate; gaining concessions; winning a war) and challenged by an opponent (other people, groups, or nations). Victory requires an appreciation of the nature of virality and the whimsical ways of the attention economy, as well as a talent for conveying narrative, emotion, and authenticity, melded with community-building and a ceaseless supply of content (inundation). And because it all takes place on the open internet, each of these conflicts becomes a global tug-of-war with an unknown number of players. The world of LikeWar can feel inescapable and overwhelming. Yet, in seeking to explain how its battles work, there is perhaps no one better for the task than a big-eyed, big-lipped amphibian, who looks like he’s stepped right out of the hellscape of Microsoft Paint.",
    "meta": {
      "theme": "The Intersection of Netwar, Politics, and Memes",
      "region": "Global",
      "use_case": "Political Campaigns and Information Warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "information warfare",
        "political campaigns",
        "social media manipulation",
        "memes"
      ],
      "influence_map": [],
      "chunk_index": 103
    },
    "id": "likewar_103"
  },
  {
    "section": "Part 4: Pepe the Frog and Memetic Warfare",
    "text": "MEMES AND MEMETIC WARFARE\nTo his critics, he was a blazing symbol of hatred and bigotry. To his supporters, he was both a joke and a badge of honor. To the artist who created him, he was just a “chilled-out [dude] who likes to eat snacks and talk on the phone [and] smoke weed.” He wore everything from a blue shirt to a baggy suit to hot-pink lingerie. He was thin or fat; sad or smug or angry. Sometimes, he looked like Donald Trump; other times, Vladimir Putin, the rapper Nicki Minaj, or even Adolf Hitler. But three things about him were always the same:\n1. He was green.\n2. His name was Pepe the Frog.\n3. He was a dumb internet meme.\nIf you spent any time on the internet, you couldn’t not see him. Soon enough, you wanted to unsee him. In 2015, Pepe was adopted as the banner of Trump’s vociferous online army. By 2016, he’d also become the symbol of a resurgent tide of white nationalism, declared a hate symbol by the Anti-Defamation League. Trump tweeted a picture of himself as an anthropomorphized Pepe. By 2017, Pepe was ascendant. Trump supporters launched a crowdfunding campaign to erect a Pepe billboard “somewhere in the American Midwest.” On Twitter, Russia’s UK embassy used a smug Pepe to taunt the British government in the midst of a diplomatic spat (“No trust in Britain’s best friend and ally?”). But . . . why? It made little sense that a cartoon frog had become a standard-bearer for a white ethno-state, or a campaign symbol or tool of international diplomacy. But it was never about the frog. Instead, Pepe was the product of an evolutionary cycle that moved at digital warp speed on the internet, piling meaning atop meaning until everyone lost track. Pepe was also the product of a conflict of reinvention and appropriation that twisted him in directions that no one might have expected. In understanding Pepe, one can understand memes, and through them the life cycle of ideas on the internet. Pepe the Frog was born in 2005 to the San Francisco–based artist Matt Furie.",
    "meta": {
      "theme": "Memes and Memetic Warfare",
      "region": "Primarily US, with international implications",
      "use_case": "Political Campaigns and Online Culture Wars",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "memes",
        "memetic warfare",
        "online culture",
        "political symbolism",
        "propaganda"
      ],
      "influence_map": [],
      "chunk_index": 104
    },
    "id": "likewar_104"
  },
  {
    "section": "Part 5: Pepe's Evolution and Impact",
    "text": "One of four teenage monsters in Furie’s Boy’s Club comic series, Pepe was just a cartoon layabout who spent his days “drinkin’, stinkin’, and never thinkin’. ” In 2008, an anonymous 4chan user shared a panel in which Pepe pulled his pants down to his ankles to urinate in a public bathroom, along with his shameless explanation for doing so: “Feels good man.” Pepe’s simplicity and irreverence perfectly captured the spirit of the freewheeling, profane 4chan community. He went viral among internet forum users and ​— ​more impressively ​— ​surpassed virality to become part of the underlying culture of the internet. When the original meme seemed exhausted, users mined Furie’s comics for more drawings. When the comics ran out, users began to make their own. In a sense, Pepe became the ideal online phenomenon ​— ​popular and endlessly adaptable, while remaining too weird and unattractive to ever go fully mainstream. With these attributes, it was not much of a shock when Pepe became the unofficial mascot of 4chan’s /pol/ politics board. When these trolls went to battle for Trump, they took Pepe with them. What began as a mockery of political activism soon became, for many of these users, a serious effort to help Trump win. At the same time, clusters of traditional Trump supporters began to adopt the same mannerisms and tactics as actual trolls. As a result, Pepe underwent another transformation. The meme was still dumb and irreverent, but now he was suffused with political meaning as well. Pepe had entered the real world, with real consequences. Amidst the election excitement, there was another, darker battle raging for Pepe’s soul. It was led (or so they wanted you to believe) by a group of thirty “shitposters” and casual bodybuilders, who feared that their meme was being co-opted by “normies,” people with no appreciation of the internet’s subterranean culture. Their solution was to turn the cartoon frog into a literal Nazi, flooding social media with Pepe memes laced with swastikas, Hitler quotes, and Third Reich iconography. In a tactic that would become commonplace, they also targeted unwitting reporters, bombarding them with Pepe-related hate speech in order to convince them that the meme was a white supremacist and anti-Semitic. The gambit worked. Pepe became inextricably linked to white nationalism, denounced by most journalists and the American left and embraced unironically by actual neo-Nazis, who finally had a “hip” symbol to call their own. The notorious white supremacist leader Richard Spencer even took to wearing a lapel pin of Pepe in public, and in an instantly viral video tried to explain its symbolic value to his cause ​— ​until a passerby punched him in the face. Trump’s troll army wielded Pepe like a weapon, poking and prodding at mainstream journalists and Clinton supporters, trying to elicit a backlash. The moment they were called out as racist or white supremacist, they replied with smug outrage, asking how in the world a cartoon could be construed as anything more than a silly, dumb frog. Pepe formed an ideological bridge between trolling and the next-generation white nationalist, alt-right movement that had lined up behind Trump. Third Reich phrases like “blood and soil,” filtered through Pepe memes, fit surprisingly well with Trump’s America First, anti-immigrant, anti-Islamic campaign platform. The wink and nod of a cartoon frog allowed a rich, but easily deniable, symbolism. When Trump won, Pepe transformed again. The green frog became representative of a successful, hard-fought campaign ​— ​one that now controlled all the levers of government. On Inauguration Day in Washington, DC, buttons and printouts of Pepe were visible in the crowd. Online vendors began selling a hat printed in the same style as those worn by military veterans of Vietnam, Korea, and World War II. It proudly pronounced its wearer as a “Meme War Veteran.” In the months that followed, Pepe continued his evolution, popping up at the events of the far-right, where grizzled, camo-clad militiamen marched alongside gangly white teenagers. When a white nationalist terrorist drove his car into a crowd in Charlottesville, Virginia, and killed a peaceful demonstrator, it was discovered that his Facebook page was peppered with Pepe memes. In response, anti-fascist demonstrators flooded the streets and the internet with signs of their own. Again, Pepe featured prominently:",
    "meta": {
      "theme": "Pepe the Frog and the Alt-Right",
      "region": "Primarily US",
      "use_case": "Political Symbolism and Extremist Movements",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems",
        "historical_memory"
      ],
      "usage_tags": [
        "pepe the frog",
        "memes",
        "alt-right",
        "white nationalism",
        "online radicalization",
        "political violence"
      ],
      "influence_map": [],
      "chunk_index": 105
    },
    "id": "likewar_105"
  },
  {
    "section": "Part 1: Memetics and LikeWar",
    "text": "this time as a corpse, a Ku Klux Klan mask torn from his green face. Had Pepe really been racist? The answer is yes. Had Pepe been an innocent, silly joke? Also, yes. In truth, Pepe was a prism, a symbol continually reinterpreted and repurposed by internet pranksters, Trump supporters, liberal activists, ultranationalists, and everyone who just happened to glimpse him in passing. Pepe was a “meme,” an empty vessel, like the chromatin that shields DNA; a protective layer over a rich, ever-multiplying strand of ideas. As it was with Pepe, so it is with all memes. They are the vessels by which culture is transmitted — and a crucial instrument by which LikeWar is fought.\nYet the concept of memes has nothing to do with the internet. In the late 1960s, biologists had begun to unravel the basic nature of the genetic code, discovering how cellular instructions are passed from one generation to the next.  If the rules of genetics could explain life, could they not explain many other things — even the nature of information? After all, just as biological life had to ceaselessly copy itself in order to survive, ideas had to do so, too. In his 1976 book *The Selfish Gene*, evolutionary biologist Richard Dawkins put a name to these bits of organic, self-multiplying information: “memes.” “The computers in which memes live are human brains,” Dawkins wrote. Memes are born from human culture and shaped and transmitted by language. Over time, a meme might become increasingly self-referential and complex, spawning clusters of new memes. A meme is “alive” only so long as it exists in the human mind. For a meme to be forgotten means that it goes extinct, the same as a species that can no longer pass on its genetic code.\nLikeWar\nReligion, for instance, can be viewed as a series of memes both broad and narrow: a general belief in a higher power to the more specific catechisms of the Christian faith to even the warping of a religion to push bigotry against members of another faith. For example, one of history’s cruelest and most enduring memes is the web of conspiracy theories that infuse anti-Semitism. The belief in a secret Jewish conspiracy aiming to run the world built upon itself from the Middle Ages to a fake pamphlet created by Russian secret police in 1903 (*The Protocols of the Meetings of the Learned Elders of Zion*) to the pamphlet’s mass printing and distribution in America by Henry Ford and its subsequent use in Nazi propaganda in Germany. The arrival of the internet sped up this memetic evolution. Dawkins, who had picked up programming as a hobby, observed as much in *The Selfish Gene’s* 1989 edition. “It was obviously predictable that manufactured electronic computers, too, would eventually play host to self-replicating patterns of information — memes,” he wrote. “. . . It is a perfect milieu for self-replicating programs to flourish and spread.”\nThrough the 1990s, memes proliferated across the chaotic, emerging network of websites and forum boards. Longstanding memes (like anti-Semitic conspiracy theories) found fresh, receptive audiences. Meanwhile, entirely new memes could seize popular attention. “The internet is a first class ecology for memes,” Dawkins observed in 2014.",
    "meta": {
      "theme": "The evolution and weaponization of memes in the digital age.",
      "region": "Global",
      "use_case": "Information warfare, political campaigning, social engineering",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "meme warfare",
        "information operations",
        "propaganda",
        "social media"
      ],
      "influence_map": {
        "influenced_works": [
          "Michael Prosser's \"Memetics - a Growth Industry in US Military Operations\"",
          "Jeff Giesea's \"It's Time to Embrace Memetic Warfare\""
        ],
        "modern_applications": [
          "Political campaigns",
          "Online extremism",
          "Social media manipulation"
        ]
      },
      "chunk_index": 106
    },
    "id": "likewar_106"
  },
  {
    "section": "Part 2: Memetic Warfare and the Case of Pepe the Frog",
    "text": "By this point, Dawkins himself had become something of a meme — as an uber-rational, dyspeptic, atheistic defender of Reason, he managed to transform himself into a toxic Twitter troll. As the web became more image- and social media–friendly, what we know as the “internet meme” was born. These were images or short GIFs, often overlaid with text and easily shareable, that relayed ideas fast. Grasping their full meaning, however, required understanding not only the content at hand but also its previous iterations. For instance, the LOLCats phenomenon, comprised of tens of thousands of cat pictures with misspelled captions, becomes funnier (to a point) only if you’re familiar with the context to which it refers — the pervasiveness of cat images on the internet. Indeed, the most effective memes often build not merely on themselves but on other memes as well. One reason for Pepe the Frog’s enduring popularity was the way he could be used to mock or replicate other viral content — to essentially “meme” memes.\nImportantly, it takes only one event, group, or person to alter a meme’s meaning for everyone who might use it. “Digital content can travel further, be decontextualized more quickly and accessed instantaneously — without the original creator’s consent or even awareness — by millions of people,” write internet ethicists Whitney Phillips and Ryan Milner. Pepe the Frog’s creator went so far as to sue to try to stop the misuse of his creation. But it was to no avail. By either hijacking or chance, a meme can come to contain vastly different ideas than those that inspired it, even as it retains all its old reach and influence. And once a meme has been so redefined, it becomes nearly impossible to reclaim. Making something go viral is hard; co-opting or poisoning something that’s already viral can be remarkably easy.\nThe study of internet “memetics” has steadily merged with studies of online warfare, attracting strange bedfellows. Both psychological warfare professionals and shitposting trolls began to explore how to co-opt old memes and spin off new ones. For U.S. defense analysts, one of the first examinations of the subject came in 2006, when U.S. Marine Corps Major Michael Prosser published a far-reaching thesis: “Memetics — a Growth Industry in US Military Operations.” In an echo of the earlier netwar writings of Arquilla and Ronfeldt, Prosser argued that armed conflict would increasingly be decided by dueling ideologies on a “nonlinear battlefield.” Accordingly, militaries would need to track the memes promulgated by their adversaries, counter them, and respond with memes of their own. In the United States, Prosser’s work would kick off a tiny, DARPA-funded industry devoted to “military memetics” — the analysis and weaponization of memes to gain advantage in an invisible, all-consuming information war. As of 2018, the work was still going strong. A perfect illustration came when the Center for Naval Analyses, a U.S. military–funded think tank, released a report titled “Exploring the Utility of Memes for U.S. Government Influence Campaigns.” Naturally, its cover was a meme of *Toy Story’s* Buzz Lightyear.\nOf course, the U.S. government has hardly been alone in this quest. Over the past decade, shadowy groups in the weirdest corners of the internet also began to write more explicitly about transforming memes into weapons. One now mostly defunct organization is the Bureau of Memetic Warfare, part of 8chan (a board for users too extreme for\nLikeWar\n4chan), whose tagline brags to visitors, “He who controls the memes, controls the world.” The conversations were a horrifying mix of unrepentant neo-Nazism, plots to hijack or undermine popular online movements, and fairly nuanced discussions about social engineering and the nature of ideas. One user grandly summarized the promise of memetic warfare for ultranationalist agitators: “Now as never before we have the ability to reach out, learn, and spread truth as we know it to be . . . We are presented with a state of affairs unique to history, an age of ideological memetic warfare in which the controlling principles of mankind are loosed to spread with no physical barriers.” Naturally, the user’s profile was a photograph of Joseph Goebbels.",
    "meta": {
      "theme": "The exploitation of memes in online warfare and political manipulation.",
      "region": "Global",
      "use_case": "Propaganda, disinformation, political influence",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "meme warfare",
        "information operations",
        "psychological operations",
        "social media manipulation"
      ],
      "influence_map": {
        "influenced_works": [
          "Whitney Phillips and Ryan Milner's work on internet ethics",
          "DARPA research on memetics"
        ],
        "modern_applications": [
          "State-sponsored disinformation campaigns",
          "Online radicalization",
          "Political polarization"
        ]
      },
      "chunk_index": 107
    },
    "id": "likewar_107"
  },
  {
    "section": "Part 3: The Merging of Online and Physical Warfare",
    "text": "These two worlds — the leading edge of military theory and the dark kingdom of internet trolls — unsurprisingly found each other online. The union came in the form of Jeff Giesea, a tech consultant who worked as an early and avid organizer for Trump. He was one of the cofounders of MAGA3X, a meme-generating hub for the Trump online army, which described itself as “Freedom’s Secret Weapon.” Giesea felt that the election’s relentless creation and co-option of memes echoed a larger shift in global affairs — one that had caught the United States and most democracies off guard. So he put his thoughts to paper in an article titled “It’s Time to Embrace Memetic Warfare.” The document wasn’t published on a Trump fan site, however, but in the journal of NATO’s Strategic Communications Centre of Excellence. Giesea drew parallels between the messaging of pro-Trump forces and the equally effective influence strategies of Russian propagandists and the Islamic State. “It’s time to drive towards a more expansive view of Strategic Communications on the social media battlefield,” he wrote. “It’s time to adopt a more aggressive, proactive, and agile mindset and approach. It’s time to embrace memetic warfare.”\nThe memetic warfare envisioned by Prosser, Giesea, DARPA researchers, and internet anti-Semites alike turns on essentially the same principle. It recognizes the power of virality — the need to produce and propel viral content through the online system. But it also recognizes that the content that goes viral — the meme — can be quite easily hijacked. And whoever does that best determines what reality looks like: whether Pepe the Frog draws chuckles or revulsion; whether a terrorist group sows fear and inspires real-life attacks or simply drowns in online derision. In the larger picture, memes are akin to the skirmishes of LikeWar, the micro-battles that shape and determine the outcome of the global tug-of-war. Win enough of these skirmishes, and, for a time, victory is yours for the taking. “Own the moment, own the hour,” writes defense analyst August Cole. “Own the hour, own the country.”\nYet, while these skirmishes start online, they don’t necessarily stay there. In a world of LikeWar, internet conflicts now merge seamlessly with those of flesh and blood.\nWAR IN THE OPEN\nTo many Palestinians who live in Gaza City, Ahmed al-Jabari was a hero: the commander of Hamas, the militant wing of resistance to the Israeli occupation. To Israelis, he was a villain: a terrorist who exploded bombs on packed school buses and rained mortar shells down on cities. But most of all, Jabari was a survivor. He’d lived through five assassination attempts and boasted that he no longer feared bullets or bombs. His reckoning came on November 14, 2012, as Jabari and his bodyguard were driving down a residential street in Gaza City. High above them, an Israeli Heron drone loitered. Its high-powered camera zoomed in as Jabari’s car sped past a packed minibus and onto a stretch of open road. Then the drone fired a missile. Jabari never saw the explosion that ended his life, but millions of other people did. Even as his body smoldered, the Israeli military’s official Twitter account spun into action. “The IDF has begun a widespread campaign on terror sites & operatives in the #Gaza Strip,” declared @IDFSpokesperson. Then came an infographic that listed Jabari’s crimes in bullet points, with a big red box reading “ELIMINATED” slapped across his glowering face. After that came the YouTube clip. “In case you missed it — VIDEO — IDF Pinpoint Strike on Ahmed Jabari, Head of #Hamas Military Wing.” You could watch Jabari’s car trundling down the street before it exploded in a ball of fire. You could watch him die as many times as you wanted (the video has since been viewed nearly 5 million times) and share it with all your friends.",
    "meta": {
      "theme": "The blurring lines between online information warfare and real-world conflict, exemplified by the targeted killing of Ahmed al-Jabari.",
      "region": "Gaza Strip, Israel",
      "use_case": "Military operations, psychological operations, information warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "historical_memory",
        "value_systems"
      ],
      "usage_tags": [
        "targeted killing",
        "information operations",
        "social media warfare",
        "drone warfare"
      ],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": [
          "Use of social media in military conflicts",
          "Real-time propaganda dissemination"
        ]
      },
      "chunk_index": 108
    },
    "id": "likewar_108"
  },
  {
    "section": "Part 4: The Three Fronts of Modern Warfare",
    "text": "Within a few hours, Israeli aircraft had destroyed dozens of weapons caches hidden across Gaza City. “We recommend that no Hamas operatives, whether low level or senior leaders, show their faces above ground in the days ahead,” @IDFSpokesperson taunted. The challenge didn’t go unanswered. “Our blessed hands will reach your leaders and soldiers wherever they are,” a Hamas spokesperson, @AlqassamBrigade, fired back. “(You Opened Hell Gates On Yourselves.)” The Israelis called it Operation Pillar of Defense. IDF air strikes perforated the buildings in which suspected Hamas fighters gathered, killing militants and innocent families alike. Hamas fighters responded with hundreds of unguided rockets, eager to kill any Israeli they could. Few reached their targets. Israel had a new, U.S.-provided defense, the Iron Dome, a missile shield that could intercept the projectiles in midair. The result was an eight-day, one-sided campaign. The IDF hit every intended target; Hamas, almost none. Two IDF soldiers and 4 Israeli civilians were killed, and another 20 Israelis were wounded. On the Palestinian side, roughly 100 militants and 105 civilians were killed, and another thousand wounded.\nBut this wasn’t the only fight that counted. There were now three fronts at work in any conflict, Israel’s chief information officer explained. Two were predictable: the “physical” fight, which Israel easily dominated, and the “cyber” fight, in which the IDF just as easily beat back the efforts of Palestinian hackers. But there was a third front, he said, “the world of social networks.” This front would prove more troublesome, and impossible to contain, soon seeping into every corner of the internet. A comparatively tiny physical conflict, fought in an area the size of Portland, Oregon, became a global engagement, prompting the exchange of more than 10 million",
    "meta": {
      "theme": "The emergence of social media as a key battleground in modern warfare, alongside physical and cyber domains.",
      "region": "Gaza Strip, Israel",
      "use_case": "Information warfare, public opinion manipulation, international relations",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "information operations",
        "social media warfare",
        "cyber warfare",
        "public diplomacy"
      ],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": [
          "Hybrid warfare",
          "Information dominance"
        ]
      },
      "chunk_index": 109
    },
    "id": "likewar_109"
  },
  {
    "section": "LikeWar Excerpt 1",
    "text": "heated messages on Twitter alone. The IDF deployed a Twitter account, Facebook pages in multiple languages, Tumblr blog pages, and even a Pinterest page. There were slick infographics and a stream of videos and statistics. Maximizing follower engagement, the official IDF blog offered small digital rewards for repeat users. Visiting the blog ten times got you a “Consistent” badge; searching the website got you recognized as a “Research Officer.” Memes were fired off in volleys and tested for engagement, the best ones deployed extensively. The IDF’s most widely shared image showed Hamas rockets bearing down on cartoon versions of Sydney, New York, London, and Paris. “What Would You Do?” the caption asked in bold red letters. By contrast, the propaganda efforts of Hamas’s militants were less structured. Most of its social media response came from millions of unaffiliated observers around the world, who watched the plight of Palestinian civilians with horror and joined the fray. The Twitter hashtag #GazaUnderFire became an unending stream of atrocities: images of bombed-out buildings, dead children, crying fathers. The scourge of war left nothing untouched — including video games and fast-food chains. The IDF hijacked the hashtags for the World Cup, a new James Bond movie, and even the same Call of Duty franchise that Junaid Hussain of ISIS would weave into his own recruiting (“Playing war games on Call of Duty last night? Over a million Israelis are still under REAL fire#BlackOps2”). Meanwhile, pro-Hamas hackers took over the Israeli Facebook page of Domino’s Pizza, using the opportunity to threaten a merciless reprisal of “more than 2000 rockets” against Israeli cities. When Domino’s regained control of the account, it had a message of its own: “You cannot defeat . . . the Israeli hunger for pizza!” Even as the missiles flew, the IDF and Hamas continued to narrate the conflict, each posting alerts, updates, and a steady string of taunts. “Warning to reporters in Gaza,” wrote @IDFSpokesperson. “Stay away from Hamas operatives and facilities. Hamas, a terrorist group, will use you as human shields.” @AlqassamBrigade couldn’t let this stand. “Stay away from Israeli IDF,” the Hamas spokesperson mimicked. “We are just targeting Israeli soldiers, fighter jets, tanks and bases.” It was a remarkably juvenile exchange. But these taunts couldn’t be dismissed as easily as the ones you might hear in a kindergarten classroom. After all, they were salvos lobbed by two combatants in a real, shooting war. There was a temptation, after the sides had settled into an uneasy cease-fire, to dismiss this weird internet flame war as a bunch of digital noise. The angriest tweets were still just tweets — literally, “short bursts of inconsequential information.” But that would have been a mistake. Years after Operation Pillar of Defense had slipped from the public mind, American University professor Thomas Zeitzoff conducted a painstaking study of hundreds of thousands of tweets, which he then mapped across each hour of the physical side of the eight-day conflict. What he found was shocking. In the case of Israel, a sudden spike in online sympathy for Hamas more than halved the pace of Israeli air strikes and resulted in a similarly sized leap in Israel’s own propaganda efforts. If you charted the sentiment (pro-Israel or pro-Palestine) of these tweets on a timeline, not only could you infer what was happening on the ground, but you also could predict what Israel would do next. Israeli politicians and IDF commanders hadn’t just been poring over battlefield maps. They’d also been keeping an eye on their Twitter feeds — the battlefield of the social network war.",
    "meta": {
      "theme": "Social Media Warfare",
      "region": "Middle East",
      "use_case": "Propaganda and Information Operations",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "information warfare",
        "propaganda",
        "social media",
        "conflict"
      ],
      "influence_map": [],
      "chunk_index": 110
    },
    "id": "likewar_110"
  },
  {
    "section": "LikeWar Excerpt 2",
    "text": "Taking place in 2012, Operation Pillar of Defense offered a glimpse of an emerging way of warfare. It was a conflict in which each side had organized to taunt and troll each other online, even as they engaged in a life-and-death struggle in the real world. Their battles drew in millions more international fighters. Some were passionate supporters of one side; others had just stumbled upon the war while looking for video game news or pizza. They shaped the fight all the same, strengthening the voice of one faction or another — and, by tiny degrees, altering the course of events on the ground. The lesson was clear: Not only did modern war require a well-planned military campaign. It required a viral marketing campaign as well. Moving forward, both Israelis and Palestinians would apply this lesson, albeit in very different ways. Their approaches are broadly representative of the two strategies — loosely networked or centrally organized — that characterize how combatants approach the information battles of LikeWar today. The next major outbreak of both web and “real” war came in 2014, as Israel and Hamas descended into another, bloodier, even more lopsided conflict, culminating in Operation Protective Edge, the IDF’s ground invasion of Gaza City. Sixty-seven IDF soldiers and three Israeli citizens would perish, as would hundreds of Hamas militants and more than a thousand Palestinian civilians. Hamas actively solicited images of the victims of Israeli air strikes (children were best) and posted them online as soon as possible. “There is nothing wrong with publishing images of the injured,” one web video urged. Real images of the devastation were soon blended with an ocean of fakes and forgeries. One 16-year-old Twitter user, confronted with proof that their recently posted viral image was fake, was as dismissive as a White House spokesperson. “People don’t need to take it as a literal account,” the teen said. “If you think of bombs going off, that’s pretty much what it looks like.” Although the IDF won every battle, as casualties mounted, social media chatter grew unrelenting in its criticism of the Israeli military. In a single month, the hashtag #GazaUnderAttack was used more than 4 million times — twenty times that of the one the IDF was pushing, #IsraelUnderFire. When Operation Protective Edge ended seven weeks after it began, many Israelis were furious. They felt that their government had crumpled under international pressure; nine out of ten believed the military had failed to achieve its objectives. Yet as the fighting ebbed, the images and videos didn’t. By 2015, more than one-third of Palestinians had a Facebook account; even more had smartphones and access to the internet. And they began to use them, even — and especially — the very young.",
    "meta": {
      "theme": "Social Media Warfare",
      "region": "Middle East",
      "use_case": "Propaganda and Information Operations",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems",
        "historical_memory"
      ],
      "usage_tags": [
        "information warfare",
        "propaganda",
        "social media",
        "conflict",
        "public opinion"
      ],
      "influence_map": [],
      "chunk_index": 111
    },
    "id": "likewar_111"
  },
  {
    "section": "Part 1: Social Media as a Battlefield",
    "text": "“missions” and rewarding them with points and badges. In one case, the app urged users to write positive things on comedian Conan O’Brien’s Instagram page during his visit to Israel. In another, it prompted them to “report” a Facebook image that had superimposed the Israeli flag over a picture of a cockroach. It offered a glimpse of war’s future: organized but crowd-sourced, directed but distributed.\n\nOf course, Israel had another, more direct way of gaining an advantage in online warfare: its flesh-and-blood police and soldiers. As Palestinians grew more vocal in their social media use, Israeli courts broadened the definition of speech they considered “incitement” to violence. Police units monitored social networks for particular keywords and messages; they studied suspicious users, checking to see if they gave vocal support to any militant causes. In the occupied West Bank, IDF soldiers in armored Humvees prowled the neighborhoods of suspected social media “inciters.” Between 2011 and 2015, more than 400 Arabs were arrested for social media–related crimes. Their fate was easy to predict. Israeli military courts had a conviction rate of 99 percent.\n\nToday, the battles between Israelis and Palestinians continue, both in the occupied territories and online. Yet they are only one tiny front in a world of wars. The social media accounts of every military organization, diplomatic envoy, world leader, soldier, and civilian exist in the same digital milieu. For the most part, they’re accessible to the same global audience, who either use English as the internet’s lingua franca or rely on increasingly sophisticated language-translation software. And when the sides come into conflict — as they often do — their supporters, critics, and trolls are all thrown into battles of their own. Every tweet or public statement, in other words, is a new front waiting to happen.\n\nSometimes, the spark is as simple as a disagreement about numbers. A puffed-up propaganda statement about enemy casualties — an act of exaggeration as old as war itself — draws a great deal more scrutiny when both sides are on Twitter and can fact-check each other. In Afghanistan, Taliban spokesmen complain often about not getting “credit” for their attacks. Such exchanges also lead to weird moments of impropriety. When, in the midst of an argument over air strikes, the Taliban feed made reference to a NATO commander’s mistress, it left observers aghast. The online consensus was that the Taliban, a group that murders women for the crime of learning to read, had “gone too far.”\n\nIn places where the physical battle lines are less clear, the migration of conflict to the internet becomes similarly perplexing. Imed Lamloum, a Libyan correspondent for Agence France-Presse, described in 2017 how the war-torn country had splintered into two rival social media–savvy governments. “Each government has its own press agency,” he explained. “Both are named Lana. Each Lana puts out statements by its respective government and also seeks to discredit the other.” Libya’s dozens of armed militias each had their own Facebook account, where they did everything from negotiating cease-fires to posting a mix of bluster and factual “updates” that were nearly impossible to verify, just like the gangs and presidents. “Sometimes I think that the situation in the country could improve if internet access was cut,” Lamloum wrote. “Then people would no longer have access to rumors, which represent roughly 90 percent of information that’s out there.”",
    "meta": {
      "theme": "Social Media Warfare",
      "region": "Global, Middle East, North Africa",
      "use_case": "Information Warfare, Propaganda, Public Opinion Manipulation",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos"
      ],
      "usage_tags": [
        "social media",
        "propaganda",
        "information warfare",
        "conflict",
        "online activism"
      ],
      "influence_map": [],
      "chunk_index": 112
    },
    "id": "likewar_112"
  },
  {
    "section": "Part 2: The Ukrainian Case Study - Hybrid Warfare",
    "text": "When two nations with similar languages and shared borders fall to bloodshed, the result is an even more surreal mess of public disparagements and digital proxy battles. Since Russia’s invasion and occupation of eastern Ukraine in 2014, the two countries have remained locked in a simmering conflict that has stolen tens of thousands of lives and that reverberates each day through Ukrainian-, Russian-, and English-language social media. As homophily and group polarization have kicked into high gear (wars have a way of accelerating the process), supporters of each side have assembled an inexhaustible list of real or fabricated crimes, which they throw at each other like knives. Each public posting across Facebook, Twitter, or VK presents a new opportunity to argue and troll. When a famous Russian-backed separatist commander was killed in a Ukrainian rocket attack, for instance, his funeral was livestreamed on Facebook — and promptly discovered by Ukrainian nationalists. The livestream became an extension of the physical battlefield, as laughing and crying emojis both jockeyed for supremacy.\n\nThis mix of deadly serious conflict and weird digital levity reverberates through the highest levels of international diplomacy. In one instance, the official Russian Twitter account (@Russia) warned, “Whoever comes to us with #sanctions will perish.” The boast was paired with a heavy-metal music video of Russians parading with medieval swords and armor. The response from the official Ukrainian account (@Ukraine) was swift: “If you’d respected international law, you would’ve avoided sanctions & would’ve been sending missions to Mars now, not running with sticks.” Ukraine then underscored its taunt with a meme, a GIF of two characters from the television series South Park hitting each other with sticks. Russia responded the same day in a different way, with shelling that killed a Ukrainian soldier.\n\nWhether the conflict is a civil war echoing across YouTube, a dispute over missile tests that culminates in one leader tweeting threats at another, a swaggering Facebook argument between gangs, or just a celebrity flame war, all of these socially mediated conflicts are overtly theatrical. It is about bolstering friends and dissuading foes, just like the kind of macho showmanship that precedes a bar fight. It is about persuading someone to back off before the first punch is thrown. Failing that, it’s about weakening and embarrassing them, sapping their supporters while energizing your own.\n\nBut there’s also another kind of internet conflict — subtle, often invisible — that simmers beneath such public disputes. These hidden battles of influence comprise the side of LikeWar that doesn’t want to be noticed, but it may be the part that has most decisively reshaped the modern world.",
    "meta": {
      "theme": "Hybrid Warfare, Information Warfare",
      "region": "Eastern Europe",
      "use_case": "Military Conflict, Propaganda, International Diplomacy",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [
        "historical_memory"
      ],
      "usage_tags": [
        "hybrid warfare",
        "information warfare",
        "social media",
        "international relations",
        "conflict"
      ],
      "influence_map": [],
      "chunk_index": 113
    },
    "id": "likewar_113"
  },
  {
    "section": "Part 3: The War You Cannot See - Russian Information Operations",
    "text": "To start the process of a “pro-Russian drift” of Crimea and eastern Ukrainian territories, [certain] events should be created beforehand that can support this process with political legitimacy and moral justification; also a PR-strategy should be built that draws attention to the forced, reactive nature of the actions of Russia and the pro-Russian political elites of southern and eastern Ukraine.\n\nIn early 2014, a policy paper began circulating in the Kremlin, outlining what steps Russia should take if President Viktor Yanukovych, the pro-Russian autocrat who controlled Ukraine, was toppled from power. Russia had to be ready, the memorandum’s author urged, to create a new set of political conditions on the ground — to manipulate the “centrifugal aspirations” of ethnic Russians, pushing them to declare independence from Ukraine. In essence, if their guy was ever forced from power, Russia had to be ready to start a war.\n\nJust two weeks later, amidst mounting protests, the unpopular Yanukovych fled the country in what was known as the Euromaidan. As proof of the emerging power of social media, the name of this Ukrainian revolt was taken from a Twitter hashtag (it combined “Europe,” for the demonstrators’ desire to partner with Europe instead of Russia, and “Maidan Nezalezhnosti,” the square in Kiev where they gathered). But just as the revolutionaries had used the new form of the internet to unite and topple their foe, so Russia now used it to tear Ukraine apart.\n\nThe strategic vision behind the operation was subsequently explained by Dmitry Peskov, Putin’s long-serving media advisor, in a 2017 interview. Particularly notable was not just how candid Peskov was, but whom he drew upon for inspiration. He spoke of “a new clash of interests” between Russia and the world, brought about by the social media revolution. But he also marveled at the incredible influence wielded by new online powers, citing Kim Kardashian. “Let’s imagine that one day she says, ‘My supporters — do this,’ ” he said. “This will be a signal that will be accepted by millions and millions of people.” But importantly, Peskov noted, Kardashian had “no intelligence, no interior ministry, no defense ministry, no KGB.”\n\nThe implication was clear. Russia did have these things — and unlike Kim Kardashian, it would use them for more important fights than a feud with Taylor Swift. “The new reality creates a perfect opportunity for mass disturbances or for initiating mass support or mass disapproval,” Peskov said. This was the grounds for “an informational disaster — an informational war.”\n\nUkraine proved a critical test case. Negative Russian-language news articles about Ukraine doubled, then tripled, in number. Ethnic Russians inside Ukraine, already on edge, soon boiled with resentment toward the activists who had overthrown the government they supported. Meanwhile, Russian commandos filtered into Crimea, then eastern Ukraine, recruiting and arming cells of pro-Russian separatists. There were waves of protests, then violence, then mounting tragedy.",
    "meta": {
      "theme": "Information Warfare, Propaganda, Hybrid Warfare",
      "region": "Eastern Europe",
      "use_case": "Military Intervention, Political Manipulation, Annexation",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "information operations",
        "propaganda",
        "hybrid warfare",
        "social media manipulation",
        "political subversion"
      ],
      "influence_map": [],
      "chunk_index": 114
    },
    "id": "likewar_114"
  },
  {
    "section": "Part 4: Escalation and Schrödinger's War",
    "text": "The tipping point came in the city of Odessa, where dozens of pro-Russian protesters — many armed — retreated to a large, Soviet-era trade union building that soon caught fire amid the hail of bullets and Molotov cocktails. At least thirty-one people died. Spying opportunity, the Russian “PR-strategy” kicked into high gear. Russia deftly seized on the tragedy, orchestrating a media campaign that Ukraine couldn’t hope to match. RT reveled in publishing gory details that were impossible to verify: pro-Ukrainians had sprinted through the flames to “strangle” pro-Russians; “17-year-old hooligans were finishing people with bats.” Legions of trolls then seeded the stories through fringe outlets around the world. Conspiracy theory memes were deployed. “US Media Covers Up Mass Murder in Odessa,” blazed one Infowars headline. Meanwhile, the Russian government fed off the very headlines it had ordered written. The Russian foreign minister declared that, given the news of atrocities, it was now Russia’s solemn duty “not to allow fascism to spread throughout Europe and the world at large.”\n\nAs time passed, the supposed atrocities grew even more troubling. Russian state media described how Ukrainian soldiers had stripped a 3-year-old to his underwear, then crucified him “just like Jesus” — right before strapping the mother to a tank and dragging her around the town square. There was nothing in the way of proof, but there didn’t have to be. The point wasn’t to be truthful, but to justify an invasion.\n\nSoon enough, thousands of Russian troops were streaming into Ukraine. Although these troops did what they could to conceal their identities, they couldn’t escape the spotlight of the same social media platforms they’d deftly manipulated. Some ethnic Russians in Crimea, enthusiastic about the prospect of reunification, took selfies with the occupiers and posted them on Instagram (“Sweetest guys,” one caption read). In a bit of internet wordplay, they took to calling these heavily armed soldiers in unmarked uniforms “little green men.” The Russians themselves couldn’t keep from talking. On his VK account, one artilleryman bragged, “We pounded Ukraine all night.” This chatter fed a new flurry of OSINT analysis. The investigative team at Bellingcat found the Russian military had awarded more than 10,000 medals for “combat operations” at a time when Russia wasn’t officially fighting anywhere.\n\nAcross the world, no one knew what to make of it. The United States and its European allies imposed sanctions and went on their highest military alert since the Cold War, all for something that officially wasn’t happening. It was an invasion that wasn’t, a major conflict that one side flatly refused to acknowledge it was fighting. Russia had used social media not only to stoke the fires of conflict, but also to create something akin to a “Schrödinger’s war”: a perception-warping, reality-bending conflict that existed in two simultaneous states. “This, in short, was no traditional military invasion; it was hybrid warfare in which goals were accomplished even before the adversary understood what was going on,” former U.S. ambassador to NATO Ivo Daalder explained. His military counterpart, General Philip Breedlove, then supreme allied commander of NATO, called it nothing less than “the most amazing information blitzkrieg we have seen in the history of information warfare.”\n\nBut it was something even more than that. On the ground in separatist-occupied Donetsk, journalist David Patrikarakos scrolled through frenzied Ukrainian social media feeds even as he listened to shells falling on the city outskirts. He realized these two worlds were inextricably linked. “I began to understand that I was caught up in two wars: one fought on the ground with tanks and artillery, and an information war fought . . . through social media,” he wrote. “And, perhaps counterintuitively, it mattered more who won the war of words and narratives than who had the most potent weaponry.” The result was a violent, confusing, paralyzing mess — precisely as Russia intended.",
    "meta": {
      "theme": "Hybrid Warfare, Information Warfare,Escalation",
      "region": "Eastern Europe",
      "use_case": "Military Intervention, Propaganda, Political Manipulation",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "hybrid warfare",
        "information warfare",
        "escalation",
        "propaganda",
        "social media manipulation"
      ],
      "influence_map": [],
      "chunk_index": 115
    },
    "id": "likewar_115"
  },
  {
    "section": "Russian Information Operations in Europe",
    "text": "Russia employed similar information warfare tactics against its neighbors as it did in Ukraine. This involved spreading disinformation through various channels, including fake news stories (like the fabricated rape story in Lithuania), troll armies targeting news portals, and establishing government-funded media outlets like Baltica, which spread fear-mongering rumors (such as American soldiers confiscating Estonian cars).  The objective was to sow discord and lay the groundwork for potential future operations. In Lithuania, these campaigns aimed to rewrite history and promote secessionist movements, echoing tactics used in eastern Ukraine. These information offensives sought to \"divide\" in addition to the classic disinformation goals of dismiss, distort, distract, and dismay. Russia exploited the Syrian refugee crisis, particularly in Germany, by spreading a hoax about a Russian-German girl being raped by migrants. This story, amplified by Russian media and far-right outlets, fueled anti-refugee sentiment and benefited nationalist political parties. Russia also interfered in other divisive situations, like the Scottish independence referendum, Brexit, Catalonia's secession attempt, and Montenegro's NATO membership bid.  The latter involved a foiled plot to assassinate the prime minister and overthrow the government. The EU expressed concern about Kremlin-backed activities, while Putin criticized the West's understanding of democracy.",
    "meta": {
      "theme": "Information Warfare",
      "region": "Europe",
      "use_case": "Political Interference",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "disinformation",
        "propaganda",
        "social media manipulation",
        "political subversion"
      ],
      "influence_map": [],
      "chunk_index": 116
    },
    "id": "likewar_116"
  },
  {
    "section": "Principles of Information Warfare and Western Vulnerabilities",
    "text": "These information operations adhere to two key principles: believability and extension.  Falsehoods are most effective when they contain a kernel of truth, preying on existing prejudices. The internet, especially through memes, facilitates this by leveraging existing narratives and controversies. The format of social media increases believability due to content originating from friends and family. Extension involves spreading falsehoods widely and over time. Denials often reinforce the message, embedding it further into public consciousness. Salacious accusations are particularly effective. The internet and social media algorithms amplify this by highlighting trending content, even when it's met with outrage. This creates a cycle where condemnation fuels further visibility. Western democracies, with their emphasis on logic, transparency, accountability, and responsibility, are ill-equipped to combat this form of warfare.  Their openness becomes a vulnerability as attempts to counter disinformation are easily twisted into narratives of censorship or conspiracy.  The effectiveness of these campaigns lies in their combination of unseen manipulation and visible amplification through networks of accounts, media outlets, and social media algorithms.",
    "meta": {
      "theme": "Information Warfare Tactics and Vulnerabilities",
      "region": "Global",
      "use_case": "Political Manipulation",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "disinformation",
        "propaganda",
        "social media manipulation",
        "virality",
        "psychological manipulation"
      ],
      "influence_map": [],
      "chunk_index": 117
    },
    "id": "likewar_117"
  },
  {
    "section": "Part 1",
    "text": "just another wedge to be exploited. But all is not so dark. For that very openness, both of democracies and the internet that only an open democracy could create, also widens the fight. The more confused and nonlinear war gets, the more participatory it becomes. LikeWar 211 WAR BETWEEN EVERYONE The shrouded figure gazes into the camera. It wears a white mask with cartoonishly arching eyebrows, a wide mustache turned up at both ends, and a thin, pointed beard. The mask’s mouth carries an oversized, sinister smile. Its computerized voice rings out, condemning the crimes being committed by the self-declared Islamic State and also promising vengeance. “We are held by a code of honor to protect those who are de- fenseless, both in the cyber world and the real world.” The figure folds its hands, black suit contrasting with the sepia-tinted globe behind it. The video ends with a motto intended to send chills down the spine of any internet user. We are Anonymous. We are Legion. We do not forgive. We do not forget. And finally, as the screen fades to black: Expect us. When ISIS rocketed to digital prominence, it drew the attention of the world, but also an unexpected adversary: members of the hacktivist group Anonymous. The Islamic State’s viral propaganda struck a nerve. Viewing themselves as the guardians of the internet, Anonymous de- cided to fight back. The counterattack began in stumbling, jumbled confusion, a mob of random trolling and harassment. Digital vigilantes surfed the massive, public ecosystems of platforms like Twitter and YouTube, relentlessly taunting ISIS militants about their sex lives (you quickly felt sorry for the goats) and flagging accounts for deletion. ISIS websites were over- loaded with message traffic and knocked offline. Japanese hacktivists, spurred by the brutal beheading of two Japanese hostages, targeted one of the Islamic State’s most precious assets: its Google ranking. They wrote programs to bombard ISIS-related search terms, replacing mes- 212 LikeWar sages of jihad with a black-robed, green-haired anime character (named ISIS-chan) with a cute smile and a strange obsession with melons. Although the Anonymous effort inspired plenty of thrill-seekers who jumped into anti-ISIS operations for only a few days (spending most of that time editing their own epic YouTube declarations of war), the churn and madness gradually forged a cadre of hacktivists cut from a different cloth. For these men and women, throwing their lives into battling the “Cyber Caliphate,” hatred of the Islamic State was visceral ​— ​and often intensely personal. There was the U.S. military veteran DigitaShadow, based in the backwoods of the American South, who hunted the dark web for ISIS sanctuaries; a former Miss Jordan beauty pageant queen, Lara Abdallat, who pushed back against ISIS propaganda on Twitter; and the European transient Mikro, a product of foster homes and juve- nile prison, who harnessed his Arabic-language skills and restless energy to locate, flag, and eliminate ISIS social media accounts across the web.",
    "meta": {
      "theme": "Cyber Warfare & Hacktivism",
      "region": "Global/Middle East",
      "use_case": "Counter-terrorism/Propaganda warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "cyberwarfare",
        "hacktivism",
        "ISIS",
        "propaganda",
        "social media"
      ],
      "influence_map": [],
      "chunk_index": 118
    },
    "id": "likewar_118"
  },
  {
    "section": "Part 2",
    "text": "Over time, these dissidents pooled their efforts into a weird, new on- line organization that was equal parts hacking collective, troll factory, and amateur spy ring. ISIS websites were systematically targeted and destroyed with military efficiency. Teams of volunteers maintained a rotating list of tens of thousands of ISIS Twitter accounts, crafting algo- rithms to concentrate their fire and banish ISIS mouthpieces as quickly as they were created. Other hacktivists posed as would-be recruits, pen- etrating deep into ISIS networks to harvest snippets of personally iden- tifying information and pass them on to governments. In a surreal turn of events, one faction even founded an internet security group, prom- ising “cyber terrain vigilance” and competing for contracts with other cybersecurity firms that had themselves been created to defend against Anonymous. As this weird internet war rumbled onward, it sometimes blurred with the “real” one. In Tunisia, eagle-eyed members of the collective spotted evidence of an impending attack on social media, leading to the arrest of eleven suspected militants. ISIS recruiters in Indonesia, care- less in masking their IP address, awoke to a police raid, their identities leaked by hacktivists halfway around the world. Devoted as the hacktivists were, the accumulated impact of their campaign was modest. They couldn’t stop the flow of foreign recruits to ISIS. Their Twitter trolling could hardly liberate Syria and Iraq. LikeWar 213 But that wasn’t the goal. The point of the anti-ISIS campaign, ex- pressed repeatedly by those who fought it, was simply to push back; to mount a resistance where before there had been none. Most netizens, much as they despised ISIS, weren’t going to march into a military re- cruiting station and undergo a year’s worth of training in order to one day possibly ​— ​possibly ​— ​get to fight ISIS on the ground. But almost anyone could join this fight. They could spend their lunch breaks scan- ning Twitter for new ISIS accounts, feeding them into a community spreadsheet to ensure they were reported and deleted as quickly as pos- sible. This was a tiny but perceptible way to chip away at the Islamic State’s propaganda apparatus, open to all comers with a basic internet connection. This fight was just one of the many wars that have broken out on- line, in which an army of volunteers have rushed into the battle. Wiki- pedia editors fought to preserve the truth of the “Rape Melania” hoax, while unpaid Bellingcat analysts investigated the shootdown of MH17. Indeed, when both the U.S. government and social media firms delayed taking action against Russian bots and sockpuppets in 2016, it was a group of think tank wonks who started to track them down.",
    "meta": {
      "theme": "Cyber Warfare & Citizen Activism",
      "region": "Global/Middle East",
      "use_case": "Information Warfare/Counter-terrorism",
      "strategic_category": [
        "military_doctrine",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "cyberwarfare",
        "citizen activism",
        "information warfare",
        "social media",
        "propaganda"
      ],
      "influence_map": [],
      "chunk_index": 119
    },
    "id": "likewar_119"
  },
  {
    "section": "Part 3",
    "text": "Yet the combatants extend beyond these cyber-minutemen con- sciously volunteering for the cause. As modern warfare turns increas- ingly on the power of internet operations, it renders everyone a poten- tial online combatant. Any particular message, image, video, or status update has the chance of achieving virality. Such content can work to the benefit of one side in a conflict and the detriment of another. As two or more online adversaries fight over the fate of that content ​— ​your in- dividual choice whether to amplify, expand, suppress, or distort it ​— ​ even a single “like” or retweet becomes a meaningful action in an ever- evolving information war. We’ve seen how this dynamic has divided and destroyed, spinning out lies and empowering some of the worst possible people and move- ments. But this very same force can work to the benefit of the weak- est and most downtrodden, giving them a voice where before they had none. That is illustrated by another young girl, in this case motivated not by opportunity or loss, but by a desire for peace. Bana Alabed was just 7 years old when her Twitter account spun to life in October 2016, broadcasting live from the besieged Syrian city of 214 LikeWar Aleppo. Her first message was poignant in its simplicity: “I need peace.” Over the following days and weeks of the siege, Bana’s messages were a surreal mix of harrowing updates (“We are sure the army is captur- ing us now”), images of bombed-out buildings, and the musings of a lit- tle girl trapped by circumstances beyond her control (“I miss school so much”). In many ways, Bana’s online diary of thoughts made her a modern- day Anne Frank, except in this case she was exposing the horrors of war in real time. (Frank’s written diary wasn’t published until six years after her death in the Holocaust.) In just two months, Bana amassed 200,000 Twitter followers, in the process becoming a human face for the hun- dreds of thousands of civilians caught in a messy civil war. At the same time, she gained powerful fans. Before an audience of millions, she cor- responded with Harry Potter author J. K. Rowling, receiving free copies of Rowling’s books and exposing a massive cross-section of Potter fans to the horrors of Aleppo.",
    "meta": {
      "theme": "Social Media & Information Warfare",
      "region": "Global/Syria",
      "use_case": "Raising Awareness/Humanitarian Advocacy",
      "strategic_category": [
        "geopolitical_strategy",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "information warfare",
        "civilian impact",
        "humanitarian crisis",
        "Syria"
      ],
      "influence_map": [],
      "chunk_index": 120
    },
    "id": "likewar_120"
  },
  {
    "section": "Part 4",
    "text": "As Bana’s account rocketed to global prominence, she sparked new information conflicts of her own. Critics alleged that Bana was actually a sockpuppet manufactured by the Syrian opposition, or that she was part of a top-secret propaganda operation run out of Britain. Rogue ac- counts were created, trying to trick people interested in Bana to click on them instead. They purported to show a little girl in a hijab with a gun, the insinuation that Bana was actually a jihadist. Then, as Bana weath- ered night after night of artillery bombardment (“I am very afraid I will die tonight. This bombs [sic] will kill me now”), even the president of Syria personally attacked the child. She was part of a “game of propa- ganda,” Bashar al-Assad said, concocted by “terrorists.” The social me- dia account of a 7-year-old girl had become a new flash point in the Syr- ian civil war’s ever-evolving information battle. The truth (eventually cobbled together by a Bellingcat investigation) was that Bana was indeed real: a young girl who had found a powerful outlet for her hopes and dreams through her instantly viral Twitter ac- count. There was one caveat, though. Bana wasn’t doing the tweeting alone; her English-literate mother, trained as a reporter, was helping her. This either proved or disproved her authenticity, depending on which side you took in the fight. Yet everything else ​— ​the videos of her stand- ing amidst playground rubble, the plaintive cries for help as the shells LikeWar 215 fell around her house ​— ​was as real as it was heart-stopping. Even after Bana and her family escaped Syria, she would remain a powerful voice for Syria’s refugees. It was a voice that couldn’t have existed just a de- cade before. But in its democratization of conflict and elevation of new voices, so- cial media presents a challenge. Whereas users like Bana employ the in- ternet to call for the end of war, others are eager to use it to start a new one. This dilemma is best captured in the Chinese proverb “If you ride a tiger, it’s hard to get off.” And China, where the internet has been ap- propriated as a tool to promote unitary nationalism, may be the best il- lustration of this danger.",
    "meta": {
      "theme": "Social Media, Propaganda & Information Warfare",
      "region": "Syria",
      "use_case": "Authenticity/Disinformation",
      "strategic_category": [
        "geopolitical_strategy",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "propaganda",
        "information warfare",
        "disinformation",
        "Syria"
      ],
      "influence_map": [],
      "chunk_index": 121
    },
    "id": "likewar_121"
  },
  {
    "section": "Part 1: Masters of the Universe",
    "text": "They’re targeting human minds. There’s one more aspect that makes them different from the conflicts of the past. Anyone can fight in them, but all the combatants are equally powerless in one key, new way. For while these warriors of LikeWar each fight their own personal and global wars across the internet, they aren’t the ones writing its rules.\n\nThere’s a war out there, a world war. And it’s not about who’s got the most bullets. It’s about who controls the information. What we see and hear, how we work, what we think… it’s all about the information!\n\nThey say necessity is the mother of invention. For Chad Hurley, Steve Chen, and Jawed Karim, that necessity was seeing Janet Jackson’s nipple during the 2004 Super Bowl halftime show. The ensuing “Nipplegate” controversy highlighted the difficulty in finding the uncensored footage, a problem YouTube was created to solve.\n\nThe internet giants of today often have humble beginnings, like Facebook's origin in the juvenile Facemash, Twitter's pivot from a failing podcasting service, and Google's start as a dissertation project. Despite their modest origins, these founders now rule digital empires that influence politics, war, and society.\n\nThere’s no historical analogue to the speed and totality with which social media platforms have conquered the planet. The surprise is most obvious among the creators themselves.  As their platforms grew, these founders weren’t pondering geopolitical implications; they were struggling to keep the servers running and attract investors.  “This is the original sin of Silicon Valley,” writes design ethicist Mike Monteiro. “The goal of every venture-backed company is to increase usage…until the people who gave you that startup capital get their payday.”\n\nEverything about these services was designed for growth, drawing users deeper into the online experience.  The notification icon, for example, leverages psychological arousal to keep users engaged.  While intended to make users’ lives easier, it also keeps them hooked on the app.\n\nThis single-minded push for growth is illustrated by a 2016 internal Facebook memo, written while Russian propagandists were using the platform and the Trump campaign was analyzing user data. The memo stated, “We connect people. Period…All the questionable contact importing practices…Maybe it costs someone a life…Maybe someone dies in a terrorist attack coordinated on our tools.”\n\nThese companies aren’t inventions but platforms—services that gain value from frequent, often addictive usage.  Scale allows the most successful Silicon Valley entrepreneurs to rule like absolute sovereigns.  A small tweak by Mark Zuckerberg becomes one of the largest collective experiences in human history.  Shifts in algorithms can make or break media outlets and even alter elections and wars.\n\nWe’re lucky these figures have chosen to rule benignly, mirroring the permissive speech codes of the United States. However, they’ve avoided reckoning with their own power.  Part of the reason is an inherent contradiction: these platforms are businesses, beholden to shareholders, not users or the UN.  Their metrics are stock price and revenue, not lives saved.\n\nThere’s also the technocratic optimism of engineers focused on building products. They weren't thinking about the potential negative consequences of their creations reaching billions of people.\n\nFinally, there’s a cultural tension: most platform builders dislike politics. This was evident in Hacker News’ “Political Detox Week” after the 2016 election.  As their work reshaped the political landscape, they tried to tune it out. This “engineering first” mentality leads to seeking technological solutions for political and social dilemmas.\n\nBut the excuses are wearing thin. It's one thing to deal with copyright infringement; it's another when the service abets terrorism and shatters political systems.  When Zuckerberg addresses pleas from Ukrainian activists or dispatches engineers to secure German elections, he’s no longer just a CEO, but a new kind of leader on the world stage.\n\nThe biggest challenge isn’t code, but corporate incentives, clashing cultures, and a revolution that has left politics and Silicon Valley reeling. It’s about giving politically pivotal responsibilities to engineers uninterested in politics. The core questions are: Should these companies restrict information? What should they restrict? And how should they do it?",
    "meta": {
      "theme": "The Rise of Social Media and its Unforeseen Consequences",
      "region": "Global",
      "use_case": "Information Warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture",
        "geostrategic_positioning"
      ],
      "economic_category": [
        "development_models"
      ],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "information control",
        "silicon valley",
        "political influence",
        "platform governance"
      ],
      "influence_map": [],
      "chunk_index": 122
    },
    "id": "likewar_122"
  },
  {
    "section": "Part 2: The Dirty Origins of Digital Freedom",
    "text": "“Marketing Pornography on the Information Superhighway…” Marty Rimm’s 1995 study, claiming 80% of the internet was pornography, became a sensation.  It was featured in major newspapers, debated on television, and landed on the cover of Time. Ironically, this viral report was fabricated. Rimm, a Carnegie Mellon student, bypassed peer review and had previously authored \"The Pornographer's Handbook,\" suggesting insincerity in his alarm about pornography.",
    "meta": {
      "theme": "Early Internet and Pornography",
      "region": "United States",
      "use_case": "Information Control and Censorship",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "internet history",
        "pornography",
        "censorship",
        "misinformation"
      ],
      "influence_map": [],
      "chunk_index": 123
    },
    "id": "likewar_123"
  },
  {
    "section": "Part 1: The Early Internet and the Birth of Section 230",
    "text": "As his work came under scrutiny and his claims that the internet was almost completely porn were debunked, Rimm vanished and eventually changed his name. Nonetheless, the damage had been done. While 1995 was a banner year for the internet, as the U.S. government officially relinquished control and millions of new users jumped online, in Congress this excitement gave way to moral panic. Thanks to one viral story and an audience of mostly tech-illiterate legislators, the internet now meant only one thing: pornography. “The information superhighway should not become a red-light district!” bellowed Senator James Exon, an elderly Democrat from Nebraska. He introduced the Communications Decency Act (CDA), which made it a crime to “send to or display in a manner available to” those under 18 years of age any communication that depicted “sexual or excretory activities . . . regardless of whether the user of such service placed the call or initiated the communication.” The punishment was two years in prison and a fine of $100,000. In 1996, the law passed with overwhelming bipartisan support. The final law had one crucial tweak, however. Two younger U.S. representatives ​— ​Chris Cox, a Republican from California, and Ron Wyden, a Democrat from Oregon ​— ​realized that unless something was done to protect websites that tried to police their own networks, the entire internet would be paralyzed by fear of lawsuits and prison time. Their consequent amendment became 47 U.S.C. § 230 (1996), known as Section 230. It was, in the words of Wired magazine, “the most important law in tech.” Section 230 provided “protection for ‘Good Samaritan’ blocking and screening of offensive material,” essentially ruling that no website could be held accountable for the speech of its users. And no website that made a “good-faith” effort to enforce applicable U.S. regulations could be punished, even if its efforts fell short. It was an amazingly permissive statute buried in one of the strictest “obscenity” laws ever passed by Congress. It was fortunate, then, that before the ink on the CDA had dried, the Supreme Court struck it down. Reno v. American Civil Liberties Union (1997) was the first and most important Supreme Court case to involve the internet. In a unanimous decision, the justices basically laughed the CDA out the door, noting that it massively violated the First Amendment. The only part of the CDA that survived was Section 230. Over the ensuing years, it would be consistently challenged and upheld. With each successful defense, its legal standing grew stronger. Outside of two specific exemptions (federal criminal law and intellectual property), the internet was mostly left to govern itself. As a result, most early corporate censorship ​— ​more politely known as “content moderation” ​— ​would come not because of government mandate, but to avoid involving government in the first place. As ever, money was the driver.",
    "meta": {
      "theme": "Internet Regulation & Censorship",
      "region": "United States",
      "use_case": "Legal Framework for Online Content",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "Section 230",
        "CDA",
        "First Amendment",
        "Content Moderation"
      ],
      "influence_map": [],
      "chunk_index": 124
    },
    "id": "likewar_124"
  },
  {
    "section": "Part 2: Copyright, Child Pornography, and the Rise of Automated Content Control",
    "text": "Over the next decade, questions regarding what constituted permissible online speech centered not on politics or propriety, but on property. Blogger (eventually acquired by Google), for example, was an early self-publishing hub that enabled millions of users to set up websites free of charge. And yet a visitor to Blogger’s home page in 1999 would find no list of rules, only a friendly reminder to properly configure your URL so you could be added to the master blog roll. Some blogs might host racist rants and pornography, the thinking went, but so what? This wasn’t a problem ​— ​it was the whole reason services like Blogger existed: to share the panoply of human expression, emotions, and beliefs. By contrast, violations of intellectual property rights were covered not by the permissive Section 230, but by the much stricter 1998 Digital Millennium Copyright Act (DMCA). This law imposed a maximum prison sentence of five years or a fine of $500,000 for the first offense of posting material for which someone else held a copyright. Fortunately, much like Section 230, the law also included a “safe harbor” provision. If websites promptly responded to a takedown notice filed by the copyright holder ​— ​without pausing to consider the merits of the request ​— ​ they could avoid being sued or jailed. Ground zero for the copyright battle was YouTube, whose nature made it an irresistible target for hosting copyrighted songs or videos. In 2006, YouTube placed a ten-minute limit on its videos, reasoning that longer clips were likely to be illegally hosted TV shows or movies. A year later, notably following Google’s $1.7 billion acquisition of the company, YouTube introduced its “Content ID” system, which assigned a unique digital fingerprint to tens of millions of copyrighted files. If Content ID spotted a match on YouTube’s servers, the file was automatically flagged for removal. This was the first use of sophisticated, wide- scale automation to control user content on a U.S. website. It was a sign of things to come. In another sign of things to come, the automated system went too far, disabling videos that contained even an incidental glimpse of copyrighted material. Just a few wayward seconds ​— ​like Katy Perry’s “I Kissed a Girl” playing in the background of a video shot in a crowded bar ​— ​was enough to nuke a whole clip. In 2008, Republican presidential candidate John McCain complained that his political ads were being automatically removed because they contained brief clips from broadcast news. Digital rights activists gleefully reminded McCain that he’d voted the DMCA into law a decade earlier. Happily, a small reprieve from copyright laws would arrive later that year, following an epic legal battle between the artist formerly known as Prince and a 13-month-old baby. The baby had been marked as a “copyright violator” after his mother uploaded a video of him pushing a toy stroller and laughing as Prince’s “Let’s Go Crazy” played for precisely twenty seconds in the background. The judicial ruling found, essentially, that the whole thing was ridiculous and that internet users had a right to plead “fair use” before their content was eradicated. YouTube’s copyright-sniffing algorithm was allowed to relax ​— ​but not much. Even as they strengthened their copyright controls, however, emerging social media titans confronted a far more horrifying problem: child pornography. Under Section 230, websites enjoyed broad legal immunity against charges of child abuse or exploitation. But use of a platform by child porn distributors wasn’t just a legal problem; it was a moral imperative, one whose mere mention could sink a company’s reputation. In 2009, Microsoft announced a free service called PhotoDNA. Applying a system much like that of Content ID, PhotoDNA compared each posted image and video with a massive database and instantly flagged any matches. Every major social media platform would eventually adopt the tool, essentially eliminating child pornography from their networks. Today, this top-secret, U.S. government–sanctioned database hosts more than a million instances of child pornography.",
    "meta": {
      "theme": "Content Moderation & Copyright",
      "region": "United States",
      "use_case": "Automated Content Control",
      "strategic_category": [],
      "economic_category": [
        "intellectual_property"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "DMCA",
        "Copyright",
        "YouTube",
        "Content ID",
        "PhotoDNA",
        "Child Pornography",
        "Fair Use"
      ],
      "influence_map": [],
      "chunk_index": 125
    },
    "id": "likewar_125"
  },
  {
    "section": "Part 3: Cyberbullying, Myspace, and the Evolution of Terms of Service",
    "text": "Other than addressing copyright infringement and child porn, by the mid-2000s Silicon Valley companies still did little to regulate user speech, clinging to the laissez-faire principles of the first generation of internet pioneers. But as the internet’s population passed 1 billion, that age had clearly ended. Social media platforms were clogged with eager users, including half of all American teenagers. Flush with hormonal drama and anguish, the vast digital commons increasingly resembled a powder keg. All it needed was a spark. That spark was provided in 2006, when the handsome, athletic, 16-year-old Josh Evans joined Myspace, the then-dominant social network. He liked the bands Rascal Flatts and Nickelback; among his “turn-ons” were tongue piercings and ear nibbling. He’d lived a hard life, born to a single mother who bounced between jobs. Nonetheless, Josh was upbeat. His goal, he confided, was to “meet a great girl.” Sadly, Josh had one flaw: he wasn’t real. He was a hoax ​— ​in the words of journalist Lauren Collins, “an online Frankenstein’s monster.” He was a sockpuppet built to exploit the hopes and vulnerabilities of one teenage girl. That target was 13-year-old Megan Meier, who ​— ​like most teenagers ​— ​maintained roller-coaster relationships with her peers. As she entered eighth grade, she fell out with a friend who lived just four houses away. That friend’s mother, 47-year-old Lori Drew, created Josh to spy on Meier, to see if the girl was saying mean things about her daughter. Drew solicited help from a 19-year-old employee of her small business and two other teenagers to run the fake account. Josh began a warm, flir- tatious online friendship with Meier. The attractive boy always seemed to know exactly what to say to make Meier happy. Indeed, how could he not? His creator knew Meier well; in a happier time, she had even joined the Drew family on vacations. The ruse soon turned to tragedy. After Meier got into an angry online argument with other classmates, Josh abruptly turned on her, taking the other kids’ side and peppering her with insults. In shock, Meier fled from the family computer and retreated to her room. When her mother checked on her a short time later, the 13-year-old was dead, hanging from an Old Navy belt. Her bereaved father uncovered the last message sent by Josh: “You’re a shitty person, and the world would be a better place without you in it.” The story swelled into a major scandal. Drew and her accomplices were tried for conspiracy, convicted, but then acquitted. Their actions were simply too new to have clearly violated any existing laws. That soon changed. As outrage spread and more reports emerged of online harassment, dozens of states enacted “cyberbullying” laws. For the first time, many Americans were forced to reckon with the potentially deadly offline consequences of online actions. For social media platforms, the death of Megan Meier was also a wake-up call. Myspace had never been in serious legal jeopardy. Indeed, Myspace was technically a victim, listed alongside Megan in the high- profile court case, because Drew had falsely represented herself to the company. But in the court of public opinion, the world’s largest social network faced a public relations disaster. If Myspace had done something, anything, might that young girl still be alive? For Myspace, Megan’s death was a setback from which it never recovered. For Silicon Valley at large, it was a sign that “terms of service” could no longer be a simple check box to placate jumpy investors. These user agreements had to become a new kind of law, penned by private corporations instead of governments, to administer communities of unprecedented scale. To be effective, these terms would have to be regularly monitored and updated, pulling engineers ever closer to the task of “regulating” free speech. To do otherwise ​— ​to leave hundreds of millions of users to say or do whatever they pleased ​— ​risked the government jumping in and passing ever more stringent legislation. In other words, to allow truly free speech would be financially ruinous.",
    "meta": {
      "theme": "Cyberbullying & Platform Responsibility",
      "region": "United States",
      "use_case": "Evolution of Terms of Service",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "Cyberbullying",
        "Myspace",
        "Terms of Service",
        "Online Harassment"
      ],
      "influence_map": [],
      "chunk_index": 126
    },
    "id": "likewar_126"
  },
  {
    "section": "Part 4: The Free Speech Ideal and the Reality of Twitter",
    "text": "Among the companies destined to rule the new social web ​— ​Twitter, Google, and Facebook ​— ​a shaky consensus emerged. All three banned personal threats or intimidation, soon expanding to include a more general ban on harassment. All but the free-spirited Twitter banned graphic violence and pornography, which included taking a hard-line stance against nudity. These rules seemed simple. They’d prove to be anything but. For Twitter, staffed by many of the same members of the idealistic team that had founded the original Blogger, the goal was to create a free- flowing platform, a libertarian ideal. “We do not actively monitor and will not censor user content, except in limited circumstances,” declared Twitter’s longstanding mission statement. A Twitter executive proudly described the company as “the free speech wing of the free speech party,” reminding all that it was the place to launch protests and topple dictators. By design, Twitter accounts were anonymous and essentially untraceable. All accounts could speak to all other accounts, unfiltered. The free speech haven became a perfect platform for rapid news distribution, but also a troll’s paradise. A graphic, personal threat wasn’t allowed, but anything short of that ​— ​like telling a Jewish user what would hypothetically happen to them in a second Holocaust ​— ​was fair game. The worst fate that could befall a Twitter user was an account ban, but as one neo-Nazi derisively pointed out to us, it took mere seconds to create a new one. As a result, the free speech haven became, in the words of one former employee, a “honeypot for assholes.” The first case of sustained harassment on Twitter occurred in 2008, as a female tech blogger endured months of insults, threats, and stalking from a network of anonymous accounts. “Twitter is a communication utility, not a mediator of content,” one founder coolly replied, as the backlash grew. For years, despite the paltry protection of its terms of service, Twitter would remain a brutally hostile place for women and nonwhite users. It would take until 2013 ​— ​amid a massive, sustained harassment campaign against female members of the British Parliament ​— ​for Twitter to introduce a way for users to directly report abusive tweets. A year later came “Gamergate,” an absurd scandal that began over the complaints of an obsessive ex-boyfriend and protests over “ethics in gaming journalism.” It ended with literally millions of abusive tweets hurled at a handful of female video game developers, the effective birth of the alt-right political movement, and an inquest by the United Nations.",
    "meta": {
      "theme": "Free Speech vs. Harassment on Twitter",
      "region": "Global/United States",
      "use_case": "Challenges of Content Moderation",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "Twitter",
        "Free Speech",
        "Harassment",
        "Gamergate",
        "Online Abuse"
      ],
      "influence_map": [],
      "chunk_index": 127
    },
    "id": "likewar_127"
  },
  {
    "section": "Masters of the Universe 229-231",
    "text": "“Freedom of expression means little as our underlying philosophy if we continue to allow voices to be silenced because they are afraid to speak up,” Twitter’s new general counsel concluded. By the end of 2015, the company’s promise not to censor user content had vanished from its mission statement. Ironically, YouTube’s more restrictive terms of service (“Don’t cross the line,” it said in big bold letters) led it almost immediately into thorny political questions. The platform banned “unlawful, obscene [or] threatening” videos. But this content proved difficult to define and regulate.\n\nThe first challenge came in 2007, when Mexican drug cartels flooded the service with music videos that featured the mutilated bodies of their enemies, intended to boost recruitment. YouTube tried to remove the videos as it discovered them. However, the same year, YouTube also deleted the videos of an Egyptian anti-torture activist, whose work necessarily documented torture. Following backlash from human rights groups, those videos were reinstated. In 2008, YouTube removed video of an air strike on Hamas fighters, whereupon the Israeli Defense Forces complained about the loss of its “exclusive footage.”\n\nThese relatively simple approaches by Twitter (avoid intervention) and YouTube (content bans) hardly registered next to the complex content moderation policies that emerged at Facebook. Facebook’s internal guidebooks soon came to resemble the constitutional law of a mid-sized nation. In 2009, its first attempt to codify its “abuse standards” ran to 15,000 words. Each new rule required more precise, often absurd clarification. It was one thing for Facebook to ban “incitement of violence”; it was quite another to say what that meant.\n\nLeaked slides of Facebook policy gave a horrifying example of the nuance. The message “Unless you stop bitching I’ll have to cut your tongue out” was permissible because the threats were conditional instead of certain. Even a seemingly black-and-white rule — like a ban on “nudity and sexual activity” — sowed controversy.  Historians and art critics pushed Facebook to allow nudity in photographs of paintings or sculptures but not in digital art. Then came the protests of new mothers, furious that their images of breastfeeding were being deleted.  This led Facebook into years of heated, internal deliberation, eventually settling on a policy that permitted portrayals of breastfeeding, but only so long as the nipple was not the principal focus of the image.\n\nThen came global politics. Originally, a firm could escape onerous censorship requests by arguing that it was a U.S. company. By the early 2010s, this was no longer a realistic defense. These companies had become multinational giants. As Silicon Valley’s ambition became truly international, its commitment to free speech sagged. In 2012, both Blogger and Twitter quietly introduced features that allowed governments to submit censorship requests on a per-country basis. The end of Silicon Valley as an explicitly American institution came in 2013, with Edward Snowden and the “Snowden Files.”  The files revealed an expansive U.S. spy operation that harvested the metadata of every major social media platform except Twitter. Google, Facebook, and Twitter began publishing “transparency reports” that detailed censorship and surveillance requests from every nation, including the United States.  “After Snowden,” explained Scott Carpenter, director of Google’s internal think tank, “[Google] does not think of itself all the time as an American company, but a global company.” From this point on, social media platforms would be governed by their own rules: a mix of remarkably permissive (regarding threats and images of graphic violence) and remarkably conservative (regarding nudity).",
    "meta": {
      "theme": "Content Moderation and Free Speech",
      "region": "United States, Global",
      "use_case": "Social Media Governance",
      "strategic_category": [
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "censorship",
        "free speech",
        "social media",
        "terrorism",
        "global politics",
        "surveillance"
      ],
      "influence_map": [
        "Edward Snowden leaks"
      ],
      "chunk_index": 128
    },
    "id": "likewar_128"
  },
  {
    "section": "Masters of the Universe 231-234",
    "text": "“Literally, I woke up in a bad mood and decided someone shouldn’t be allowed on the internet. No one should have that power.” In August 2017, Matthew Prince, CEO of Cloudflare, made a decision he’d spent a decade dreading. Cloudflare protected websites from cyberattacks. Thanks to Cloudflare, dissidents around the world were shielded from hackers. But so, too, were abhorrent voices. For years, Stormfront, a neo-Nazi forum, had relied on Cloudflare. After a white nationalist terror attack in Charlottesville, Stormfront users celebrated the murder. Outrage targeted Cloudflare for keeping the neo-Nazis online.  The company explained that it couldn’t revoke Stormfront’s accounts without “censoring the internet” — a position that led Stormfront to brag that Cloudflare was on its side.  Prince reversed course and pulled the plug, explaining in an email to his staff: “This was my decision…The people behind The Daily Stormer are assholes and I’d had enough…This was an arbitrary decision…I woke up this morning in a bad mood and decided to kick them off the internet…It’s important that what we did today not set a precedent.”\n\nThis was a landmark moment. A “content-neutral” company had made a decision to destroy content.  Prince’s decision echoed the dilemma faced by social media’s ruling class. Faced with campaigns to censor or delete speech, companies could either ignore their users, risking a PR disaster, or comply and be drawn deeper into political issues.  In avoiding governance, these companies had become governments unto themselves, grappling with intractable political problems.\n\nNations around the world had awoken to the influence that U.S. social media giants exerted over domestic politics. Between 2012 and 2017, some fifty countries passed laws restricting online speech. Even in the United States, tech-savvy politicians hovered, ready to impose new regulations if the companies didn’t tighten the rules themselves.  It was no longer enough to police copyright infringements, naughty pictures, and harassment.  Silicon Valley firms would be pushed ever closer to the role of traditional media companies, making editorial decisions about content allowed on their platforms.  The first and most obvious challenge was terrorism.  Al Qaeda and its copycats had begun posting propaganda on YouTube, including recordings of snipers killing U.S. soldiers. YouTube was slow to remove the clips.  The challenge proved even starker with the first internet-inspired terror attacks. Anwar al-Awlaki, an American-born Islamic cleric, began uploading Quranic lectures to YouTube, accumulating millions of views.  Although there was no explicit violence in the clips, his words promoted violence and inspired dozens of deadly attacks. The YouTube algorithm exacerbated the threat by creating a playlist of “related videos,” steering viewers to other terrorist propagandists. By 2011, al-Awlaki was sentenced to death in absentia by the Obama administration for online propaganda that “posed a continuing and imminent threat of violent attack.”  He was slain by a U.S. drone strike.  Al-Awlaki’s YouTube archive became a digital shrine, and his online voice grew even more popular.  The U.S. intelligence community noticed an uptick in views of his videos that accompanied spikes in terrorist attacks. It took YouTube another six years, until 2017, to block the videos.  Yet it was Twitter that became terrorists’ main social media haven. Terrorists who wanted to destroy freedom of speech found alignment with Twitter’s original commitment to it. The only line a terrorist couldn’t cross was personal harassment.  Although many voiced frustration, Twitter brushed off complaints. For aspiring terror groups, Twitter became the perfect platform to connect with followers and build brand recognition. Then came headlines Twitter couldn’t ignore. In 2013, four gunmen stormed Nairobi’s Westgate shopping mall. The attackers belonged to Al-Shabaab, whose members had been early Twitter adopters. Shabaab used the attack to pump out tweets, press releases, and even photos, becoming the main source for international journalists.  Reeling from bad press, Twitter suspended the terrorists’ account. Shabaab simply registered new ones.",
    "meta": {
      "theme": "Terrorism and Social Media",
      "region": "United States, Global, Kenya",
      "use_case": "Terrorist Exploitation of Social Media",
      "strategic_category": [
        "military_doctrine",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "terrorism",
        "social media",
        "censorship",
        "propaganda",
        "online extremism"
      ],
      "influence_map": [
        "Rise of ISIS",
        "Al-Shabaab attack on Westgate Mall"
      ],
      "chunk_index": 129
    },
    "id": "likewar_129"
  },
  {
    "section": "The Weaponization of Social Media & Initial Responses",
    "text": "boys, sockpuppets, and bots. As ISIS propaganda seeped across the platform in more than a dozen languages, Twitter executives were caught flat-footed. Their content moderation team simply wasn’t equipped to deal with the wholesale weaponization of their service. This wasn’t just for lack of interest, but also for lack of resources. Every employee hour spent policing the network was an hour not spent growing the network and demonstrating investor value. Was the purpose of the company fighting against propaganda or for profitability? Meanwhile, public outrage mounted. In 2015, Congress edged as close as it had in a decade to regulating social media companies, drafting a bill that would have required the disclosure of any “terrorist activity” discovered on their platforms (the definition of “terrorist activity” was kept intentionally vague). The same year, then-candidate Donald Trump seemed to endorse the internet censorship and balkanization practiced by authoritarian nations. “We have to talk to [tech CEOs] about, maybe in certain areas, closing that internet up in some ways,” he declared. “Somebody will say, ‘Oh freedom of speech, freedom of speech.’ Those are foolish people.” Twitter tried to act, but ISIS clung to it like a cancer. Militants developed scripts that automatically regenerated their network when a connection was severed. They made use of Twitter blocklists—originally developed to fight harassment—to hide their online activities from users who hunted them. Some accounts were destroyed and resurrected literally hundreds of times. When the rather obvious Twitter handle @IslamicState hit its hundredth iteration, it celebrated by posting an image of a birthday cake. Nonetheless, the growing suspensions changed the once-free terrain for ISIS. Thanks to diligent volunteer efforts, steady improvements to Twitter’s systems, and unrelenting public pressure, ISIS’s use of the platform gradually declined. In 2017, Twitter announced that its internal systems were detecting 95 percent of “troubling” terrorist accounts on its own and deleting three-quarters of them before they made their first tweet. It was a remarkable achievement—and an extraordinary turnabout from Twitter’s laissez-faire approach of just a few years before. Although Twitter’s transformation was the most dramatic, the other Silicon Valley giants charted a similar path. In 2016, Google piloted a program that used the advertising space of certain Google searches (e.g., “How do I join ISIS?”) to redirect users to anti-ISIS YouTube videos. It spoke to the seriousness with which Google was starting to treat the problem. Meanwhile, Facebook built a 150-person counterterrorism force. At the end of 2016, Facebook, Microsoft, Twitter, and Google circled back to where online censorship had begun. Emulating the success of Content ID and PhotoDNA, the companies now applied the same automated technique to terrorist propaganda, jointly launching a database for “violent terrorist imagery.” Just a few years before, they had insisted that such a system was impossible. This was another sign of how decisively the political landscape had shifted.",
    "meta": {
      "theme": "Content Moderation and Terrorism",
      "region": "Global",
      "use_case": "Counterterrorism",
      "strategic_category": [
        "military_doctrine",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "terrorism",
        "propaganda",
        "censorship",
        "regulation"
      ],
      "influence_map": [],
      "chunk_index": 130
    },
    "id": "likewar_130"
  },
  {
    "section": "From Terrorism to Extremism: Expanding the Scope of Content Moderation",
    "text": "Yet no matter how much these social media companies evolved, there were always outside forces pressuring them to do more. In 2015, Facebook was sued for $1 billion by relatives of Americans who had been killed during a spate of lone wolf terror attacks. The tech firm was accused of having “knowingly provided material support” to the terrorists. Around the same time, 20,000 Israelis brought suit against Facebook. Although the lawsuits were eventually dismissed, each new terror attack prompted further lawsuits by victims. The legal protections granted by Section 230—originally meant to police pornography—had now been pushed to the limit. Meanwhile, the precedent set by Silicon Valley’s well-publicized purge of ISIS accounts steered it toward other, even more painfully ambiguous political challenges. By 2015, ultranationalists, white supremacists, and anti-immigrant and anti-Islamic bigots had begun to coalesce into the alt-right movement.  They shrouded their sentiments in memes and coy references; they danced to the very edge of the line without crossing it. The alt-right leader Richard Spencer, for instance, didn’t use his popular Twitter profile to directly champion the killing of all Jews and blacks; instead, he simply observed how much nicer things would be if America were made white and pure. The extremists toyed with new ways of targeting people with anti-Semitic harassment. Such tactics made it easier for Gamergate-style hordes to find their targets online and bury them with slurs and abuse. If challenged, they claimed that they were “just trolling.”  For a time, Google, Facebook, and Twitter essentially threw up their hands and looked the other way. Racism and bigotry were distasteful, the companies readily admitted, but censoring distasteful things wasn’t their job. Plus, the tactics of these extremists—winking and nudging, dog-whistling and implying—were often too subtle for any terms of service to adequately address. But as Silicon Valley cranked up the pressure on terrorists and their supporters, it became easier to contemplate the next step: moving to combat a more general kind of “extremism.” In mid-2016, Twitter fired the first salvo, kicking the Breitbart writer and far-right provocateur Milo Yiannopoulos out of its service. Having won fame with his race-baiting, Yiannopoulos had finally crossed the line when he organized a campaign of online harassment targeting an African American actress.  Following a spate of more than 700 hate crimes across the country after the election of Donald Trump in November 2016, pressure began to build on the social media giants to do more about the hate that was not just allowed but empowered by their platforms, especially as it spurred violence. The crackdown started with the long-overdue Twitter suspension of white supremacist leader Richard Spencer.  But this digital purge was actually only a time-out. The alt-right used social media to organize a series of “free speech” events around the nation, culminating in that infamous Charlottesville rally. Amid the national outcry that followed, the social media giants moved to expand their definition of “hate speech” and banish the worst offenders from their services. This was a massive shift for an industry barely over a decade old. Since their founding, social media companies had stuck by the belief that their services were essentially a “marketplace of ideas,” one in which those that came to dominate public discourse would naturally be the most virtuous and rational. But Silicon Valley had lost the faith.",
    "meta": {
      "theme": "Extremism and Hate Speech",
      "region": "Primarily United States",
      "use_case": "Content Moderation",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "extremism",
        "hate speech",
        "alt-right",
        "censorship",
        "free speech"
      ],
      "influence_map": [],
      "chunk_index": 131
    },
    "id": "likewar_131"
  },
  {
    "section": "The 2016 Election and the Reckoning with Disinformation",
    "text": "The trouble went deeper than the specters of terrorism and far-right extremism, however. Silicon Valley was beginning to awaken to another, more fundamental challenge. This was a growing realization that all the doomsaying about homophily, filter bubbles, and echo chambers had been accurate. In crucial ways, virality did shape reality. And a handful of tech CEOs stood at the controls of this reality-shaping machine—but they hadn’t been working those controls properly. It was the election of Donald Trump that drove this realization home. Most deeply impacted was Facebook, whose mostly young and progressive employees feared that their work had elevated Trump to high office. Indeed, there was strong evidence that it had. Although Twitter had served as Trump’s treasured microphone, it was Facebook in which Americans had been at their most politically vulnerable, trapped in networks of people who thought just like them and who accorded hundreds of millions of “shares” to stories that were obvious hoaxes. Indeed, the whispers were already beginning that Facebook had been saturated not just with profit-motivated misinformation and “fake news” spun by Macedonian teenagers, but also with a pro-Trump disinformation campaign orchestrated by the Russian government. As stupefied liberals searched for someone or something to blame, Mark Zuckerberg could see the tidal wave coming. What followed was essentially a corporate version of psychiatrist Elisabeth Kübler-Ross’s five stages of grief: denial, anger, bargaining, depression, and acceptance. Zuckerberg’s first impulse was to deny. It was “a pretty crazy idea,” he said a few days after the election, that misinformation on his platform had influenced the outcome of anyone’s vote. After his initial denial was met with widespread fury and even a private scolding from President Obama, Zuckerberg shifted gears, penning a series of notes in which he vowed to try harder to counter hoaxes and misinformation on Facebook. At the same time, he tried to reassure users that this was a comparatively small problem. Meanwhile, frustrated Facebook employees began meeting in private to crowdsource solutions of their own. The truth then came out that some at the company had been concerned about rampant misinformation taking place on their platforms during the election, but had been prevented from making any changes for fear of violating Facebook’s “objectivity,” as well as alienating conservative users and legislators. By mid-2017, Facebook had struck a very different note. In the first report of its kind, Facebook’s security team published “Information Operations and Facebook,” a document explaining how its platform had fallen prey to “subtle and insidious forms of misuse.” In another first, Facebook publicly named its adversary: the government of the Russian Federation. Critics noted, however, that the company had waited a crucial nine months between when its executives knew that a massive campaign of Russian manipulation had occurred on its networks and when it informed its customers and American voters about it. Reflecting its ability to implement change when so motivated, however, Facebook expanded its cybersecurity efforts beyond regular hacking, turning its focus to the threat of organized disinformation campaigns. Where the company had studiously ignored the effects of disinformation during the 2016 U.S. election, it now cooperated closely with the French and German governments to safeguard their electoral processes, shutting down tens of thousands of suspicious accounts. A year after calling the idea of electoral influence “crazy,” Zuckerberg apologized for having ever said it. And in a very different speech, delivered via Facebook Live, Zuckerberg addressed his 2 billion constituents.",
    "meta": {
      "theme": "Disinformation and the 2016 Election",
      "region": "Primarily United States, with implications for France and Germany",
      "use_case": "Election Security, Content Moderation",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "disinformation",
        "fake news",
        "election interference",
        "cybersecurity"
      ],
      "influence_map": [],
      "chunk_index": 132
    },
    "id": "likewar_132"
  },
  {
    "section": "Part 1",
    "text": "use our tools to undermine democracy,” he said. “That’s not what we stand for.” This shift was driven in part by a reckoning that their creations had been used and disfigured. Even at the freewheeling Reddit, CEO Steve Huffman spoke of how he realized Russian propaganda had penetrated the site, but removing it would not be enough. “I believe the biggest risk we face as Americans is our own ability to discern reality from non-sense, and this is a burden we all bear.” Yet much of the impetus for change came in the form it always had — mounting legal and political pressures. In 2017, over the stren-uous objections of Silicon Valley lobbyists and free speech advocates, German lawmakers passed a bill that levied fines as high as $57 million on companies that failed to delete “illegal, racist, or slanderous” posts within twenty-four hours. Closer to home, U.S. legislators launched the first major effort to regulate online political advertisements, especially the “dark ads” used by Russian propagandists to spread disinforma-tion and by the Trump campaign to suppress minority voter turnout. It moved to subject them to the same Federal Election Commission dis-closure rules that applied to broadcast television. Previously, political advertising on social media — a multibillion-dollar industry — had en-joyed all the same exemptions as skywriting. For the titans of industry turned regulators of online war, it was an unexpected, unwanted, and often uncomfortable role to play. As Zuck-erberg confessed in a 2018 interview, shortly before he was brought to testify before the U.S. Congress, “If you had asked me, when I got started with Facebook, if one of the central things I’d need to work on now is preventing governments from interfering in each other’s elec-tions, there’s no way I thought that’s what I’d be doing, if we talked in 2004 in my dorm room.” With each step the social media giants took as they waded deeper into political issues — tackling terrorism, extremism, and misinforma-tion — they found themselves ever more bogged down by scandals that arose from the “gray areas” of politics and war. Sometimes, a new initia-tive to solve one problem might be exploited by a predatory government (Russia had a very different definition of “terrorism” than the United States) or well-meaning reporting systems gamed by trolls. Other times, it might lead to a clueless and costly mistake by a moderator expected to gauge the appropriateness of content from a country they’d never been to, amidst a political context they couldn’t possibly understand. One illustration of this problem was a Facebook rule, adopted to im-prove counterterrorism on the platform, that prohibited any positive mention of “violence to resist occupation of an internationally recog-nized state.” From an engineering standpoint, it was an elegant solu-tion — brief and broad. It was also one that any savvy political observer could have predicted would lead to massive problems. It led to mass de-letions of user content from Palestine, Kashmir, and Western Sahara, each a political and cultural powder keg ruled by an occupying power. These gray areas ran the gamut. A Chinese billionaire, taking ref-uge in the United States and vowing to reveal corruption among the highest ranks of the Communist Party, found his Facebook profile sus-pended for sharing someone else’s “personally identifiable information” (which had kind of been the point). In Myanmar, when members of the Rohingya Muslim minority tried to use Facebook to document a gov-ernment-led ethnic-cleansing campaign against them, some found their posts deleted — for the crime of detailing the very military atrocities they were suffering.",
    "meta": {
      "theme": "Content Moderation and Disinformation",
      "region": "Global",
      "use_case": "Social Media Platforms",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "political manipulation",
        "online warfare",
        "censorship"
      ],
      "influence_map": [],
      "chunk_index": 133
    },
    "id": "likewar_133"
  },
  {
    "section": "Part 2",
    "text": "Throughout this messy and inexorable politicization, however, there was one rule that all of Silicon Valley made sure to enforce: the bot-tom line. The companies that controlled so much of modern life were themselves controlled by shareholders, their decision-making guided by quarterly earnings reports. When a Twitter engineer discovered evi-dence of massive Russian botnets as far back as 2015, he was told to ig-nore it. After all, every bot made Twitter look bigger and more popular. “They were more concerned with growth numbers than fake and com-promised accounts,” the engineer explained. When Facebook employees confronted Mark Zuckerberg about then-candidate Trump’s vow to bar all Muslims from entering the United States, he acknowledged that it was indeed hate speech, in viola-tion of Facebook’s policies. Nonetheless, he explained, his hands were tied. To remove the post would cost Facebook conservative users — and valuable business. It was exactly as observed by writer Upton Sinclair a century earlier: “It is difficult to get a man to understand something when his salary de-pends on his not understanding it.” Today, the role of social media firms in public life is one that evades easy description. They are profit-motivated, mostly U.S.-based busi-nesses that manage themselves like global governments. They are charmingly earnest, preaching inclusivity even as they play host to the world’s most divisive forces. They are powerful entities that pretend to be powerless, inescapable political forces that insist they have no inter-est at all in politics. In essence, they are the mighty playthings of a small number of young adults, who have been given the unenviable task of shaping the nature of society, the economy, and now war and politics. And although the companies and those who lead them have matured an extraordinary amount in just a few years, the challenges they face only grow more complex. But the most important part of their work is finding the answer to an obvious question — the kind of question that engineers like to hear. As-sume that they’ve accepted the scope and complexity of their responsi-bilities, that they have decided to outlaw an unacceptable behavior and even defined exactly what that behavior looks like. How do they build the systems to stop it? What do those systems look like? Their answers have been to turn to the very same tools that created many of the prob-lems in the first place: the online crowd and pitiless machines.",
    "meta": {
      "theme": "Corporate Responsibility vs. Profit",
      "region": "Global",
      "use_case": "Social Media Platforms",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "ethics",
        "corporate influence",
        "content moderation"
      ],
      "influence_map": [],
      "chunk_index": 134
    },
    "id": "likewar_134"
  },
  {
    "section": "Part 3",
    "text": "COMMUNITY WATCHES AND DIGITAL SERFS America Online called them “community leaders,” but this vague cor-poratese hardly described who they were or what they did. Neverthe-less, a time traveler from thirteenth-century Europe would have recog-nized their role immediately. They were serfs — peasants who worked their feudal lord’s land in return for a cut of the harvest. AOL’s serfs just happened to toil through a dial-up modem. And their lord just hap-pened to be the first true internet giant. By the mid-1990s, AOL had evolved from a small internet service pro-vider into a sprawling digital empire. For millions of users, AOL was the internet: an online chat service, a constellation of hosted websites (AOL partnered with everyone from CNN to the Library of Congress) and forum boards, and a general internet browser. AOL was both a piece of software and a massive media service, one that eventually reached 26 million subscribers. It marketed itself by carpet-bombing millions of homes with blue CDs emblazoned with the AOL logo, promising “500 Hours Free!” At one time, half of all the CDs produced on earth were used for AOL free trials. Early in its corporate existence, AOL recognized two truths that ev-ery web company would eventually confront. The first was that the in-ternet was a teeming hive of scum and villainy. The second was that there was no way AOL could afford to hire enough employees to police it. Instead, AOL executives stumbled upon a novel solution. Instead of trying to police their sprawling digital commonwealth, why not enlist their most passionate users to do it for them? And so the AOL Community Leader Program was born. In exchange for free or reduced-price internet access, volunteers agreed to labor for dozens of hours each week to maintain the web communities that made AOL rich, ensuring that they stayed on topic and that porn was kept to a minimum. Given special screen names, or “uniforms,” that filled them with civic pride, they could mute or kick out disruptive users. As AOL expanded, the program grew more organized and bureau-cratic. The Community Leader Program eventually adopted a formal three-month training process. Volunteers had to work a minimum of four hours each week and submit detailed reports of how they’d spent their time. At its peak, the program boasted 14,000 volunteers, includ-ing a “youth corps” of 350 teenagers. AOL had effectively doubled its workforce while subsidizing roughly 0.0005 percent of its subscriber base, all while maintaining a degree of plausible deniability if anything went wrong. It seemed to be the best investment AOL ever made. Predictably, such a criminally good deal was bound for a criminal end. In 1999, two former community leaders sued AOL in a class-action lawsuit, alleging that they’d been employees in a “cyber-sweatshop” and that some were owed as much as $50,000 in back pay. A legal odyssey ensued. In 2005, AOL terminated the Community Leader Program, be-stowing a free twelve-month subscription on any remaining volunteers. In 2008, AOL was denied its motion to dismiss the lawsuit. And at last, in 2010 — long after AOL had been eclipsed by the likes of Google and Facebook — the company suffered its final indignity, forced to pay its volunteer police force $15 million in back pay. The rise and fall of AOL’s digital serfs foreshadowed how all big in-ternet companies would come to handle content moderation.",
    "meta": {
      "theme": "Early Content Moderation & Exploitation of Labor",
      "region": "United States",
      "use_case": "Online Community Management",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "digital labor",
        "crowdsourcing",
        "community management"
      ],
      "influence_map": [],
      "chunk_index": 135
    },
    "id": "likewar_135"
  },
  {
    "section": "Part III: Masters of the Universe",
    "text": " into profit gen- erators like new features, marketing, or literally anything else. Accord- ingly, companies will always view it as a tax on their business model. Af- ter all, no startup ever secured a round of funding by trotting out a shiny new gold-plated content moderation system. The second problem is scale. To paraphrase Winston Churchill, never before has so much, posted by so many, been moderated by so few. When WhatsApp was being used by ISIS to coordinate the first battle for Mosul, the company had just 55 employees for its 900 million us- ers. But even that made it a behemoth. When the newly launched video- hosting startup Vid.Me found itself infested by thousands of ISIS pro- paganda clips around the same time, the company had a total of just 6 people on staff, none of whom spoke Arabic. Even these numbers pale in comparison with the true social me- dia giants. Recall from chapter 3 the wealth of data that these services generate. Every minute, Facebook users post 500,000 new comments, 293,000 new statuses, and 450,000 new photos; YouTube users, more than 400 hours of video; and Twitter users, more than 300,000 tweets. Each of these posts is a Sword of Damocles hanging over the company. It can suffer devastating PR disasters if it allows any objectionable piece of content to stand for more than a few minutes before being deleted. But if a company acts rashly, the cries of censorship are liable to come just as fast. Masters of the Universe 247 Finally, if social media firms are to police their networks (which, re- member, they don’t really want to do), they must contend not just with millions of pieces of content, but also with adversaries who actively seek to thwart and confuse their content moderation systems. Think of the Islamic State’s resilient, regenerating Twitter network, the Russian gov- ernment’s believable sockpuppets, or the smirking alt-right memes that straddle the line between hateful jokes and raw hate. When Facebook announced in 2017 that it was hiring 250 more people to review advertis- ing on the platform, New York University business professor Scott Gal- loway rightly described it as “pissing in the ocean.” Under extraordinary pressure and facing an ever-expanding content moderation queue, the engineers of Silicon Valley have cast far and wide for an answer. Unsurprisingly, they think they’ve found that answer in more technology.",
    "meta": {
      "theme": "Content Moderation Challenges and Technological Solutions",
      "region": "Global",
      "use_case": "Social Media Platform Governance",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "content moderation",
        "scale",
        "adversarial actors",
        "technological solutions"
      ],
      "influence_map": [],
      "chunk_index": 136
    },
    "id": "likewar_136"
  },
  {
    "section": "Part III: Masters of the Universe",
    "text": "ROBO-REALITY WARS “you look like a thing and i love you.” As a Tinder pickup line, it needed work. But it wasn’t bad for some- thing that hadn’t even been written by a human. All AI specialist Janelle Shane had done was compile a list of existing pickup lines and taught the computer to read them. After that, an artificial brain ​— ​a neural net- work ​— ​studied the list and invented a new pickup line all on its own. Neural networks are a new kind of computing system: a calculating machine that hardly resembles a “machine” at all. Although such net- works were theorized as far back as the 1940s, they’ve only matured dur- ing this decade as cloud processing has begun to make them practical. Instead of rule-based programming that relies on formal logic (“If A = yes, run process B; if A = no, run process C”), neural networks resemble living brains. They’re composed of millions of artificial neurons, each of which draws connections to thousands of other neurons via “synapses.” Each neuron has its own level of intensity, determined either by the ini- tial input or by synaptic connections received from neurons farther up the stream. In turn, this determines the strength of the signal these neu- rons send down the stream through their own dependent synapses. 248 LikeWar These networks function by means of pattern recognition. They sift through massive amounts of data, spying commonalities and making inferences about what might belong where. With enough neurons, it be- comes possible to split the network into multiple “layers,” each discov- ering a new pattern by starting with the findings of the previous layer. If a neural network is studying pictures, it might start by discovering the concept of “edges,” sorting out all the edges from the non-edges. In turn, the next layer might discover “circles”; the layer after that, “faces”; the layer after that, “noses.” Each layer allows the network to approach a problem with more and more granularity. But each layer also demands exponentially more neurons and computing power. Neural networks are trained via a process known as “deep learning.” Originally, this process was supervised. A flesh-and-blood human engi- neer fed the network a mountain of data (10 million images or a library of English literature) and slowly guided the network to find what the en- gineer was looking for (a “car” or a “compliment”). As the network went to work on its pattern-sorting and the engineer judged its performance and tweaked the synapses, it got a little better each time. Writer Gideon Lewis-Kraus delightfully describes the process as tuning a kind of “gi- ant machine democracy.” Today, advanced neural networks can function without that human supervision. In 2012, engineers with the Google Brain project published a groundbreaking study that documented how they had fed a nine-layer neural network 10 million different screenshots from random YouTube videos, leaving it to play with the data on its own. As it sifted through the screenshots, the neural network ​— ​just like many human YouTube users ​— ​developed a fascination with pictures of cats. By discovering and isolating a set of cat-related qualities, it taught itself to be an effec- tive cat detector. “We never told it during the training, ‘This is a cat,’ ” explained one of the Google engineers. “It basically invented the con- cept of a cat.” Of course, the neural network had no idea what a “cat” was, nor did it invent the cat. The machine simply distinguished the pattern of a cat from all “not-cat” patterns. Yet this was really no different from the thought process of a human brain. Nobody is programmed from birth with a set, metaphysical definition of a cat. Instead, we learn a set of Masters of the Universe 249 catlike qualities that we measure against each thing we perceive. Every time we spot something in the world ​— ​say, a dog or a banana ​— ​we are running a quick probabilistic calculation to check if the object is a cat.",
    "meta": {
      "theme": "Neural Networks and Deep Learning",
      "region": "Global",
      "use_case": "Artificial Intelligence Applications",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "neural networks",
        "deep learning",
        "pattern recognition",
        "AI",
        "machine learning"
      ],
      "influence_map": [],
      "chunk_index": 137
    },
    "id": "likewar_137"
  },
  {
    "id": "likewar_138",
    "section": "Part 1",
    "text": "and Cisco once conspired to build China’s Great Firewall. But it doesn’t take an authoritarian state to turn a neural network toward evil ends. Anyone can build and train one using free, open- source tools. An explosion of interest in these systems has led to thousands of new applications. Some might be described as “helpful,” others “strange.” And a few — though developed with the best of intentions — are rightly described as nothing less than “mind-bendingly terrifying.” We’ve already seen how easy it is for obvious falsehoods (“The world is flat”; “The pizza parlor is a secret underage sex dungeon”) to take hold and spread across the internet. Neural networks are set to massively compound this problem with the creation of what are known as “deep fakes.” Just as they can study recorded speech to infer meaning, these networks can also study a database of words and sounds to infer the components of speech — pitch, cadence, intonation — and learn to mimic a speaker’s voice almost perfectly. Moreover, the network can use its mastery of a voice to approximate words and phrases that it’s never heard. With a minute’s worth of audio, these systems might make a good approximation of someone’s speech patterns. With a few hours, they are essentially perfect. One such “speech synthesis” startup, called Lyrebird, shocked the world in 2017 when it released recordings of an eerily accurate, entirely fake conversation between Barack Obama, Hillary Clinton, and Donald Trump. Another company unveiled an editing tool that it described as “Photoshop for audio,” showing how one can tweak or add new bits of speech to an audio file as easily as one might touch up an image.",
    "meta": {
      "theme": "Deepfakes and Generative Networks",
      "region": "Global",
      "use_case": "Disinformation and Manipulation",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "artificial intelligence",
        "deep learning",
        "misinformation",
        "social media"
      ],
      "influence_map": [],
      "chunk_index": 138
    }
  },
  {
    "section": "Conclusion",
    "text": "From a military perspective, SMEIR (Social Media Environment and Internet Replication) at Fort Polk is a surreal development. It simulates online activity to train troops for navigating the digital battlefield alongside the physical one.  This highlights the internet's transformation from a niche entity to a crucial battlespace.  However, even SMEIR struggles to capture the complexities of online conflict, where manipulation, botnets, and viral propaganda can overwhelm fact-checking and truth.  The digital battles are decided by global audiences and social media policies, not just events on the ground. Social media platforms, founded on optimistic ideals of connection, now grapple with their role in global conflicts.  Human susceptibility to disinformation, driven by our social nature, makes us vulnerable.  Youth offers no defense against these dangers; our species struggles with the internet's instantaneity and information overload. However, humans can learn and adapt.  The evolving information environment has rules:\n\n1. **Stability:** The internet's dominance and the key players will remain.\n2. **Battlefield:** The internet is a tool for manipulation, where conflict is continuous, the battlefield contiguous, and information contagious.\n3. **Information Redefined:** Digital records are pervasive, but belief determines power. Truth is obscured by psychological, political, and algorithmic manipulation.\n4. **Intertwined Warfare:** Online methods blur the lines between political and military competition.\n5. **Universal Participation:** We are all combatants in the information war, our online actions shaping the battlefield. LikeWar is not likeable, and it’s not what was promised.  Recognizing these truths allows us to focus on effective measures.",
    "meta": {
      "theme": "The Changing Nature of Warfare",
      "region": "Global",
      "use_case": "Military Training and Information Warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "information warfare",
        "social media",
        "military training",
        "disinformation",
        "internet"
      ],
      "influence_map": [],
      "chunk_index": 139
    },
    "id": "likewar_139"
  },
  {
    "section": "Conclusion (continued)",
    "text": "Governments, especially democratic ones, must take this new battleground seriously.  Social media's importance in various aspects of life makes it a crucial area for national and individual security. While authoritarian regimes have recognized its potential, the United States lags in preparedness and is seen as a negative example.  A \"whole-of-nation\" approach, similar to those adopted by countries facing Russian information attacks, is necessary.  This includes citizen education, public tracking of disinformation, election protections, and legal action against malicious actors.  Resurrecting Cold War-era initiatives like the Active Measures Working Group and creating an information clearinghouse akin to the Centers for Disease Control are vital.  However, the U.S. faces the challenge of political denial and collusion with these threats, hindering effective responses.  Information literacy is now a national security imperative, requiring early education in critical thinking and media analysis, along with public awareness campaigns.  While some advocate for abandoning social media, this is unrealistic given its integral role in modern life.  The technology itself is not inherently bad, but its use must be carefully managed.",
    "meta": {
      "theme": "Government Response and Information Literacy",
      "region": "Primarily United States, but also applicable globally",
      "use_case": "National Security Policy and Education",
      "strategic_category": [
        "national_security",
        "diplomatic_posture",
        "geostrategic_positioning"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "information literacy",
        "national security",
        "government policy",
        "disinformation",
        "election security"
      ],
      "influence_map": [],
      "chunk_index": 140
    },
    "id": "likewar_140"
  },
  {
    "section": "Conclusion",
    "text": "media, just of a different kind. While the technology has been used to foment a wide array of problems around the world, a number of leaders and nations have simultaneously embraced its participatory nature to do the opposite: to identify and enact shared policy solutions. Such “technocracy” views the new mass engagement that social networks allow as a mechanism to improve our civic lives. For instance, a growing number of elected governments don’t use social media just to frighten or anger their followers; they also use it to expand public awareness and access to programs, track citizen wants and needs, even gather proposals for public spending. Some also are seeking to inject it more directly into the political process. Switzerland, for instance, may be the world’s oldest continuous democracy, but it has been quick to use social networks to allow the digitization of citizen petitions and the insertion of online initiatives into its policy deliberations. In Australia and Brazil, the Flux movement seeks to use technology to return to true political representation, whereby elected leaders commit to a system allowing parliamentary submission of and digital voting on key issues, moving the power from the politician back to the people. What is common across these examples of governance via network is the use of social media to learn and involve. It is the opposite of governance via trolling—the all-too-frequent use of social media to attack, provoke, and preen. This points to perhaps the biggest challenge of all: it will be hard to overcome any system that incentivizes an opposite outcome. Not just our networks but our politics and culture have been swarmed by the worst aspects of social media, from lies and conspiracy theories to homophily and trolling. This has happened for the very reason that it works: it is rewarded with attention, and, as we have seen, this attention becomes power. Super-spreaders play a magnified role in our world; there is no changing that fact now. But it is how they are rewarded that determines whether their influence is a malign or benevolent one. When someone engages in the spread of lies, hate, and other societal poisons, they should be stigmatized accordingly. It is not just shameful but dangerous that the purveyors of the worst behaviors on social media have enjoyed increased fame and fortune, all the way up to invitations to the White House. Stopping these bad actors requires setting an example and ensuring that repeat offenders never escape the gravity of their past actions and are excluded from the institutions and platforms of power that now matter most in our society. In a democracy, you have a right to your opinion, but no right to be celebrated for an ugly, hateful opinion, especially if you’ve spread lie after lie. Indeed, social media actions need to be taken all the more seriously when their poisonous side infects realms like national security, where large numbers of people’s lives are at stake. Those who deliberately facilitate enemy efforts, whether it be providing a megaphone for terrorist groups or consciously spreading disinformation, especially that from foreign government offensives, have to be seen for what they are. They are no longer just fighting for their personal brand or their political party; they are aiding and abetting enemies that seek to harm all of society. We must also come to grips with the new challenge of free speech in the age of social media—what is known as “dangerous speech.” This term has emerged from studies of what prompts communal violence. It describes public statements intended to inspire hate and incite violent actions, usually against minorities. Dangerous speech isn’t merely partisan language or a bigoted remark. These are, alas, all too common.",
    "meta": {
      "theme": "Social Media and Governance",
      "region": "Global",
      "use_case": "Political discourse, information warfare",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "disinformation",
        "trolling",
        "technocracy",
        "dangerous speech",
        "free speech"
      ],
      "influence_map": [],
      "chunk_index": 141
    },
    "id": "likewar_141"
  },
  {
    "section": "Conclusion (continued)",
    "text": "Rather, dangerous speech falls into one or more of five categories: dehumanizing language (comparing people to animals or as “disgusting” or subhuman in some way); coded language (using coy historical references, loaded memes, or terms popular among hate groups); suggestions of impurity (that a target is unworthy of equal rights, somehow “poisoning” society as a whole); opportunistic claims of attacks on women, but by people with no concern for women’s rights (which allows the group to claim a valorous reason for its hate); and accusation in a mirror (a reversal of reality, in which a group is falsely told it is under attack, as a means to justify preemptive violence against the target). This sort of speech poses a mortal threat to a peaceable society, especially if crossed with the power of a super-spreader to give it both validation and reach. Cloaking itself in ambiguity and spreading via half-truths, dangerous speech is uniquely suited to social media. Its human toll can be seen in episodes like the web-empowered anti-Muslim riots of India and the genocide of the Rohingya people in Myanmar. But what the researchers who focus on the problem have grown most disturbed by is how “dangerous speech” is increasingly at work in the U.S. Instances of dangerous speech are at an all-time high, spreading via deliberate information offenses from afar, as well as via once-scorned domestic extremists whose voices have become amplified and even welcomed into the mainstream. The coming years will determine whether these dangerous voices will continue to thrive in our social networks, and thus our politics, or be defeated. This challenge takes us beyond governments and their voters to the accountability we should demand from the companies that now shape social media and the world beyond. It is a strange fact that the entities best positioned to police the viral spread of hate and violence are not legislatures, but social media companies. They have access to the data and patterns that evidence it, and they can more rapidly respond than governments. As rulers of voluntary networks, they determine the terms of service that reflect their communities’ and stockholders’ best interests. Dangerous speech is not good for either. This is just one dimension of the challenges these companies must confront. Put simply, Silicon Valley must accept more of the political and social responsibility that the success of its technology has thrust upon it. “The more we connect, the better it gets” is an old Facebook slogan that remains generally representative of how social media companies see the world. As we’ve seen, that slogan is neither true nor an acceptable way for these firms to approach the new role they play in society. Although figures like Mark Zuckerberg have protested at various times that they should not be considered “arbiters of the truth,” this is exactly what they are. The information that spreads via their services—governed by their legal and software codes—shapes our shared reality. If they aren’t the arbiters of truth, who is? Accordingly, these companies must abandon the pretense that they are merely “neutral” platform providers. It is a weak defense that they outgrew many years ago. Bigots, racists, violent extremists, and professional trolls do not have to be accorded the same respect as marginalized peoples and democratic states. In turn, the authoritarian governments that exploit their networks and target their users must be treated as adversaries—not potential new markets.",
    "meta": {
      "theme": "Social Media and Corporate Responsibility",
      "region": "Global",
      "use_case": "Platform governance, content moderation",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "dangerous speech",
        "corporate responsibility",
        "platform accountability",
        "misinformation"
      ],
      "influence_map": [],
      "chunk_index": 142
    },
    "id": "likewar_142"
  },
  {
    "section": "Introduction/Conclusion",
    "text": "the PhDs scored low. While certainly intelligent, they approached the information “verti- cally.” They stayed within a single worldview, parsing the content of only one source. As a result, they were “easily manipulated.” By contrast, the fact-checkers didn’t just recognize online manip- ulation more often, they also detected it far more rapidly. The reason was that they approached the task “laterally,” leaping across multiple other websites as they made a determination of accuracy. As the Stan- ford team wrote, the fact-checkers “understood the Web as a maze filled with trap doors and blind alleys, where things are not always what they seem.” So they constantly linked to other locales and sources, “seeking context and perspective.” In short, they networked out to find the truth. The best way to navigate the internet is one that reflects the very struc- ture of the internet itself. There is nothing inherently technological about this approach. In- deed, it’s taught by one of the oldest and most widely shared narratives in human history: the parable of the blind men and the elephant. This story dates back to the earliest Buddhist, Hindu, and Jain texts, almost 4,000 years ago. It describes how a group of blind men, grasping at dif- ferent parts of an elephant, imagine it to be many different things: a snake, a tree, a wall. In some versions of the story, the men fall to mortal combat as their disagreement widens. As the Hindu Rigveda summa- rizes the story, “Reality is one, though wise men speak of it variously.” When in doubt, seek a second opinion ​— ​then a third, then a fourth. If you’re not in doubt, then you’re likely part of the problem! What makes social media so different, and so powerful, is that it is a tool of mass communication whose connections run both ways. Every act on it is simultaneously personal and global. So in protecting ourselves online, we all, too, have broader responsibilities to protect others. Think of this obligation as akin to why you cover your mouth when you cough. You don’t do it because it directly protects you, but because it protects all those you come in contact with, and everyone whom they meet in turn. This ethic of responsibility makes us all safer in the end. It works the same way in social media. That leads us to a final point as to how to handle a world of “likes” and lies gone viral online. Here again, to succeed in the digital future is to draw upon the lessons of the past, including some of the oldest re- corded.",
    "meta": {
      "theme": "Navigating Online Information",
      "region": "Global",
      "use_case": "Information Literacy",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "critical thinking",
        "information warfare",
        "social media"
      ],
      "influence_map": [],
      "chunk_index": 143
    },
    "id": "likewar_143"
  },
  {
    "section": "Plato's Cave and The Matrix",
    "text": "Plato’s Republic, written around 520 bce, is one of the founda- tional works of Western philosophy and politics. One of its most impor- tant insights is conveyed through “The Allegory of the Cave.” It tells the story of prisoners in a cave, who watch shadows dance across the wall. Knowing only that world, they think the shadows are reality, when ac- tually they are just the reflections of a light they cannot see. (Note this ancient parallel to Zuckerberg’s fundamental notion that Facebook was “a mirror of what existed in real life.”) The true lesson comes, though, when one prisoner escapes the cave. He sees real light for the first time, finally understanding the nature of his reality. Yet the prisoners inside the cave refuse to believe him. They are thus prisoners not just of their chains but also of their beliefs. They hold fast to the manufactured reality instead of opening up to the truth. Indeed, it is notable that the ancient lessons of Plato’s cave are a core theme of one of the foundational movies of the internet age, The Matrix. In this modern reworking, it is computers that hide the true state of the world from humanity, with the internet allowing mass-scale manipula- tion and oppression. The Matrix came out in 1999, however, before so- cial media had changed the web into its new form. Perhaps, then, the new matrix that binds and fools us today isn’t some machine-generated simulation plugged into our brains. It is just the way we view the world, filtered through the cracked mirror of social media. But there may be something more. One of the underlying themes of Plato’s cave is that power turns on perception and choice. It shows that if people are unwilling to contemplate the world around them in its ac- tuality, they can be easily manipulated. Yet they have only themselves to blame. They, rather than the “ruler,” possess the real power ​— ​the power to decide what to believe and what to tell others. So, too, in The Matrix, every person has a choice. You can pick a red pill (itself now an internet meme) that offers the truth. Or you can pick a blue pill, which allows you to “believe whatever you want to believe.” Social media is extraordinarily powerful, but also easily accessible and pliable. Across it play out battles for not just every issue you care about, but for the future itself. Yet within this network, and in each of the conflicts on it, we all still have the power of choice. Not only do we determine what role we play, but we also influence what others know and do, shaping the outcomes of all these battles. In this new world, the same basic law applies to us all: You are now what you share. And through what you choose, you share who you truly are.",
    "meta": {
      "theme": "Power, Perception, and Choice in the Digital Age",
      "region": "Global",
      "use_case": "Understanding Information Manipulation",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "information warfare",
        "social media",
        "philosophy"
      ],
      "influence_map": [
        "Plato's Republic",
        "The Matrix"
      ],
      "chunk_index": 144
    },
    "id": "likewar_144"
  },
  {
    "section": "Acknowledgements",
    "text": "This book is the culmination of a five-year journey that began with an idle conversation about social media and the future of war, long before the Islamic State had reared its ugly head and the Russian government transformed U.S. politics forever. In the years since, we’ve faced shock, surprise, discovery, and ​— ​as you might imagine ​— ​lots and lots of re- writes. We owe debts of gratitude to more than these pages can fill, but we’ll try our best. [Omitted Acknowledgements section for brevity]",
    "meta": {
      "theme": "Book's Genesis and Acknowledgements",
      "region": "Global",
      "use_case": "Meta-Information",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [],
      "influence_map": [],
      "chunk_index": 145
    },
    "id": "likewar_145"
  },
  {
    "section": "Notes",
    "text": "1. THE WAR BEGINS page 1 “It was an extraordinary”: George Orwell, Homage to Catalonia (Hough- ton Mifflin Harcourt, 2015), 33. [Rest of notes omitted for brevity]",
    "meta": {
      "theme": "Book's References/Notes",
      "region": "Global",
      "use_case": "Meta-Information",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [],
      "influence_map": [
        "George Orwell, Homage to Catalonia"
      ],
      "chunk_index": 146
    },
    "id": "likewar_146"
  },
  {
    "section": "Introduction and Trump's Twitter Use",
    "text": "Trump's prolific use of Twitter, escalating from 59 messages in 2009 to 3,531 in 2012, transformed political communication.  Analysis of his tweets reveals a distinct style, often angrier and more direct.  Trump used Twitter to attack political opponents, spread misinformation (like the birther conspiracy), and mobilize his base.  This constant engagement, driven by the dopamine-reward system of social media, allowed him to bypass traditional media and connect directly with a vast audience.  By 2016, he had sent approximately 15,000 tweets, reaching a significant portion of Americans in a nation where nine-tenths of the population were online. Twitter, with its 300 million active users, became Trump's primary tool for disseminating information and shaping public discourse.",
    "meta": {
      "theme": "The Rise of Social Media in Warfare and Politics",
      "region": "United States",
      "use_case": "Political Communication and Propaganda",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos"
      ],
      "usage_tags": [
        "social media",
        "twitter",
        "political campaigns",
        "misinformation",
        "propaganda"
      ],
      "influence_map": [],
      "chunk_index": 147
    },
    "id": "likewar_147"
  },
  {
    "section": "ISIS and the Weaponization of Social Media",
    "text": "The rise of ISIS demonstrated the potent weaponization of social media in modern conflict. ISIS leveraged platforms like Twitter to amplify its message, recruit foreign fighters, and instill fear.  Their sophisticated use of hashtags, viral images (like those of Toyota trucks seized in Mosul), and direct engagement with potential recruits proved remarkably effective.  In Iraq, where three-quarters of the population used smartphones and nearly 4 million people had internet access, ISIS's online propaganda easily reached a vast and impressionable audience.  The fall of Mosul, a metropolis of 1.8 million, highlighted the group's military strength and the Iraqi army's vulnerability.  The seizure of advanced weaponry, including Humvees, M1A1 tanks, and even Black Hawk helicopters, further enhanced ISIS's image of power and invincibility.",
    "meta": {
      "theme": "The Rise of Social Media in Warfare and Politics",
      "region": "Middle East (Iraq, Syria)",
      "use_case": "Terrorism, Propaganda, Recruitment",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "civilizational_missions"
      ],
      "usage_tags": [
        "social media",
        "terrorism",
        "propaganda",
        "recruitment",
        "psychological warfare"
      ],
      "influence_map": [],
      "chunk_index": 148
    },
    "id": "likewar_148"
  },
  {
    "section": "The Impact of Social Media on Conflict and Warfare",
    "text": "The rise of social media has fundamentally altered the nature of conflict and warfare.  From influencing public opinion to coordinating military operations, social media platforms have become integral tools.  The Mosul offensive exemplified this transformation.  The Iraqi army used portable cellphone towers to restore communication and counter ISIS propaganda.  Soldiers shared grinning selfies, while hashtags like #FreeMosul rallied international support.  Special operators engaged in psychological warfare, even impersonating ISIS propagandists online.  Drones were shot down, and the fighting was livestreamed, providing real-time access to a global audience.  Tens of thousands of civilians were rescued, aided by information gleaned from social media. The 2012 Gaza conflict further illustrated social media's influence, with “Twitter wars” impacting the conflict's trajectory. Social media's role in shaping perceptions, mobilizing support, and even directing military operations became undeniable.",
    "meta": {
      "theme": "The Rise of Social Media in Warfare and Politics",
      "region": "Middle East (Iraq, Gaza)",
      "use_case": "Information Warfare, Psychological Operations, Humanitarian Aid",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "information warfare",
        "psychological operations",
        "humanitarian aid",
        "livestreaming"
      ],
      "influence_map": [],
      "chunk_index": 149
    },
    "id": "likewar_149"
  },
  {
    "section": "Social Media and Gang Violence",
    "text": "Beyond international conflicts, social media also plays a significant role in localized violence, such as gang warfare in Chicago.  Online platforms have become battlegrounds for “cyberbanging,” where gangs taunt rivals, settle personal scores, and even incite violence.  Disparaging remarks on Facebook, “cybertag” challenges, and “cyberbang” threats often escalate into real-world confrontations.  Chicago, with its high rate of gang violence, provides a stark example.  Digital sociologists describe this phenomenon as the blurring of online and offline spaces, where the anonymity and reach of the internet amplify the impact of threats and insults.  In Chicago, an estimated 80 percent of gang fights are now linked to social media activity. Regional variations in “cyberbanging” exist, with specific terminology and tactics. The ease with which individuals can issue threats online contributes to the escalation of violence, transforming social media into a dangerous tool in the hands of gangs.",
    "meta": {
      "theme": "The Rise of Social Media in Warfare and Politics",
      "region": "United States (Chicago)",
      "use_case": "Gang Violence, Cyberbanging",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos"
      ],
      "usage_tags": [
        "social media",
        "gang violence",
        "cyberbanging",
        "online threats",
        "urban conflict"
      ],
      "influence_map": [],
      "chunk_index": 150
    },
    "id": "likewar_150"
  },
  {
    "section": "Introduction",
    "text": "Gangs are increasingly using online platforms to challenge rivals.14 This includes sharing music videos,14 engaging in dueling Instagram posts,14 and even issuing death threats online.14  El Salvadoran drug gangs have been particularly active in using social media to maintain control and intimidate communities.14  The fragile peace in Colombia in 2016 saw a shift from rifles to smartphones as tools of communication and influence.14  Philippine President Rodrigo Duterte, considered the first \"social media president,\"15 used a custom emoji15 and online platforms to conduct a brutal crackdown,15 discrediting journalists15 and sowing false stories.15  This resulted in the deaths of more than 12,000 people.15  Similar online conflicts have played out between Israelis and the Palestinian Authority,15 with dueling \"Facebook militias\"16 and online \"expeditions.\"16  China has been constantly pushing nationalist narratives online regarding the South China Sea.16  These online activities are limiting leaders' options and impacting international relations.16",
    "meta": {
      "theme": "The use of social media in conflict and international relations",
      "region": "Global",
      "use_case": "Information warfare, political manipulation, gang violence",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "conflict",
        "propaganda",
        "information warfare",
        "gangs",
        "international relations"
      ],
      "influence_map": [],
      "chunk_index": 151
    },
    "id": "likewar_151"
  },
  {
    "section": "Historical Context of Communication and War",
    "text": "Carl von Clausewitz argued that war is a \"continuation of political intercourse\" by other means.17 This implies that the methods of communication used during peacetime naturally extend into wartime and the subsequent peace.17  The concept of a \"center of gravity\" in warfare highlights the importance of targeting the enemy's key strengths, which often include moral elements.18  The Vietnam War, with its massive bombing campaigns (6.5 million tons of bombs)18 and high casualties,18 demonstrates the destructive potential of traditional warfare.  However, even during that era, the use of shortwave radio for propaganda and entertainment played a significant role.18  Today, social media platforms have become the new battleground for information warfare, as seen with the controversies surrounding Twitter20 and the spread of misinformation.",
    "meta": {
      "theme": "The evolution of communication in warfare",
      "region": "Global",
      "use_case": "Information warfare, propaganda, historical context of war",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "Clausewitz",
        "center of gravity",
        "Vietnam War",
        "shortwave radio",
        "propaganda",
        "information warfare",
        "social media"
      ],
      "influence_map": [
        "Carl von Clausewitz, On War"
      ],
      "chunk_index": 152
    },
    "id": "likewar_152"
  },
  {
    "section": "The Rise of the Interconnected World",
    "text": "Ray Bradbury's vision of interconnectedness in \"I Sing the Body Electric!\"24 foreshadowed the rise of the internet.  In 1994, the public's understanding of the internet was still rudimentary.24  Now, roughly half the world's population is online,24 with many constantly connected.24  Licklider and Taylor's 1968 paper envisioned a future where computers would facilitate communication and collaboration on a global scale, creating an \"Intergalactic Computer Network.\"26  This vision, though initially focused on scientific collaboration, recognized the potential for individual empowerment and global community building.26  Wheeler's concept of \"It from Bit\" suggests a fundamental link between information and reality.26  The internet has become a \"competitor to ourselves,\"26 constantly vying for our attention and influencing our perceptions.",
    "meta": {
      "theme": "The development and impact of the internet",
      "region": "Global",
      "use_case": "Communication, information dissemination, global interconnectedness",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "internet",
        "communication",
        "information",
        "global interconnectedness",
        "digital age"
      ],
      "influence_map": [
        "Ray Bradbury, I Sing the Body Electric!",
        "J.C.R. Licklider and Robert W. Taylor, The Computer as a Communication Device",
        "John Archibald Wheeler, It from Bit"
      ],
      "chunk_index": 153
    },
    "id": "likewar_153"
  },
  {
    "section": "The History of Information Dissemination",
    "text": "The history of information dissemination, from the invention of printing in China28 to the advent of the internet, reveals a continuous evolution in the speed and reach of communication. Gutenberg's printing press revolutionized the spread of knowledge, making books more accessible.28  The printing press played a key role in the Reformation, as Luther's ideas spread rapidly through printed pamphlets.28  The development of newspapers in the 17th century provided a new platform for disseminating news and opinions, with publications like \"Mrs. Silence Dogood\" offering social commentary.29  The marathon, inspired by Pheidippides' legendary run,29 highlights the human desire to quickly convey important information.29  The Roman imperial post, capable of covering fifty miles per day,29 and the invention of the telegraph in the 19th century further accelerated the speed of communication.29  The telegraph, with its vast network of wires,30 was hailed as \"the peacemaker of the age\"30 for its potential to foster understanding between nations.30  However, the rise of yellow journalism in the late 19th century demonstrated the potential for new technologies to be used for sensationalism and propaganda.31",
    "meta": {
      "theme": "The evolution of information dissemination technologies",
      "region": "Global",
      "use_case": "Communication, news dissemination, propaganda, historical context of media",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "printing press",
        "newspapers",
        "telegraph",
        "yellow journalism",
        "propaganda",
        "information dissemination",
        "communication"
      ],
      "influence_map": [],
      "chunk_index": 154
    },
    "id": "likewar_154"
  },
  {
    "section": "War, 43. 31 “No Fake War News”: Adrienne LaFrance, “How the Fake News Crisis of 1896 Explains Trump,”",
    "text": "War, 43. 31 “No Fake War News”: Adrienne LaFrance, “How the Fake News Crisis of 1896 Explains Trump,” The Atlantic, January 19, 2017, https://www.theatlantic.com/technology/archive/2017/01/the-fake-news-crisis-120-years-ago/513710/?utm_source=feed. 31 number to call: “This Day in History: 1877, Hayes Has First Phone Installed in White House,” History.com, http://www.history.com/this-day-in-history/hayes-has-first-phone-installed-in-white-house. first to build: Anthony Brown, Great Ideas in Communication (D. White, 1969), 141. aggressively peddled it: Marc Raboy, Marconi: The Man Who Networked the World (Oxford University Press, 2016), 423. played “O Holy Night”: Neuman, Lights, Camera, War, 137. 20 million radio listeners: Ibid., 139. just ten minutes: Ibid., 140. four-fifths of American households: Ibid., 149. divert the news: Ibid., 151. “It would not”: Joseph Goebbels, “The Radio as the Eighth Great Power,” in Signals of the New Era: 25 Selected Speeches by Dr. Joseph Goebbels (Munich: Zentralverlag der NSDAP, 1938). nearly a thousand: Neuman, Lights, Camera, War, 148. “propagandistic casus belli”: Roy Godson and James J. Wirtz, Strategic Denial and Deception: The Twenty-First Century Challenge (Transaction, 2011), 100. “Around the world”: Donald M. Bishop, “Classic Quotable: Robert D. Leigh on the Aims of Broadcasting During World War II (1944),” Public Diplomacy Council, http://www.publicdiplomacycouncil.org/commentaries/10-13-15/classic-quotable-robert-d-leigh-aims-broadcasting-during-world-war-ii-1944 (page deleted). ventriloquist’s dummy: Andrew Liszewski, “TVs in the 1920s Had Bottle Cap–Sized Screens, with Just 30 Lines of Resolution,” Gizmodo, January 16, 2017, http://gizmodo.com/in-1929-tvs-had-bottle-cap-sized-screens-with-just-30-l-1791250849?utm_campaign=socialflow_gizmodo_twitter&utm_source=gizmodo_twitter&utm_medium=socialflow. nine of ten American homes: Jordan Winthrop, The Americans (McDougal Littell, 1996), 798. “the most trusted man”: “Final Words: Cronkite’s Vietnam Commentary,” All Things Considered, NPR, July 18, 2009, http://www.npr.org/templates/story/story.php?storyId=106775685. “I’ve lost Middle America”: Louis Menand, “Seeing It Now,” The New Yorker, July 9, 2012, https://www.newyorker.com/magazine/2012/07/09/seeing-it-now.",
    "meta": {
      "theme": "Evolution of Information Warfare",
      "region": "United States, Global",
      "use_case": "Propaganda, Public Opinion, Political Influence",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "historical_memory"
      ],
      "usage_tags": "media, technology, war, propaganda, internet",
      "influence_map": [],
      "chunk_index": 155
    },
    "id": "likewar_155"
  },
  {
    "section": "From University Computer Labs to the Information Superhighway",
    "text": "fifteen university computer labs: Ryan, A History of the Internet, loc. 490. its first international connection: Ibid., loc. 613. The “@” symbol: Ian Peter, “The History of Email,” NetHistory, http://www.nethistory.info/History%20of%20the%20Internet/email.html. The email subject: Judy Malloy, “The Origins of Social Media,” in Social Media Archeology and Poetics, edited by Judy Malloy (Cambridge, MA: MIT Press, 2016), 10. “we had a social medium”: Vint Cerf, phone interview with authors, May 23, 2016. Yumyum: Ibid. a good stress test: Ryan, A History of the Internet, loc. 1446. the humble emoticon: “Original Bboard Thread in Which :-) Was Proposed,” Carnegie Mellon University School of Computer Science, http://www.cs.cmu.edu/~sef/Orig-Smiley.htm. old and familiar things: This is not an uncommon phenomenon. See Andrew Chadwick, The Hybrid Media System (New York: Oxford University Press, 2017). 70 institutions: Ryan, A History of the Internet, loc. 1673. AT&T said “no thanks”: Ibid., loc. 1645. grew to nearly 160,000: Ibid., loc. 1778. “Lay down thy packet”: Alex Scroxton, “CW@50: The Story of the Internet, and How It Changed the World,” Computer Weekly, July 2016, http://www.computerweekly.com/feature/CW50-The-story-of-the-internet-and-how-it-changed-the-world. “information superhighway”: High Performance Computing Act of 1991, Pub. L. No. 102-194, 105 Stat. 1594 (1991). NSFNET formally closed: Ryan, A History of the Internet, loc. 2367. reached 360 million: “Internet Users,” Internet Live Stats, accessed March 16, 2018, http://www.internetlivestats.com/internet-users/. worth $3 billion: Adam Lashinsky, “Netscape IPO 20-Year Anniversary: Read Fortune’s 2005 Oral History of the Birth of the Web,” Fortune, http://fortune.com/2015/08/09/remembering-netscape/. “Google” symbolized: “Our Story: From the Garage to the Googleplex,” Google, https://www.google.com/about/our-story/.",
    "meta": {
      "theme": "Development of the Internet",
      "region": "United States, Global",
      "use_case": "Communication, Information Sharing, Technological Advancement",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [
        "development_models"
      ],
      "civilizational_category": [
        "temporal_orientation"
      ],
      "usage_tags": "internet, technology, communication, email, social media",
      "influence_map": [],
      "chunk_index": 156
    },
    "id": "likewar_156"
  },
  {
    "section": "The Rise of Social Media and Mobile Technology",
    "text": "Twelve thousand soldiers: David Ronfeldt et al., The Zapatista Social Netwar in Mexico (monograph, RAND, 1998), 2, https://www.rand.org/content/dam/rand/pubs/monograph_reports/1998/MR994.pdf. more than 130 countries: Ibid., 117. “a war on the internet”: Ibid., 4. “rumor first reported”: “Scandalous Scoop Breaks Online,” BBC News, January 25, 1998, http://news.bbc.co.uk/2/hi/special_report/1998/clinton_scandal/50031.stm. “comparable to”: Manuel Castells, The Information Age: Economy, Society and Culture, vol. 1, The Rise of the Networked Society, quoted in Paul DiMaggio et al., “Social Implications of the Internet,” Annual Review of Sociology 27 (2001): 309. Bowie waxed philosophical: Matt Novak, “Watching David Bowie Argue with an Interviewer About the Future of the Internet Is Beautiful,” Paleofuture, January 10, 2017, https://paleofuture.gizmodo.com/watching-david-bowie-argue-with-an-interviewer-about-th-1791017656. “The goal wasn’t”: Mark Zuckerberg, “Facebook Interview,” YouTube video, 04:49, uploaded by Derek Franzese, March 26, 2013, https://www.youtube.com/watch?v=—APdD6vejI. had built ZuckNet: Phillip Tracy, “Before Facebook, There Was ‘ZuckNet,’ the Chat Service 12-Year-Old Mark Zuckerberg Built for His Family,” The Daily Dot, https://www.dailydot.com/debug/mark-zuckerberg-messaging-service-zucknet/. a bold, crude proclamation: Bari Schwartz, “Hot or Not? Website Briefly Judges Looks,” Harvard Crimson, November 4, 2003, http://www.thecrimson.com/article/2003/11/4/hot-or-not-website-briefly-judges/?page=single. some 22,000 votes: Ibid. 20,000 students: Rachel Feintzeig, “Students Flock to Join College Online Facebook,” Daily Pennsylvanian, March 18, 2004, https://web.archive.org/web/20110825022008/http://thedp.com/node/41990. “I’ve been paralyzed”: Ibid. 3.5 million registered members: Julia Angwin, Stealing MySpace: Battle to Control the Most Popular Website in America (Random House, 2009), 52. shortened to “blogs”: Tim Dowling, “Should We Ban the Word ‘Blog’?” Books (blog), The Guardian, March 22, 2007, https://www.theguardian.com/books/booksblog/2007/mar/22/shouldwebanthewordblog. 100 million active blogs: Jenna Wortham, “After 10 Years of Blogs, the Future’s Brighter Than Ever,” Wired, December 17, 2007, https://www.wired.com/2007/12/after-10-years-of-blogs-the-futures-brighter-than-ever/. $2.5 trillion: Adjusted for inflation. David Kleinbard, “The $1.7 Trillion Dot.Com Lesson,” CNNMoney, November 9, 2000, http://cnnfn.cnn.com/2000/11/09/technology/overview/. 820 million: “Internet Users.” 50 percent each year: Jakob Nielsen, “Nielsen’s Law of Internet Bandwidth,” Nielsen Norman Group, April 5, 1998, https://www.nngroup.com/articles/law-of-bandwidth/. voice of Salem: Sabrina, the Teenage Witch, IMDb, http://www.imdb.com/title/tt0115341/. “Web 2.0”: Tim O’Reilly, “What Is Web 2.0: Design Patterns and Business Models for the Next Generation of Software,” O’Reilly (website), September 30, 2005, http://www.oreilly.com/pub/a/web2/archive/what-is-web-20.html. more than 2 million articles: “Wikipedia Publishes 2-Millionth Article,” Reuters, September 12, 2007, https://www.reuters.com/article/us-wikipedia-growth/wikipedia-publishes-2-millionth-articleidUSN1234286820070912. 3 million users: Gary Rivlin, “Wallflower at the Web Party,” New York Times, October 15, 2006, http://www.nytimes.com/2006/10/15/business/yourmoney/15friend.html?_r=1&mtrref=en.wikipedia.org.",
    "meta": {
      "theme": "Rise of Social Media and Mobile Technology",
      "region": "United States, Global",
      "use_case": "Social Networking, Information Dissemination, Technological Innovation",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [
        "development_models"
      ],
      "civilizational_category": [
        "cultural_ethos",
        "temporal_orientation"
      ],
      "usage_tags": "social media, mobile technology, internet, facebook, blogs",
      "influence_map": [],
      "chunk_index": 157
    },
    "id": "likewar_157"
  },
  {
    "section": "Facebook, Smartphones, and the Mobile Web",
    "text": "more than a million active accounts: Ami Sedghi, “Facebook: 10 Years of Social Networking, in Numbers,” The Guardian, February 4, 2014, https://www.theguardian.com/news/datablog/2014/feb/04/facebook-in-numbers-statistics. 58 million users: Ibid. “300 million stories a day”: Tom Loftus, “Mark Zuckerberg’s Best Quotes,” Digits (blog), Wall Street Journal, February 1, 2012, http://blogs.wsj.com/digits/2012/02/01/mark-zuckerbergs-best-quotes/. 2 billion users: Kaya Yurieff, “Facebook Hits 2 Billion Monthly Users,” CNNMoney, June 27, 2017, http://money.cnn.com/2017/06/27/technology/facebook-2-billion-users/index.html. He would show off: Sarah Perez, “Mark Zuckerberg Meets Pope Francis, Gives Him a Drone,” TechCrunch, August 29, 2016, https://techcrunch.com/2016/08/29/mark-zuckerberg-meets-pope-francis-gives-him-a-drone/. arbitrate the pleas: Vitaly Shevchenko, “Ukrainians Petition Facebook Against ‘Russian Trolls,’ ” BBC News, May 13, 2015, http://www.bbc.com/news/world-europe-32720965. “Apple is reinventing”: Mic Wright, “The Original iPhone Announcement Annotated: Steve Jobs’ Genius Meets Genius,” The Next Web, September 9, 2015, https://thenextweb.com/apple/2015/09/09/genius-annotated-with-genius/. $10,000: John F. Clark, “History of Mobile Applications,” http://www.uky.edu/~jclark/mas490apps/History%20of%20Mobile%20Apps.pdf. as far back as 1997: Abdulrauf M. Ahmad, “The World’s First ‘Smartphone’ Was Launched on 1997,” LinkedIn, April 9, 2016, https://www.linkedin.com/pulse/worlds-first-smartphone-launched-1997-abdulrauf-m-ahmad. Only 200 were produced: Ibid. the list of features: Wright, “The Original iPhone Announcement Annotated.” making the entire internet: Taylor Martin, “The Evolution of the Smartphone,” Pocketnow, July 28, 2014, http://pocketnow.com/2014/07/28/the-evolution-of-the-smartphone. smartphone could be used:",
    "meta": {
      "theme": "The Mobile Web and Social Media Dominance",
      "region": "Global",
      "use_case": "Communication, Social Networking, Information Access",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [
        "development_models"
      ],
      "civilizational_category": [
        "cultural_ethos",
        "temporal_orientation"
      ],
      "usage_tags": "facebook, smartphones, mobile web, social media, internet",
      "influence_map": [],
      "chunk_index": 158
    },
    "id": "likewar_158"
  },
  {
    "section": "Introduction and the Rise of Mobile Technology",
    "text": "Tracing the history and evolution of mobile apps reveals a dramatic rise in their usage. From humble beginnings, the number of apps available has soared to millions, driven largely by Google's Android operating system. The global number of smartphone users has increased exponentially, reaching billions, with a significant portion of the developed world relying on these devices as their primary source of information and entertainment, often surpassing television. This widespread adoption of smartphones has paved the way for social media platforms like Twitter.",
    "meta": {
      "theme": "Technological Advancement and Societal Impact",
      "region": "Global",
      "use_case": "Communication and Information Dissemination",
      "strategic_category": [],
      "economic_category": [
        "development_models"
      ],
      "civilizational_category": [
        "temporal_orientation"
      ],
      "usage_tags": [
        "mobile technology",
        "social media",
        "smartphones",
        "apps"
      ],
      "influence_map": [],
      "chunk_index": 159
    },
    "id": "likewar_159"
  },
  {
    "section": "Twitter and the Transformation of Information Sharing",
    "text": "Initially conceived as a platform for sharing short status updates, Twitter quickly gained traction, witnessing an explosion in daily tweets.  Journalists embraced Twitter as a tool for news dissemination and verification, contributing to its growing influence.  The platform's accessibility and immediacy also empowered individuals to share their perspectives and challenge established narratives. Notably, figures like Donald Trump leveraged Twitter's reach to bypass traditional media outlets and communicate directly with the public. This direct access to information marked a significant shift in the information landscape.",
    "meta": {
      "theme": "The Democratization of Information",
      "region": "Global",
      "use_case": "Political Communication and Citizen Journalism",
      "strategic_category": [
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "twitter",
        "social media",
        "news dissemination",
        "political communication"
      ],
      "influence_map": [],
      "chunk_index": 160
    },
    "id": "likewar_160"
  },
  {
    "section": "The Expanding Digital Ecosystem and Global Connectivity",
    "text": "Alongside Twitter, other platforms like Instagram and WhatsApp experienced rapid growth, further fragmenting the digital space. Facebook's acquisition of WhatsApp highlighted the increasing value of messaging apps. The global reach of these platforms extended to emerging markets, with countries like Thailand and the Philippines demonstrating high levels of engagement.  However, this expansion also raised concerns about the centralization of power within a few tech giants.  The rise of WeChat in China presented an alternative model, with its integrated services and vast user base, but also underscored the potential for surveillance and control in a closed digital ecosystem.",
    "meta": {
      "theme": "Digital Platforms and Global Interconnectedness",
      "region": "Global",
      "use_case": "Social Networking and Communication",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [
        "trade_tariff_systems"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "digital platforms",
        "global connectivity",
        "wechat",
        "whatsapp",
        "instagram"
      ],
      "influence_map": [],
      "chunk_index": 161
    },
    "id": "likewar_161"
  },
  {
    "section": "The Ubiquity of the Internet and the Transparency of Information",
    "text": "The internet's reach continued to expand, connecting an ever-growing portion of the global population. This increasing connectivity, coupled with the proliferation of digital devices, led to an unprecedented level of information transparency.  Events like the Osama bin Laden raid, inadvertently live-tweeted by Sohaib Athar, demonstrated the power of citizen journalism and the shrinking capacity for secrecy.  Athar's experience highlighted the phenomenon of disintermediation, where individuals can bypass traditional gatekeepers of information. This shift presented both opportunities and challenges, raising questions about the veracity of information and the potential for manipulation.",
    "meta": {
      "theme": "Transparency, Citizen Journalism, and the Erosion of Secrecy",
      "region": "Global",
      "use_case": "Real-time Information Sharing and Citizen Reporting",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "internet",
        "citizen journalism",
        "information transparency",
        "disintermediation"
      ],
      "influence_map": [],
      "chunk_index": 162
    },
    "id": "likewar_162"
  },
  {
    "section": "Sensor-Based Economy and Surveillance",
    "text": "A future with almost a trillion sensors collecting data raises concerns about surveillance.  This evokes comparisons to the mythical Argus Panoptes, the all-seeing giant, and Bentham's Panopticon, a prison design promoting self-regulation through constant observation.  Orwell's \"telescreens\" in *Nineteen Eighty-Four* further illustrate this fear of ubiquitous monitoring.  The sheer volume of data generated daily, from Facebook comments and YouTube videos to tweets and the expanding \"digital universe,\" combined with the ability to deanonymize seemingly harmless information like agents' daily jogs, creates a landscape ripe for surveillance.",
    "meta": {
      "theme": "Surveillance and Data Collection",
      "region": "Global",
      "use_case": "Intelligence Gathering, Social Control",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "Big Data",
        "Privacy",
        "Digital Footprint"
      ],
      "influence_map": {
        "influenced_works": [
          "Nineteen Eighty-Four"
        ],
        "modern_applications": [
          "Social Media Monitoring",
          "Data Analytics"
        ]
      },
      "chunk_index": 163
    },
    "id": "likewar_163"
  },
  {
    "section": "Data as a Weapon",
    "text": "The volume of data available presents both opportunities and threats. General Milley's statement about data exceeding the Allies' D-Day logistics highlights the unprecedented scale of information gathering.  Data mining, as seen in the Ashley Madison hack, reveals vulnerabilities and potential for manipulation.  The use of location data to target Ukrainian soldiers with propaganda exemplifies data weaponization.  Even seemingly innocuous platforms like Facebook, starting with its early days in 2006, now capture vast amounts of personal data, from selfies to political opinions.  This data, coupled with social media platforms, can be leveraged for various purposes, from influencing public opinion to targeting individuals.",
    "meta": {
      "theme": "Data Weaponization and Information Warfare",
      "region": "Global",
      "use_case": "Military Targeting, Propaganda, Psychological Operations",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "Cyber Warfare",
        "Information Operations",
        "Disinformation"
      ],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": [
          "Targeted Advertising",
          "Political Campaigns",
          "Social Engineering"
        ]
      },
      "chunk_index": 164
    },
    "id": "likewar_164"
  },
  {
    "section": "Digital Memory and Political Communication",
    "text": "The internet creates a permanent record, \"the end of forgetting.\"  Archiving platforms preserve everything from presidential speeches and tweets to social media interactions. While this offers valuable historical insights, it also presents risks.  President Trump's tweets, for example, have been scrutinized as potential national security threats, offering adversaries \"solid gold info\" for psychological profiling.  This digital record can be exploited by foreign intelligence services and used to understand and manipulate individuals and even nations. Conversely, the same platforms can be used for positive purposes, such as citizen engagement and open communication, as seen in President Obama's remarks on the importance of avoiding partisanship.",
    "meta": {
      "theme": "Digital Legacy and Political Discourse",
      "region": "Global",
      "use_case": "Political Analysis, Intelligence Gathering, Public Diplomacy",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "Open Source Intelligence",
        "Public Opinion",
        "Political Communication"
      ],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": [
          "Political Campaigns",
          "Crisis Communication",
          "International Relations"
        ]
      },
      "chunk_index": 165
    },
    "id": "likewar_165"
  },
  {
    "section": "Social Media in Crisis and Conflict",
    "text": "The 2008 Mumbai attacks demonstrated the power of social media in real-time crisis reporting. Twitter became a crucial source of information, with eyewitness accounts, updates on the attacks, and pleas for help.  This real-time information flow, combined with platforms like Google Maps, provided a dynamic view of the unfolding events.  While the Indian government initially downplayed the role of social media, the attacks showcased its potential for both good and bad.  Terrorists used it to spread fear and propaganda, while citizens used it to coordinate rescue efforts, share information, and seek blood donations. This event highlighted the emergence of crowdsourced information and its impact on crisis response.",
    "meta": {
      "theme": "Social Media in Crisis and Conflict",
      "region": "South Asia",
      "use_case": "Crisis Reporting, Situational Awareness, Emergency Response, Propaganda",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "Crowdsourcing",
        "Citizen Journalism",
        "Disaster Relief"
      ],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": [
          "Emergency Management",
          "Conflict Reporting",
          "Humanitarian Aid"
        ]
      },
      "chunk_index": 166
    },
    "id": "likewar_166"
  },
  {
    "section": "Crowdfunding and Conflict",
    "text": "Crowdfunding has emerged as a new avenue for financing conflict.  From political campaigns like Bernie Sanders's to extremist groups, crowdfunding allows for rapid mobilization of resources.  The ability to bypass traditional funding mechanisms enables both legitimate and illicit actors to solicit donations from a wide range of sources. While crowdfunding can empower grassroots movements, it also poses challenges in regulating the flow of funds to potentially dangerous groups engaging in \"financial jihad.\" The ease of donating online, combined with the anonymity it can offer, makes it difficult to track and control the financing of conflict.",
    "meta": {
      "theme": "Crowdfunding and Conflict Finance",
      "region": "Global",
      "use_case": "Terrorist Financing, Political Fundraising, Insurgency Support",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "Terrorism",
        "Political Campaigns",
        "Financial Regulation"
      ],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": [
          "Counterterrorism Finance",
          "Campaign Finance Reform"
        ]
      },
      "chunk_index": 167
    },
    "id": "likewar_167"
  },
  {
    "section": "New Crowdfunding Campaign – Present Shock",
    "text": "“Thanks for vote”: Adam Linehan, “This Controversial Instagram Account Lets You Decide Whether ‘ISIS Fighters’ Live or Die,” Task & Purpose, March 28, 2016. “A guy on the toilet”: Ibid. Took about thirty seconds: After Action Report for the Response to the 2013 Boston Marathon Bombings (Massachusetts Emergency Management Agency et al., December 2014). “Holy shit!”: Kristen Surman (@KristenSurman), “Holy shit! Explosion!,” Twitter, April 15, 2013, 2:50 p.m. First photo of the attack: Dan Lampariello (@Boston_to_a_T), “Explosion at coply,” Twitter, April 15, 2013, 2:50 p.m. Fox Sports Radio: Fox Sports 1380/95.3 (@KRKO1380), “BREAKING: Per our man on the ground at the Boston Marathon, @tooblackdogs, there was an explosion. More to follow,” Twitter, April 15, 2013, 2:52 p.m. Nearly an hour: Hong Qu, “Social Media and the Boston Bombings: When Citizens and Journalists Cover the Same Story,” Nieman Lab, April 17, 2013. More than doubled: “Number of Smartphone Users Worldwide from 2014 to 2020 (Billions),” Statista, accessed March 18, 2018. An incomprehensibly vast now: “Time,” Stanford Encyclopedia of Philosophy, updated January 24, 2014, accessed March 18, 2018. “present shock”: Douglas Rushkoff, Present Shock: When Everything Happens Now (Current, 2014). Ripe old age: Ryan Broderick, “What It’s Like to Live-Tweet the Day Your Neighborhood Becomes a War Zone,” BuzzFeed, August 30, 2016. Hyperlocal reporting: Ibid. A truly local paper: Selinsgrove, like the other small towns of Pennsylvania’s central Susquehanna Valley, is served by the Daily Item, circulation roughly 14,000. “I may be nine”: Hilde Kate Lysiak, “Yes, I’m a Nine-Year-Old Girl. But I’m Still a Serious Reporter,” The Guardian, April 6, 2016.",
    "meta": {
      "theme": "Rise of Citizen Journalism and OSINT",
      "region": "Global",
      "use_case": "Information Dissemination, Crisis Reporting, Conflict Monitoring",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "temporal_orientation"
      ],
      "usage_tags": [
        "social media",
        "citizen journalism",
        "real-time reporting",
        "open source intelligence"
      ],
      "influence_map": [],
      "chunk_index": 168
    },
    "id": "likewar_168"
  },
  {
    "section": "Attacks on Journalism - Censorship and Violence",
    "text": "Nearly 800 documented attacks: Paul Imison, “Journalists in Mexico Killed in Record Numbers ​— ​Along with Freedom of Speech,” Fox News, April 4, 2017. The Norte newspaper: Associated Press, “Mexican Newspaper Closes Citing Insecurity for Journalists,” Fox News, April 2, 2017. “You do it”: Dana Priest, “Censor or Die: The Death of Mexican News in the Age of Drug Cartels,” Washington Post, December 11, 2015. But even that: “ ‘Adios!’: Mexican Newspaper Norte Closes After Murder of Journalist,” The Guardian, April 3, 2017. Catwoman: Jason McGahan, “She Tweeted Against the Mexican Cartels, They Tweeted Her Murder,” The Daily Beast, October 21, 2014. Killed over 15,000 people: Alasdair Baverstock, “Revealed, America’s Most Fearful City Where Texans Live Next to a ‘War Zone,’ ” Daily Mail, October 8, 2015. “tweeted her murder”: McGahan, “She Tweeted Against the Mexican Cartels.”",
    "meta": {
      "theme": "Risks and Challenges to Press Freedom",
      "region": "Mexico, Global",
      "use_case": "Censorship, Violence Against Journalists",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "press freedom",
        "censorship",
        "violence",
        "drug cartels",
        "organized crime"
      ],
      "influence_map": [],
      "chunk_index": 169
    },
    "id": "likewar_169"
  },
  {
    "section": "Citizen Journalism in Conflict Zones - Raqqa and MH17",
    "text": "A group of seventeen: Alice Speri, “Raqqa Is Being Slaughtered Silently, and These Guys Are Risking Their Lives to Document It,” Vice, September 25, 2014. More powerful than: David Remnick, “Telling the Truth About ISIS and Raqqa,” The New Yorker, November 22, 2015. Paraded in front of: Mansour Al-Hadj, “Anti-ISIS Activists in Al-Raqqa Vow to Remain Resolute Despite Constant Death Threats, Assassinations,” Middle East Media Research Institute, February 3, 2016. Ten members of the network: David Remnick, “The Tragic Legacy of Raqqa Is Being Slaughtered Silently,” The New Yorker, October 21, 2017. “It’s okay”: Elahe Izadi and Liz Sly, “Female Activist Killed by the Islamic State Posted This Final Defiant Message,” Washington Post, January 7, 2016. “here’s what it looks like”: Cor Pan, “Mocht hij verdwijnen, zo ziet hij d’r uit,” Facebook, July 17, 2014, accessed March 18, 2018. They were a mix: Christopher Miller, “Field of Death: How MH17 and Its Passengers Became Victims of a Distant War,” Mashable, July 16, 2015. Thirty milliseconds: Crash of Malaysia Airlines Flight MH17 (report, Dutch Safety Board, October 2015), 115. Over 7,600 pieces: “A Detailed Description of the BUK SA-11 Which Could Have Shot Down MH17,” WhatHappenedToFlightMH17.com, March 21, 2015. Separated into three pieces: Crash of Malaysia Airlines Flight MH17, 162. For ninety seconds: Ibid., 165. Under five minutes: Amber Dawson et al., “As It Happened: Malaysian Plane Crash in Ukraine,” BBC News, July 17, 2014. “just fell”: Miller, “Field of Death.”",
    "meta": {
      "theme": "Citizen Documentation of War Crimes and Disasters",
      "region": "Syria, Ukraine",
      "use_case": "Conflict Monitoring, Disaster Reporting, Open Source Investigations",
      "strategic_category": [
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "war crimes",
        "human rights",
        "open source investigations",
        "MH17",
        "ISIS",
        "Raqqa"
      ],
      "influence_map": [],
      "chunk_index": 170
    },
    "id": "likewar_170"
  },
  {
    "section": "Rise of Open Source Intelligence (OSINT)",
    "text": "World of Warcraft addict: Patrick Radden Keefe, “Rocket Man,” The New Yorker, November 25, 2013. “Brown Moses”: Ibid. His knowledge: Matthew Weaver, “How Brown Moses Exposed Syrian Arms Trafficking from His Front Room,” The Guardian, March 21, 2013. Had used nerve gas: Brown Moses, “Who Was Responsible for the August 21st Attack?,” Brown Moses Blog, September 16, 2013. Published its first report: Eliot Higgins, “Buk Transporter Filmed ‘Heading to Russia’ Sighted in an Earlier Photograph,” Bellingcat, July 18, 2014. Pattern of shrapnel damage: Eliot Higgins, “The Latest Open Source Theories, Speculation and Debunks on Flight MH17,” Bellingcat, July 22, 2014. “a lot of obsessive people”: Keefe, “Rocket Man.” His in-laws thought: Aric Toler, interview with authors, Washington, DC, March 10, 2016. Soon after the crash: Higgins, “Buk Transporter.” The equivalent of: “Origin of the Separatists’ Buk: A Bellingcat Investigation,” Bellingcat, November 8, 2014. Mapping out the odyssey: Bellingcat interactive map, Mapbox, accessed March 18, 2018. Even snapped a picture: Toler interview. Worried about their loved ones: “MH17 ​— ​Potential Suspects and Witnesses from the 53rd Anti-Aircraft Missile Brigade,” Bellingcat, 2016. It included the names: Janene Pieters, “Twenty Russians Wanted for Questioning in MH17 Downing,” NL Times, January 4, 2016. One OSINT analyst: Email to authors, February 8, 2016. GVA Dictator Alert: Amar Toor, “This Twitter Bot Is Tracking Dictators’ Flights in and out of Geneva,” The Verge, October 13, 2016. One of every five: Eric Gomez, “How Collectible Medals and Facebook Likes Encouraged Cheaters in the Mexico City Marathon,” ESPN.com, April 16, 2018.",
    "meta": {
      "theme": "The Power and Potential of OSINT",
      "region": "Global",
      "use_case": "Conflict Investigation, Accountability, Transparency",
      "strategic_category": [
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "open source intelligence",
        "Bellingcat",
        "conflict monitoring",
        "arms trafficking",
        "digital forensics"
      ],
      "influence_map": [],
      "chunk_index": 171
    },
    "id": "likewar_171"
  },
  {
    "section": "Footnotes and excerpts related to open-source intelligence and the digital sphere.",
    "text": "76 chemical weapons in Syria: “Open Source Survey of Alleged Chemical Attacks in Douma on 7th April 2018,” Bellingcat, April 11, 2018, https://www.bellingcat.com/news/mena/2018/04/11/open-source-survey-alleged-chemical-attacks-douma-7th-april-2018/. 76 indicted Mahmoud Al-Werfalli: “Situation in Libya in the Case of The Prosecutor v. Mahmoud Mustafa Busayf Al-Werfalli,” International Criminal Court, August 15, 2017, https://www.icc-cpi.int/CourtRecords/CR2017_05031.PDF. 76 “virtual kidnappings”: Daniel Borunda, “‘Virtual Kidnapping’ Cases Spread from Mexico to US, FBI Says,” El Paso Times, October 19, 2017, https://www.elpasotimes.com/story/news/crime/2017/10/19/virtual-kidnapping-cases-spread-mexico-us-fbi-says/780847001/. 76 Scouring Libyan Facebook groups: C. J. Chivers, “Facebook Groups Act as Weapons Bazaars for Militias,” New York Times, April 6, 2016, https://www.nytimes.com/2016/04/07/world/middleeast/facebook-weapons-syria-libya-iraq.html. 77 traced to stocks: Ibid. 77 “By carefully gathering”: Sangwon Yoon, “This Startup Is Predicting the Future by Decoding the Past,” Bloomberg, Markets, April 6, 2016, https://www.bloomberg.com/news/articles/2016-04-06/this-startup-is-predicting-the-future-by-decoding-the-past. 77 North Korean missile: James Shinn, interview with author, Washington, DC, January 7, 2016. 77 “The exponential explosion”: Michael Flynn, phone interview with authors, May 26, 2016. 78 reading the obituary: Adam Rawnsley, “The Open-Source Spies of World War II: U.S. Intelligence Analysts Helped Shape Modern Spycraft,” War Is Boring (blog), Medium, March 2, 2015, https://medium.com/war-is-boring/the-open-source-spies-of-world-war-ii-7943bd5b663c. 78 roughly 45,000 pages: Anthony Olcott, Open Source Intelligence in a Networked World (Continuum, 2012), 16. 78 Foreign Broadcast Monitoring Service: Kalev Leetaru, “The Scope of FBIS and BBC Open-Source Media Coverage, 1979–2008,” Studies in Intelligence 54, no. 1 (2010): 17–37.",
    "meta": {
      "theme": "Open-source intelligence",
      "region": "Global",
      "use_case": "Intelligence gathering, criminal investigations, market analysis",
      "strategic_category": [
        "military_doctrine",
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "OSINT",
        "social media",
        "digital investigations"
      ],
      "influence_map": [],
      "chunk_index": 172
    },
    "id": "likewar_172"
  },
  {
    "section": "Footnotes and excerpts related to Michael Flynn's career and views.",
    "text": "78 over a thousand Soviet journals: Olcott, Open Source Intelligence in a Networked World. 78 a thousand hours of television: Leetaru, “The Scope of FBIS and BBC Open-Source Media Coverage.” 78 they suspected trickery: Olcott, Open Source Intelligence in a Networked World. 78 had risen to 50,000: Ibid., 90. 79 “Whether you’re a CEO”: Flynn interview. 79 Flynn joined: Nicholas Schmidle, “Michael Flynn, General Chaos,” The New Yorker, February 27, 2017, http://www.newyorker.com/magazine/2017/02/27/michael-flynn-general-chaos. 79 They would eschew: Ibid. 80 He envisioned: Ibid. 80 Before the rise: Flynn interview. 80 “unwanted pregnancy”: Ibid. 80 “redheaded stepchild”: Ibid. 80 alarmed the DIA’s bureaucracy: Patrick Tucker, “The Other Michael Flynn,” Defense One, November 21, 2016, https://cdn.defenseone.com/b/defenseone/interstitial.html?v=8.8.0&rf=http%3A%2F%2Fwww.defenseone.com%2Fpolitics%2F2016%2F11%2Fother-michael-flynn%2F133337%2F. 80 after thirty-three years: Schmidle, “Michael Flynn.” 80 $530,000 deal: Fredreka Schouten, “Turkish Client Paid $530,000 to Michael Flynn’s Consulting Firm,” USA Today, March 8, 2017, https://www.usatoday.com/story/news/politics/2017/03/08/michael-flynn-received-530000-from-turkish-client-during-trump-campaign/98917184/. 81 “he was going to be”: Schmidle, “Michael Flynn.” 81 “Fear of Muslims is RATIONAL”: Michael Flynn (@GenFlynn), “Fear of Muslims is RATIONAL: please forward this to others: the truth fears no questions . . . ,” Twitter, February 26, 2016, 5:14 p.m., accessed March 18, 2018, https://twitter.com/genflynn/status/703387702998278144?lang=en. 81 “Not anymore, Jews”: Kristen East, “Flynn Retweets Anti-Semitic Remark,” Politico, July 24, 2016, http://www.politico.com/story/2016/07/michael-flynn-twitter-226091. 81 a “jihadi” who “laundered”: Bryan Bender and Andrew Hanna, “Flynn Under Fire for Fake News,” Politico, December 5, 2016, https://www.politico.com/story/2016/12/michael-flynn-conspiracy-pizzeria-trump-232227. 81 “Sex Crimes w Children”: Lauren Carroll, “Michael Flynn’s Troubling Penchant for Conspiracy Theories,” Politifact, February 14, 2017, http://www.politifact.com/truth-o-meter/article/2017/feb/14/michael-flynns-troubling-penchant-conspiracy-thoer/.",
    "meta": {
      "theme": "Michael Flynn's career and controversies",
      "region": "United States",
      "use_case": "Political analysis, biographical information",
      "strategic_category": [
        "national_security",
        "military_doctrine"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "politics",
        "military",
        "intelligence"
      ],
      "influence_map": [],
      "chunk_index": 173
    },
    "id": "likewar_173"
  },
  {
    "section": "Footnotes and excerpts related to the internet, social media, and political upheaval.",
    "text": "81 outlaw Christianity: Ibid. 81 human blood and semen: Bender and Hanna, “Flynn Under Fire for Fake News.” 81 “making sure that”: Flynn interview. 82 “We are going”: Michael Flynn (@GenFlynn), “We are going to win and win and win at everything we do. It is going to be tough, but Team Trump-Pence will #MAGA,” Twitter, December 1, 2016, 7:33 p.m., https://twitter.com/GenFlynn/status/804528907978412033?ref_src=twsrc%5Etfw&ref_url=https%3A%2F%2F; http://www.washingtonpost.com%2Fblogs%2Fpost-partisan%2Fwp%2F2016%2F12%2F02%2Fsorry-lt-gen-flynn-its-unrealistic-to-win-and-win-and-win-at-everything%2F. 82 “false, fictitious”: United States of America v. Michael T. Flynn, United States District Court for the District of Columbia, filed November 30, 2017, https://www.politico.com/f/?id=00000160-128a-dd6b-afeb-37afd8000000. 82 piercing through the “fog”: Flynn interview. 4. THE EMPIRES STRIKE BACK 83 “‘Truth’ is a lost cause”: Peter Pomerantsev and Michael Weiss, “The Menace of Unreality: How the Kremlin Weaponizes Information, Culture and Money” (report, Institute of Modern Russia, 2014), http://www.interpretermag.com/wp-content/uploads/2014/11/The_Menace_of_Unreality_Final.pdf. 83 “Information wants”: Steven Levy, “‘Hackers’ and ‘Information Wants to Be Free,’ ” Backchannel (blog), Medium, November 21, 2014, https://medium.com/backchannel/the-definitive-story-of-information-wants-to-be-free-a8d95427641c. 83 “The Net interprets”: Philip Elmer-Dewitt, “First Nation in Cyberspace,” Time, December 6, 1993, http://kirste.userpage.fu-berlin.de/outerspace/internet-article.html. 83 “the Japanese guy”: Bruce Sterling, “Triumph of the Plastic People,” Wired, January 1, 1995, https://www.wired.com/1995/01/prague/. 84 first so-called internet revolution: Olesya Tkacheva et al., Internet Freedom and Political Space (RAND, 2013), 121. 84 government censors: Lev Grossman, “Iran Protests: Twitter, the Medium of the Movement,” Time, June 17, 2009, http://content.time.com/time/world/article/0,8599,1905125,00.html. 84 98 percent of the links: “Iran and the ‘Twitter Revolution,’ ” Pew Research Center, June 25, 2009, http://www.journalism.org/2009/06/25/iran-and-twitter-revolution/. 84 “The Revolution”: Andrew Sullivan, “The Revolution Will Be Tweeted,” The Daily Dish (blog), The Atlantic, June 13, 2009, http://www.theatlantic.com/daily-dish/archive/2009/06/the-revolution-will-be-twittered/200478/. 84 Nobel Peace Prize: Lewis Wallace, “Wired Backs Internet for Nobel Peace Prize,” Wired, November 20, 2009, https://www.wired.com/2009/11/internet-for-peace-nobel/. 85 Mohamed Bouazizi: Yasmine Ryan, “The Tragic Life of a Street Vendor,” Al Jazeera, January 20, 2011, http://www.aljazeera.com/indepth/features/2011/01/201111684242518839.html. 85 “Is Egypt about to have”: Abigail Hauslohner, “Is Egypt About to Have a Facebook Revolution?,” Time, January 24, 2011, http://content.time.com/time/world/article/0,8599,2044142,00.html. 85 Mubarak’s resignation: Leila Fadel, “With Peace, Egyptians Overthrow a Dictator,” Washington Post, February 11, 2011, http://www.washingtonpost.com/wp-dyn/content/article/2011/02/11/AR2011021105709.html.",
    "meta": {
      "theme": "The internet and political revolutions",
      "region": "Middle East, North Africa, Global",
      "use_case": "Analysis of social movements and the role of technology",
      "strategic_category": [
        "geopolitical_strategy",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "revolution",
        "internet freedom",
        "censorship"
      ],
      "influence_map": [],
      "chunk_index": 174
    },
    "id": "likewar_174"
  },
  {
    "section": "Internet Shutdowns and Censorship",
    "text": "Two-thirds of all ISPs are located in just sixty-one countries.  This concentration of control allows governments to shut down internet access for entire populations.  Syria completely cut off internet access in 2011. Algeria blocked social media in 2016, costing their economy an estimated $190 million. Bahrain imposed an “internet curfew” in a protest village, narrowing internet access during specific times. Iran throttles internet speeds during protests and is developing a “clean” internet with restricted access to outside information. Syrians under government control have sought internet access through Turkey’s wireless network, even using solar-powered phone chargers. North Korea's internet is heavily restricted, with access limited to about thirty websites.",
    "meta": {
      "theme": "Control of Information",
      "region": "Global",
      "use_case": "Political Control, Censorship",
      "strategic_category": [
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "internet shutdown",
        "censorship",
        "social media",
        "information control"
      ],
      "influence_map": [],
      "chunk_index": 175
    },
    "id": "likewar_175"
  },
  {
    "section": "Exploiting Technology for Political Power",
    "text": "During the 2016 attempted military coup in Turkey, President Erdogan used FaceTime to address the nation and rally support, highlighting the power of technology in political struggles.  The coup attempt prompted a game of hide-and-seek between the government and those involved, demonstrating how quickly control of information can shift.  The aftermath saw a massive crackdown, with over 45,000 people arrested and over 135,000 civil servants dismissed.  Internet freedoms were increasingly restricted, with social media platforms blocked and journalists' accounts withheld.  Even a satirical Instagram caption or retweeting certain content could lead to detention.  The government aimed to control the narrative and suppress dissent.",
    "meta": {
      "theme": "Political Power and Technology",
      "region": "Turkey",
      "use_case": "Coup Response, Repression",
      "strategic_category": [
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems",
        "historical_memory"
      ],
      "usage_tags": [
        "coup",
        "political repression",
        "social media censorship",
        "internet freedom",
        "surveillance"
      ],
      "influence_map": [],
      "chunk_index": 176
    },
    "id": "likewar_176"
  },
  {
    "section": "Global Expansion of Internet Control",
    "text": "Governments worldwide are increasingly policing online content. Iran maintains its “clean” internet. Saudi Arabia uses Twitter to track dissidents. Pakistan instituted the death penalty for blasphemy on social media. Thailand prosecutes those who view material deemed insulting to the monarchy and uses a “Cyber Scouts” program to monitor dissent. Kazakhstan imprisons individuals for insulting Putin online. Russia punishes those who repost criticism of its actions in Ukraine.  These actions demonstrate a growing trend of governments using legal and technological means to control online speech and suppress dissent.",
    "meta": {
      "theme": "Global Internet Control",
      "region": "Global",
      "use_case": "Censorship, Repression",
      "strategic_category": [
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems",
        "cultural_ethos"
      ],
      "usage_tags": [
        "internet censorship",
        "political repression",
        "social media surveillance",
        "authoritarianism"
      ],
      "influence_map": [],
      "chunk_index": 177
    },
    "id": "likewar_177"
  },
  {
    "section": "China's Great Firewall and Harmonious Society",
    "text": "China, with nearly 800 million internet users, exemplifies state control of online information.  The government promotes a “harmonious society” and exercises strict censorship to ensure “correct guidance” online.  The Golden Shield Project, also known as the Great Firewall, uses technology from companies like Sun Microsystems and Cisco to filter and block content.  Sensitive topics, like the Panama Papers, are swiftly scrubbed from the internet. The government's extensive censorship apparatus aims to maintain social stability and control the narrative within its borders.",
    "meta": {
      "theme": "State Control of Information",
      "region": "China",
      "use_case": "Censorship, Propaganda",
      "strategic_category": [
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "internet censorship",
        "great firewall",
        "propaganda",
        "harmonious society",
        "information control"
      ],
      "influence_map": [],
      "chunk_index": 178
    },
    "id": "likewar_178"
  },
  {
    "section": "Censorship and Control in China",
    "text": "China's censorship apparatus goes beyond simple keyword blocking. It involves manipulating search results, deleting posts, and silencing discussions on sensitive topics.  Even seemingly innocuous subjects like Winnie the Pooh have been targeted due to comparisons with political figures.  This censorship extends to eliminating references to historical events like the Tiananmen Square Massacre, with hundreds of terms blocked.  Online encyclopedias are rewritten to conform to the official narrative.  Even complaints about hospital food can lead to arrest for \"disturbing public order.\" While some grassroots movements are tolerated, any hint of collective action or criticism that gains traction is swiftly suppressed.  This control extends to news reporting, with bans on independent online news outlets and the punishment of \"rumor spreaders.\" Online personalities and bloggers are closely monitored, with some forced into televised confessions.  Even seemingly innocuous online activities, like hotel reviews, are subject to manipulation and control.",
    "meta": {
      "theme": "Information Control",
      "region": "China",
      "use_case": "Political Stability Maintenance",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "historical_memory"
      ],
      "usage_tags": [
        "censorship",
        "propaganda",
        "social_control"
      ],
      "influence_map": [],
      "chunk_index": 179
    },
    "id": "likewar_179"
  },
  {
    "section": "China's 50-Cent Army and Manipulation of Online Discourse",
    "text": "China employs vast armies of internet commentators, often referred to as the \"50-Cent Army,\" to manipulate online discussions and shape public opinion.  These individuals, some of whom are government employees, post pro-government comments, spread disinformation, and attack critics.  Leaked documents reveal pay scales and official certifications for these commentators.  While the term \"50 cents\" has been banned, their activities continue.  Estimates of their numbers vary widely, from hundreds of thousands to millions. This tactic has been adopted by other countries as well.  Beyond paid commentators, the Chinese government also fabricates social media posts for strategic distraction and to create the illusion of popular support for its policies.",
    "meta": {
      "theme": "Information Warfare",
      "region": "China",
      "use_case": "Propaganda and Public Opinion Manipulation",
      "strategic_category": [
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "disinformation",
        "propaganda",
        "astroturfing"
      ],
      "influence_map": [],
      "chunk_index": 180
    },
    "id": "likewar_180"
  },
  {
    "section": "China's Social Credit System and Global Influence",
    "text": "China's social credit system aims to engineer a society based on \"trustworthiness\" by tracking citizens' online and offline behavior. This system assigns citizens a score based on a wide range of factors, from online purchases and social media activity to adherence to traffic laws and payment of bills.  Activities like buying too many video games or regularly purchasing diapers can negatively impact one's score. Conversely, \"report acts\" on neighbors and colleagues can improve one's standing.  A low score can result in restricted access to services, travel limitations, and even exclusion from online matchmaking services. This system has raised concerns about privacy and individual liberties.  Worryingly, China's model of internet control and social engineering is being adopted by other nations, including Thailand, Vietnam, Zimbabwe, Cuba, and Russia. These countries are implementing similar systems of censorship, surveillance, and social control, indicating a growing trend toward authoritarianism in the digital age.",
    "meta": {
      "theme": "Social Control and Surveillance",
      "region": "China, Global",
      "use_case": "Social Engineering, Authoritarianism",
      "strategic_category": [
        "national_security",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "surveillance",
        "social_credit",
        "censorship"
      ],
      "influence_map": [],
      "chunk_index": 181
    },
    "id": "likewar_181"
  },
  {
    "section": "Russian Disinformation Campaigns",
    "text": "Russia has a long history of disinformation campaigns, dating back to the Soviet era.  These campaigns often involve spreading false narratives, conspiracy theories, and propaganda through various channels, including traditional media and social media.  One example is Operation INFEKTION, a Soviet disinformation campaign that falsely claimed the United States created AIDS.  This disinformation was spread through various media outlets, including an Indian newspaper and the Lyndon LaRouche movement.  More recently, Russia has been accused of interfering in foreign elections through sophisticated disinformation campaigns.  These campaigns involve creating and disseminating fake news, manipulating social media, and hacking into computer systems. The use of \"Kremlin trolls\" – individuals paid to post pro-government comments and spread disinformation online – is a key component of these campaigns.",
    "meta": {
      "theme": "Disinformation and Propaganda",
      "region": "Russia, Global",
      "use_case": "Political Warfare, Election Interference",
      "strategic_category": [
        "geopolitical_strategy",
        "military_doctrine"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "disinformation",
        "propaganda",
        "cyberwarfare"
      ],
      "influence_map": [],
      "chunk_index": 182
    },
    "id": "likewar_182"
  },
  {
    "id": "likewar_183",
    "section": "Extracted Content",
    "text": "“spoke in grave”: “1984 in 2014,” The Economist, March 29, 2014,",
    "meta": {
      "theme": "unspecified",
      "region": "unspecified",
      "use_case": "doctrine_selector",
      "strategic_category": {},
      "economic_category": {},
      "civilizational_category": {},
      "usage_tags": [],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": []
      },
      "chunk_index": 183
    }
  },
  {
    "section": "Introduction - Russian Troll Activities",
    "text": "Russian troll accounts actively disseminated messages in the days leading up to the election. These accounts often appeared as seemingly trustworthy individuals, promoting specific political agendas such as voting for third-party candidates or spreading disinformation about military affairs and national security.  This activity extended to various social media platforms, including Twitter and Facebook, reaching millions of users.  Fake accounts, sometimes posing as specific demographics like Black activists, were linked to the Russian government. Research indicates Russian propaganda may have been shared hundreds of millions of times, potentially influencing a significant portion of the online population.",
    "meta": {
      "theme": "Russian Interference in Elections",
      "region": "United States, Russia",
      "use_case": "Disinformation and Propaganda",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media manipulation",
        "election interference",
        "fake news"
      ],
      "influence_map": [],
      "chunk_index": 184
    },
    "id": "likewar_184"
  },
  {
    "section": "Tactics and Techniques of Disinformation",
    "text": "Beyond simply sharing misleading information, these campaigns employed sophisticated tactics.  Personas like \"Jenna Abrams\" were fabricated to dupe mainstream media and manipulate public discourse. Facebook's algorithms were sometimes exploited to steer users towards divisive content, amplifying pre-existing societal tensions.  Tactics included promoting anti-immigrant sentiment, harassment of journalists, and even labeling critics with derogatory terms. The hashtag #UniteTheRight was also pushed, demonstrating an attempt to influence real-world events.  This manipulation wasn't limited to the United States; similar tactics were observed in countries like Venezuela, Azerbaijan, and India, indicating a broader global strategy.",
    "meta": {
      "theme": "Disinformation Tactics",
      "region": "Global",
      "use_case": "Political Manipulation",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "propaganda",
        "social engineering",
        "cyber warfare",
        "information warfare"
      ],
      "influence_map": [],
      "chunk_index": 185
    },
    "id": "likewar_185"
  },
  {
    "section": "The Macedonian Fake News Industry",
    "text": "The town of Veles, Macedonia, emerged as a hub for fake news production.  Driven by financial incentives, young people in this economically depressed area created and disseminated fabricated stories targeting specific political audiences, particularly Trump supporters during the 2016 US election.  These operations, sometimes involving “clickbait coaches” and special events, generated significant revenue through online advertising.  The creators often expressed a cynical disregard for the truth, focusing on maximizing clicks and profits regardless of the impact of their fabricated stories.  This highlights how economic factors can contribute to the spread of disinformation.",
    "meta": {
      "theme": "Fake News Economy",
      "region": "Macedonia, United States",
      "use_case": "Profit-Driven Disinformation",
      "strategic_category": [],
      "economic_category": [
        "development_models"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "clickbait",
        "online advertising",
        "misinformation",
        "content farms"
      ],
      "influence_map": [],
      "chunk_index": 186
    },
    "id": "likewar_186"
  },
  {
    "section": "Impact of Personalized Media and Filter Bubbles",
    "text": "The rise of personalized media and filter bubbles contributes to the spread and effectiveness of disinformation.  As individuals are increasingly exposed to information tailored to their existing beliefs, they become more susceptible to misinformation that confirms those biases.  This creates echo chambers where dissenting opinions are excluded, further polarizing society. The concept of the \"Daily Me,\" where individuals curate their own information streams, and the \"Daily We,\" representing shared online spaces with like-minded individuals, exacerbates this issue.  This phenomenon fuels the growth of online communities centered around fringe beliefs, like the flat-earth theory, highlighting the potential for disinformation to thrive in these isolated environments.",
    "meta": {
      "theme": "Information Ecosystem",
      "region": "Global",
      "use_case": "Information Control and Manipulation",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "filter bubble",
        "echo chamber",
        "personalized media",
        "algorithm bias",
        "polarization"
      ],
      "influence_map": [],
      "chunk_index": 187
    },
    "id": "likewar_187"
  },
  {
    "section": "Misinformation and Social Media",
    "text": "_of_misinformation_online; Delia Mocanu et al., “Collective Attention in the Age of (Mis)information,” arXiv:1403.3344 [cs.SI], March 2014.  Yale University researchers: Gordon Pennycook, Tyrone Cannon, and David G. Rand, “Implausibility and Illusory Truth: Prior Exposure Increases Perceived Accuracy of Fake News but Has No Effect on Entirely Implausible Statements” (working paper, March 16, 2018), https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2958246.  lower-tier celebrities: For a blunt take on the subject, see “Anti-Vaccine Body Count,” http://www.jennymccarthybodycount.com/.  “Healthy young child”: Donald Trump (@realDonaldTrump), “Healthy young child goes to doctor, gets pumped with massive shot of many vaccines, doesn’t feel good and changes ​— ​AUTISM. Many such cases!,” Twitter, March 28, 2014, 5:35 a.m., https://twitter.com/realdonaldtrump/status/449525268529815552?lang=en.  “personal belief exception”: Anna Merlan, “Meet the New, Dangerous Fringe of the Anti-Vaccination Movement,” Jezebel, June 29, 2015, https://jezebel.com/meet-the-new-dangerous-fringe-of-the-anti-vaccination-1713438567.  sixty-year high: Rong-Gong Lin, “Latest Measles Outbreak Highlights a Growing Problem in California,” Los Angeles Times, January 7, 2015, http://www.latimes.com/local/california/la-me-aa2-snapshot-measles-whooping-cough-20150108-story.html.  sickened 147 children: “Year in Review: Measles Linked to Disneyland,” Public Health Matters Blog, Centers for Disease Control and Prevention, December 2, 2015, https://blogs.cdc.gov/publichealthmatters/2015/12/year-in-review-measles-linked-to-disneyland/. law requiring kindergarten vaccinations: Erin Hare, “Facts Alone Won’t Convince People to Vaccinate Their Kids,” FiveThirtyEight, June 12, 2017, https://fivethirtyeight.com/features/facts-alone-wont-convince-people-to-vaccinate-their-kids/?utm_content=buffer21fe5&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer.  dig in their heels: Charles G. Lord, Lee Ross, and Mark R. Lepper, “Biased Assimilation and Attitude Polarization: The Effects of Prior Theories on Subsequently Considered Evidence,” Journal of Personality and Social Psychology 37, no. 11 (1979): 2098–109. “Once, every village”: Robert Bateman (@RobertLBateman), “Once, every village had an idiot. It took the internet to bring them all together. ​ — ​Unknown (well, by me),” Twitter, August 19, 2017, 4:16 p.m., https://twitter.com/RobertLBateman/status/899047467282518017.",
    "meta": {
      "theme": "Misinformation/Disinformation",
      "region": "Global/United States",
      "use_case": "Spread of false narratives",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "fake news",
        "propaganda",
        "public health",
        "political polarization"
      ],
      "influence_map": [],
      "chunk_index": 188
    },
    "id": "likewar_188"
  },
  {
    "section": "Social Media's Impact on Democracy and Political Discourse",
    "text": "A 2016 study: Marc Lynch, Deen Freelon, and Sean Aday, “How Social Media Undermines Transitions to Democracy,” Bullets and Blogs, no. 4 (PeaceTech Lab, 2016), https://ipdgc.gwu.edu/sites/g/files/zaxdzs2221/f/downloads/Blogs%20and%20Bullets%20IV.pdf. “encouraged political society”: Ibid., 21. “echo-chamber qualities”: Sean Aday, Deen Freelon, and Marc Lynch, “How Social Media Undermined Egypt’s Democratic Transition,” Monkey Cage (blog), Washington Post, October 7, 2016, https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/07/how-social-media-undermined-egypts-democratic-transition/?utm_term=.c6f0a6afc33b. “There’s no such thing”: Jack Holmes, “A Trump Surrogate Drops the Mic: ‘There’s No Such Thing as Facts,’ ” Esquire, December 1, 2016, http://www.esquire.com/news-politics/videos/a51152/trump-surrogate-no-such-thing-as-facts/. shielded their terrified children: Marc Fisher, John Woodrow Cox, and Peter Hermann, “Pizzagate: From Rumor, to Hashtag, to Gunfire in D.C.,” Washington Post, December 6, 2016, https://www.washingtonpost.com/local/pizzagate-from-rumor-to-hashtag-to-gunfire-in-dc/2016/12/06/4c7def50-bbd4-11e6-94ac-3d324840106c_story.html?utm_term=.c84c2847b899. customers made a run for it: Amanda Robb, “Anatomy of a Fake News Scandal,” Rolling Stone, November 16, 2017, https://www.rollingstone.com/politics/news/pizzagate-anatomy-of-a-fake-news-scandal-w511904. an employee holding pizza dough: Fisher, Cox, and Hermann, “Pizzagate.” tiny computer room: Ibid.",
    "meta": {
      "theme": "Misinformation/Disinformation",
      "region": "United States/Egypt",
      "use_case": "Political manipulation, erosion of trust",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "fake news",
        "political polarization",
        "disinformation campaigns",
        "democratic backsliding"
      ],
      "influence_map": [],
      "chunk_index": 189
    },
    "id": "likewar_189"
  },
  {
    "section": "Fake News Empire",
    "text": "ult Every Day. Really. We Counted,” CNNMoney, January 27, 2018. See, but certainly don’t buy, Jack Posobiec, Citizens for Trump: The Inside Story of the People’s Movement to Take Back America (CreateSpace, 2017).  Laura Sydell, “We Tracked Down a Fake-News Creator in the Suburbs. Here’s What We Learned,” All Things Considered, NPR, November 23, 2016. David Mikkelson, “Fact Check: FBI Agent Suspected in Hillary Email Leaks Found Dead,” Snopes, November 5, 2016. Ryan Grenoble, “Here Are Some of Those Fake News Stories That Mark Zuckerberg Isn’t Worried About,” Huffington Post, November 16, 2016. Yochai Benkler et al., “Study: Breitbart-Led Right-Swing Media Ecosystem Altered Broader Media Agenda,” Columbia Journalism Review, March 3, 2017. Charlie Spiering, “New Andrew Breitbart footage: ‘My Goal Is to Destroy the New York Times and CNN,’ ” Washington Examiner, August 6, 2012. Joseph Bernstein, “Alt-White: How the Breitbart Machine Laundered Racist Hate,” BuzzFeed, October 5, 2017. “Alt-Right,” Southern Poverty Law Center. John Daniszewski, “How to Describe Extremists Who Rallied in Charlottesville,” The Definitive Source (blog), Associated Press, August 15, 2017. Sarah Posner, “How Donald Trump’s New Campaign Chief Created an Online Haven for White Nationalists,” Mother Jones, August 22, 2016.",
    "meta": {
      "theme": "Disinformation and Propaganda",
      "region": "United States, Global",
      "use_case": "Political Manipulation, Social Division",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "fake news",
        "social media",
        "propaganda",
        "breitbart",
        "alt-right"
      ],
      "influence_map": [],
      "chunk_index": 190
    },
    "id": "likewar_190"
  },
  {
    "section": "Spread of Disinformation",
    "text": "Ildefonso Ortiz and Brandon Darby, “Mexico Helping Unvetted African Migrants to U.S. Border, Many from Al-Shabaab Terror Hotbed,” Breitbart, September 10, 2016. John Hayward, “Three Green Berets Killed, Two Wounded in Niger Ambush,” Breitbart, October 5, 2017. John Herrman, “In the Trenches of the Facebook Election,” The Awl, November 21, 2014. Makysm Gabielkov et al., “Social Clicks: What and Who Gets Read on Twitter?” (paper prepared for Sigmetrics ’16, Antibes Juan-Les-Pins, France, June 14–18, 2016). Thomas E. Patterson, “News Coverage of the 2016 General Election: How the Press Failed the Voters,” Shorenstein Center on Media, Politics, and Public Policy, Harvard Kennedy School, December 7, 2016. Andrew Tyndall, “Issues? What Issues?,” Tyndall Report, October 25, 2016. Jonathan Easley, “Top Dem Super PAC Launches Anti-Trump War Room,” The Hill, December 6, 2016. Casey Michel, “The Bizarre Rise and Dramatic Fall of Louise Mensch and Her ‘Blue Detectives,’ ” ThinkProgress, January 19, 2018. Laura Daniels, “How Russia Hacked the French Election,” Politico, April 23, 2017. Vasco Cotovio and Emanuella Grinberg, “Spain: ‘Misinformation’ on Catalonia Referendum Came from Russia,” CNN, November 13, 2017. Ben Westcott, “Duped by Fake News Story, Pakistani Minister Threatens Nuclear War with Israel,” CNN, December 26, 2016. Justin Lynch, “In South Sudan, Fake News Has Deadly Consequences,” Slate, June 9, 2017.",
    "meta": {
      "theme": "Disinformation and Global Impact",
      "region": "Global",
      "use_case": "Political Interference, Social Unrest",
      "strategic_category": [
        "geopolitical_strategy",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "fake news",
        "disinformation",
        "social media",
        "international relations",
        "political interference"
      ],
      "influence_map": [],
      "chunk_index": 191
    },
    "id": "likewar_191"
  },
  {
    "section": "Impact and Consequences of Disinformation",
    "text": "\"Social Media and Conflict in South Sudan: A Lexicon of Hate Speech Terms\" (report, PeaceTech Lab, n.d.). “Hindutva.Info Runs Fake News of Hindus Thrashing Barkati,” ENewsRoom, February 16, 2018. Euan McKirdy, “When Facebook Becomes ‘the Beast’: Myanmar Activists Say Social Media Aids Genocide,” CNN, April 6, 2018. Amanda Taub and Max Fisher, “Where Countries Are Tinderboxes and Facebook Is a Match,” New York Times, April 21, 2018. Michael Lohmuller, “Panic Ensues After MS13 Allegedly Prohibits Blonde Hair in Honduras Markets,” InSight Crime, May 27, 2015. MS-13, press release, trans. Google Translate, InSight Crime. Ian Black and Fazel Hawramy, “ISIS Denies Ordering That All Girls in Mosul Undergo FGM,” The Guardian, July 24, 2014. Michael Barthel, Amy Mitchell, and Jesse Holcomb, “Many Americans Believe Fake News Is Sowing Confusion,” Pew Research Center, December 15, 2016. Caitlin Dewey, “What Was Fake on the Internet This Week: Why This Is the Final Column,” The Intersect (blog), Washington Post, December 18, 2015. “Digital Wildfires in a Hyperconnected World,” World Economic Forum. Sue Shellenbarger, “Most Students Don’t Know When News Is Fake, Stanford Study Finds,” Wall Street Journal, November 21, 2016. Matt McKinney, “ ‘If It’s Going Viral, It Must Be True’: Hampton Roads Kids Struggle with Fake News, Teachers Say,” Virginian-Pilot, November 28, 2016.",
    "meta": {
      "theme": "Social Impact of Disinformation",
      "region": "Global",
      "use_case": "Social Manipulation, Violence, Education",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "fake news",
        "social media",
        "misinformation",
        "social unrest",
        "education",
        "media literacy"
      ],
      "influence_map": [],
      "chunk_index": 192
    },
    "id": "likewar_192"
  },
  {
    "section": "Botnets and Social Manipulation",
    "text": "Angee’s archived Twitter account provides an excellent snapshot of a Russian botnet in action. See Angee Dixson (@ angeelistr). Isaac Arnsdorf, “Pro-Russian Bots Take Up the Right-Wing Cause After Charlottesville,” ProPublica, August 23, 2017. Christina Caron, “Heather Heyer, Charlottesville Victim, Is Recalled as a ‘Strong Woman,’ ” New York Times, August 13, 2017. Dan Merica, “Trump Says Both Sides to Blame Amid Charlottesville Backlash,” CNN, August 16, 2017. Casey Michel, “Russia-Linked Propaganda Accounts Banned by Twitter Are Still Active on Facebook,” ThinkProgress, November 4, 2017. Tom Williams, “The Power of Social Media ​— ​How Twitter Exposed a Brexiteer, More Influential Than Sky News",
    "meta": {
      "theme": "Botnets and Social Manipulation",
      "region": "Global, United States",
      "use_case": "Political Manipulation, Social Division",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "bots",
        "social media",
        "disinformation",
        "political manipulation",
        "russia"
      ],
      "influence_map": [],
      "chunk_index": 193
    },
    "id": "likewar_193"
  },
  {
    "section": "Introduction",
    "text": " as a Rus- sian Troll,” PoliticsMeansPolitics (blog), Medium, August 31, 2017, https:// blog.politicsmeanspolitics.com/the-power-of-social-media-how-twitter- exposed-a-brexiteer-more-influential-than-sky-news-as-a-e0b991129bd9. Fake followers and “likes”: Nicholas Confessore et al., “The Follower Factory,” New York Times, January 27, 2018, https://www.nytimes.com/in- teractive/2018/01/27/technology/social-media-bots.html. at least $1 billion: Doug Bock Clark, “Inside a Counterfeit Facebook Farm,” The Week, June 15, 2015, http://theweek.com/articles/560046/ inside-counterfeit-facebook-farm. 18 million “likes”: Heather Timmons and Josh Horwitz, “China’s Pro- paganda News Outlets Are Absolutely Crushing It on Facebook,” Quartz, May 6, 2016, https://qz.com/671211/chinas-propaganda-outlets-have- leaped-the-top-of-facebook-even-though-it-banned-at-home/. more than a million “fans”: Ibid. 4 percent supposedly lived: Jennings Brown and Adi Cohen, “There’s Something Odd About Donald Trump’s Facebook Page,” Vocativ, June 17, 2015, http://www.businessinsider.com/donald-trumps-facebook-follow ers-2015-6. Dhaka in Bangladesh: Charles Arthur, “How Low-Paid Workers at ‘Click Farms’ Create Appearance of Online Popularity,” The Guardian, August 2, 2013, https://www.theguardian.com/technology/2013/aug/02/ click-farms-appearance-online-popularity. Lapu-Lapu in the Philippines: Clark, “Inside a Counterfeit Facebook Farm.” companies’ spam protection: Ibid. Czech word meaning “slave”: Lydia H. Liu, The Freudian Robot: Digital Media and the Future of the Unconscious (University of Chicago Press, 2010), 6. “Lizynia Zikur”: ProPublica (@ProPublica), “The weirdness contin- ues. This Russian account has just 76 followers and tweeted just once: a smear of us, that got . . . 23,400+ retweets,” Twitter, August 24, 2017, 6:08 p.m., https://twitter.com/ProPublica/status/900887458400829440. The “Star Wars” botnet: Bill Brenner, “Twitter’s Phantom Menace: A Star Wars Botnet,” Naked Security, https://nakedsecurity.sophos .com/2017/01/25/potential-phantom-menace-found-on-twitter-a-star- wars-botnet/. roughly 15 percent: Confessore et al., “The Follower Factory.” random soccer statistics: Jillian C. York, “Syria’s Twitter spambots,” The Guardian, April 21, 2011, https://www.theguardian.com/commentis free/2011/apr/21/syria-twitter-spambots-pro-revolution. beautiful landscape images: Ibid. hashtags like #FreeTibet: “Twitter Bots Target Tibetan Protests,” Krebs on Security (blog), March 12, 2012, http://krebsonsecurity.com/2012/03/ twitter-bots-target-tibetan-protests/.",
    "meta": {
      "theme": "Social Media Manipulation",
      "region": "Global",
      "use_case": "Disinformation and Propaganda",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "bots",
        "fake followers",
        "click farms",
        "social media manipulation"
      ],
      "influence_map": [],
      "chunk_index": 194
    },
    "id": "likewar_194"
  },
  {
    "section": "Political Interference & Cyberwarfare",
    "text": "first documented uses: Marion R. Just et al., “ ‘It’s Trending on Twitter’ ​— ​ An Analysis of the Twitter Manipulations in the Massachusetts 2010 Spe- cial Senate Election” (paper prepared for the Annual Meeting of the Amer- ican Political Science Association, New Orleans, August 30–September 2, 2012), https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2108272#. “Swift Boat” negative advertising campaign: Ibid. “Twitterbomb”: Ibid. more than a million fake followers: Samuel Woolley and Phil Howard, “Bots Unite to Automate the Presidential Election,” Wired, May 15, 2016, https://www.wired.com/2016/05/twitterbots-2/. In Italy: Andrea Vogt, “Hot or Bot? Italian Professor Casts Doubt on Politician’s Twitter Popularity,” The Guardian, July 22, 2012, https://www .theguardian.com/world/2012/jul/22/bot-italian-politician-twitter-grillo. military cyberwarfare specialists: Choe Sang-Hun, “South Korean Offi- cials Accused of Political Meddling,” New York Times, December 19, 2013, http://www.nytimes.com/2013/12/20/world/asia/south-korean-cyber warfare-unit-accused-of-political-meddling.html. nearly 25 million messages: Lee Yoo Eun, “South Korea’s Spy Agency, Military Sent 24.2 Million Tweets to Manipulate Election,” Global Voices, November 25, 2013, https://globalvoices.org/2013/11/25/south-koreas-spy- agency-military-sent-24-2-million-tweets-to-manipulate-election/. shifted their attention: Philip N. Howard and Bence Kollanyi, “Bots, #Strongerin, and #Brexit: Computational Propaganda During the UK-EU Referendum,” arXiv:1606.06356 [cs.SI], June 20, 2016. ratio of five to one: Ibid. linked to Russia: Robert Booth et al., “Russia Used Hundreds of Fake Accounts to Tweet About Brexit, Data Shows,” The Guardian, November 14, 2017, https://www.theguardian.com/world/2017/nov/14/how-400- russia-run-fake-accounts-posted-bogus-brexit-tweets. less than 1 percent: Howard and Kollanyi, “Bots, #Strongerin, and #Brexit.” roughly 400,000 bot accounts: Alessandro Bessi and Emilio Ferrara, “So- cial Bots Distort the 2016 U.S. Presidential Election Online Discussion,” First Monday 21, no. 11 (November 2016), http://firstmonday.org/ojs/index. php/fm/article/view/7090/5653. “colonized” pro-Clinton hashtags: John Markoff, “Automated Pro-Trump Bots Overwhelmed Pro-Clinton Messages, Researchers Say,” New York Times, November 17, 2016, https://www.nytimes.com/2016/11/18/tech nology/automated-pro-trump-bots-overwhelmed-pro-clinton-messages- researchers-say.html?nytmobile=0&_r=0. five-to-one ratio: Bence Kollanyi, Philip N. Howard, and Samuel C. Woolley, “Bots and Automation over Twitter During the U.S. Election” (data memo 2016.4, Computational Propaganda Project, University of Oxford, November 2016), http://blogs.oii.ox.ac.uk/politicalbots/wp-con tent/uploads/sites/89/2016/11/Data-Memo-US-Election.pdf. quote 150 bots: “Chapter 15. Make America Bot Again. Part Three,” Sad- BotTrue, http://sadbottrue.com/article/24/. the online handle “MicroChip”: Joseph Bernstein, “Never Mind the Rus- sians, Meet the Bot King Who Helps Trump Win Twitter,” BuzzFeed, April 5, 2017, https://www.buzzfeed.com/josephbernstein/from-utah- with-love?utm_term=.dmdwvOGde#.hg6qwrJ28.",
    "meta": {
      "theme": "Political Interference and Cyberwarfare",
      "region": "Global",
      "use_case": "Election Manipulation, Propaganda",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "bots",
        "political bots",
        "election interference",
        "cyberwarfare",
        "disinformation"
      ],
      "influence_map": [],
      "chunk_index": 195
    },
    "id": "likewar_195"
  },
  {
    "section": "Information Warfare & Terrorism",
    "text": "more than 30,000 retweets: Ibid. “how this game works”: Ibid. their “information war”: “An Ex St. Petersburg ‘Troll’ Speaks Out,” Meduza, October 15, 2017, https://meduza.io/en/feature/2017/10/15/an- ex-st-petersburg-troll-speaks-out?utm_source=Sailthru&utm_ medium=email&utm_campaign=Newpercent20Campaign&utm_term =percent2ASituationpercent20Report. 2.2. million “election-related tweets”: Twitter, Inc., “United States Sen- ate Committee on the Judiciary, Subcommittee on Crime and Terrorism Update on Results of Retrospective Review of Russian-Related Election Activity,” January 19, 2018, https://www.judiciary.senate.gov/imo/media/ doc/Edgett%20Appendix%20to%20Responses.pdf. 454.7 million times: Ibid. cited forty-one times: Sheera Frenkel and Katie Bender, “To Stir Discord in 2016, Russians Turned Most Often to Facebook,” New York Times, Feb- ruary 17, 2018, https://www.nytimes.com/2018/02/17/technology/indict ment-russian-tech-facebook.html. 126 million users: Twitter, Inc., “United States Senate Committee on the Judiciary.” retweeted @realDonaldTrump: Ibid. collective U.S. intelligence community: “Assessing Russian Activities and Intentions in Recent US Elections” (Intelligence Community Assessment, Office of the Director of National Intelligence, January 6, 2017), https:// www.dni.gov/files/documents/ICA_2017_01.pdf. five different cybersecurity companies: P. W. Singer, “Cyber-Deterrence and the Goal of Resilience: 30 New Actions That Congress Can Take to Improve U.S. Cybersecurity,” testimony before the House Armed Ser- vices Committee hearing “Cyber Warfare in the 21st Century: Threats, Challenges, and Opportunities,” March 1, 2017, http://docs.house.gov/ meetings/AS/AS00/20170301/105607/HHRG-115-AS00-Wstate-Singer P-20170301.pdf. between 48 percent and 73 percent: Twitter, Inc., “United States Senate Committee on the Judiciary.” “The news media”: Jonathon Morgan and Kris Schaffer, “Sockpuppets, Secessionists, and Breitbart,” Data for Democracy (blog), Medium, March 31, 2017, https://medium.com/data-for-democracy/sockpuppets-seces sionists-and-breitbart-7171b1134cd5. Samuel Woolley: Craig Timberg, “As a Conservative Twitter User Sleeps, His Account Is Hard at Work,” Washington Post, February 5, 2017, https://www.washingtonpost.com/business/economy/as-a-conserva tive-twitter-user-sleeps-his-account-is-hard-at-work/2017/02/05/18d5a532 -df31-11e6-918c-99ede3c8cafa_story.html?utm_term=.59665eea94ba. France: Daniels, “How Russia Hacked the French Election.” Mexico: David Alire Garcia and Noe Torres, “Russia Meddling in Mex- ican Election: White House Aide McMaster,” Reuters, January 7, 2018,  https://www.reuters.com/article/us-mexico-russia-usa/russia-meddling- in-mexican-election-white-house-aide-mcmaster-idUSKBN1EW0UD. one study found: Kirk Semple and Marina Franco, “Bots and Trolls El- bow Into Mexico’s Crowded Electoral Field,” New York Times, May 1, 2018, https://www.nytimes.com/2018/05/01/world/americas/mexico-election- fake-news.html. Jonathon Morgan and Kris Schaffer: This report numbers among the most fascinating and insightful to come out of the flurry of data-driven, bot-centric journalism that began in 2017. Morgan and Schaffer, “Sockpup pets, Secessionists, and Breitbart.” particular language and culture: Ibid. “suddenly and simultaneously”: Ibid. a shared playbook: Ibid. four times as likely: Ibid. the word “Jewish”: Ibid. WIN THE NET, WIN THE DAY “Media weapons”: Charlie Winter, “Media Jihad: The Islamic State’s Doctrine for Information Warfare” (report, International Centre for the Study of Radicalisation and Political Violence, 2017), 18, http://icsr.info/ wp-content/uploads/2017/02/Media-jihad_web.pdf. “You can sit”: Lorraine Murphy, “The Curious Case of the Jihadist Who Started Out as a Hacktivist,” Vanity Fair, December 15, 2015, https:// www.vanityfair.com/news/2015/12/isis-hacker-junaid-hussain. “He had hacker cred”: Ibid. easy familiarity with: Del Quentin Wilber, “Here’s How the FBI Tracked Down a Tech-Savvy Terrorist Recruiter for the Islamic State,” Los Angeles Times, April 13, 2017, http://www.latimes.com/politics/la-fg-islamic-state- recruiter-20170406-story.html. some 30,000 recruits: Martin Chulov, Jamie Grierson, and Jon Swaine, “Isis Faces Exodus of Foreign Fighters as Its ‘Caliphate’ Crumbles,” The Guardian, April 26, 2017, https://www.theguardian.com/world/2017/ apr/26/isis-exodus-foreign-fighters-caliphate-crumbles. “The knives have",
    "meta": {
      "theme": "Information Warfare and Terrorism",
      "region": "Global",
      "use_case": "Recruitment, Propaganda, Disinformation",
      "strategic_category": [
        "military_doctrine",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "information warfare",
        "terrorism",
        "propaganda",
        "social media",
        "ISIS"
      ],
      "influence_map": [],
      "chunk_index": 196
    },
    "id": "likewar_196"
  },
  {
    "section": "The Rise of ISIS Propaganda",
    "text": "been”: Rukmini Callimachi, “Clues on Twitter Show Ties Between Texas Gunman and ISIS Network,” New York Times, May 11, 2015. He took a wife: Nancy Youssef, “The British Punk Rocker Widow Who Wants to Run ISIS’s Hackers,” The Daily Beast, September 27, 2015. Pentagon’s “kill list”: “UK Jihadist Junaid Hussain Killed in Syria Drone Strike, Says US,” BBC News, August 27, 2015. tricked into clicking: James Cartledge, “Isis Terrorist Junaid Hussain Killed in Drone Attack After Boffins ‘Crack Group’s Code,’ ” Birmingham Live, September 16, 2015. leave his stepson: Adam Goldman and Eric Schmitt, “One by One, ISIS Social Media Experts Are Killed as Result of F.B.I. Program,” New York Times, November 24, 2016. word of the day: Jessica Stern and J. M. Berger, ISIS: The State of Terror (Ecco, 2015), 120. apocalyptic interpretation: Quite literally apocalyptic. See William McCants, The ISIS Apocalypse: The History, Strategy, and Doomsday Vision of the Islamic State (St. Martin’s, 2015). “Terrorism is theater”: Brian Jenkins, “International Terrorism: A New Kind of Warfare” (RAND Papers Series, no. P-5261, RAND, June 1974). Jihadi Design: Gilad Shiloach, “How ISIS Supporters Learn to Design Propaganda,” The Daily Dot, March 7, 2017. “With the old methods”: Richard Engel, “Sadat’s Assassination Plotter Remains Unrepentant,” NBC News, July 5, 2011.",
    "meta": {
      "theme": "ISIS Propaganda and Recruitment",
      "region": "Middle East, Global",
      "use_case": "Terrorism, Online Radicalization",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "propaganda",
        "terrorism"
      ],
      "influence_map": [],
      "chunk_index": 197
    },
    "id": "likewar_197"
  },
  {
    "section": "The Spread of ISIS Propaganda",
    "text": "propelled by some 60,000: Steffan Truvé, “ISIS Jumping from Account to Account, Twitter Trying to Keep Up,” Recorded Future, September 3, 2014. dramatic screengrabs: George Brown and CNN Wire, “How Should Media Cover American Beheading,” News Channel 3, August 20, 2014. “Don’t share it”: Ibid. One aspiring politician: Amanda Terkel, “GOP House Candidate Uses James Foley Execution Footage in Campaign Ad,” Huffington Post, October 6, 2014. submerged in a pool: “ISIS Release Brutal Execution Videos of Mosul ‘Spies,’ ” Newsweek, June 23, 2015. “Kill the Jordanian”: Gilad Shiloach, “Crowdsourcing Terror: ISIS Asks for Ideas on Killing Jordanian Pilot,” Vocativ, December 26, 2014. “This is our football”: Jay Caspian King, “ISIS’s Call of Duty,” The New Yorker, September 18, 2014. “first terrorist group”: Jared Cohen, “Digital Counterinsurgency: How to Marginalize the Islamic State Online,” Foreign Affairs, November/December 2015. nearly fifty different: Charlie Winter, “Documenting the Virtual ‘Caliphate’ ” (report, Quilliam, October 2015), 16. over a thousand “official”: Ibid., 5. at least 30,000 civilians: “Iraq Body Count,” accessed March 19, 2018. lived with their parents: “Case by Case: ISIS Prosecutions in the United States, March 1, 2014–June 30, 2016” (report, Center on National Security at Fordham Law, July 2016). pledge his allegiance: Thomas Joscelyn, “Orlando Terrorist Swore Allegiance to Islamic State’s Abu Bakr al Baghdadi,” FDD’s Long War Journal, June 20, 2016.",
    "meta": {
      "theme": "ISIS Propaganda Dissemination and Impact",
      "region": "Middle East, Global",
      "use_case": "Terrorism, Media Manipulation, Public Opinion",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "media manipulation",
        "violence",
        "online dissemination"
      ],
      "influence_map": [],
      "chunk_index": 198
    },
    "id": "likewar_198"
  },
  {
    "section": "The Psychology of Propaganda and the Modern Media Landscape",
    "text": "had gone viral: Denver Nicks, “Orlando Shooter Checked Facebook to See If His Attack Went Viral,” Time, June 16, 2016. virtually every scholar: Jennifer Williams, “How ISIS Uses and Abuses Islam,” Vox, November 18, 2015. exaggerated its gains: Daveed Gartenstein-Ross, Nathaniel Barr, and Bridget Moreng, “How the Islamic State’s Propaganda Feeds Into Its Global Expansion Efforts,” War on the Rocks, April 28, 2016. claim after the fact: Joshua Keating, “ISIS Is Not Known for Falsely Taking Credit for Attacks — Until Recently,” Slate, October 2, 2017. “If there is”: Mark Mazzetti and Eric Schmitt, “In the Age of ISIS, Who’s a Terrorist, and Who’s Simply Deranged?,” New York Times, July 17, 2016. “information jihad”: Charlie Winter, “What I Learned from Reading the Islamic State’s Propaganda Instruction Manual,” Lawfare (blog), April 2, 2017. media “projectiles”: Ibid. “make terrorism sexy”: David Francis, “Why Don Draper Would Be Impressed by the Islamic State,” The Cable (blog), Foreign Policy, April 7, 2015. “became a reality star”: Spencer Pratt, phone interview with authors, May 23, 2016. how to make $50,000: Naomi Fry, “The Reality-TV Star Spencer Pratt on America’s Addiction to Drama,” The New Yorker, June 30, 2017. “I saw The Osbournes”: Pratt interview. the Kardashians: Suzannah Weiss, “Spencer Pratt Missed His Chance to Make the Kardashians Famous,” Refinery29, February 20, 2017. nightclub called Privilege: Michael Sunderland, “Head over Hills: The Undying Love Story of Heidi and Spencer Pratt,” Vice, February 12, 2016. “manipulating the media”: Pratt interview. “working with the paparazzi”: Ibid. “Best Villain”: “Teen Choice Awards 2009 Nominees,” Los Angeles Times, June 15, 2009. “shot that scene”: Pratt interview. “just an awful asshole”: Ibid. pioneering 1944 study: Fritz Heider and Marianne Simmel, “An Experimental Study of Apparent Behavior,” American Journal of Psychology 57, no. 2 (1944): 243–59. “psychological political by-products”: Matthew Armstrong, “The Past, Present, and Future of the War for Public Opinion,” War on the Rocks, January 19, 2017. “everyone’s an editor”: Heidi Montag, phone interview with authors, May 23, 2016. “everyone is a reality star”: Pratt interview. shrunk to eight seconds: “Attention Span Statistics,” Statistic Brain. fifth-grade education: “Most Presidential Candidates Speak at Grade 6–8 Level,” Cision, March 16, 2016. the complexity score dipped: Derek Thompson, “Presidential Speeches Were Once College-Level Rhetoric — Now They’re for Sixth-Graders,” The Atlantic, October 14, 2014.",
    "meta": {
      "theme": "Media Manipulation and Public Perception",
      "region": "United States, Global",
      "use_case": "Propaganda, Reality TV, Political Discourse",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "attention span",
        "public opinion",
        "media literacy"
      ],
      "influence_map": [],
      "chunk_index": 199
    },
    "id": "likewar_199"
  },
  {
    "section": "The Viral Nature of Misinformation",
    "text": "a shark swimming down: Kaleigh Rogers, “ ‘Shark Swims Down a Flooded Street’ Is a Viral Hoax That Won’t Die,” Motherboard (blog), Vice, October 5, 2015. more unyieldingly hyperpartisan: Adam Hughes and Onyi Lam, “Highly Ideological Members of Congress Have More Facebook Followers Than Moderates Do,” Pew Research Center, August 21, 2017. why conspiracy theories: Marco Guerini and Carlo Strapparava, “Why Do Urban Legends Go Viral?,” Information Processing and Management 52, no. 1 (January 2016): 163–72. a jar of Nutella: Scott Campbell, “ISIS Using Kittens and NUTELLA to Lure Jihadi Wannabes into Evil Death Cult,” Mirror, May 27, 2016. from far-right political leaders: Andrew Marantz, “Trolls for Trump,” The New Yorker, October 31, 2016.",
    "meta": {
      "theme": "Spread of Misinformation and Polarization",
      "region": "United States, Global",
      "use_case": "Online Hoaxes, Political Polarization, Conspiracy Theories",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "viral content",
        "misinformation",
        "political polarization"
      ],
      "influence_map": [],
      "chunk_index": 200
    },
    "id": "likewar_200"
  },
  {
    "section": null,
    "text": "ine/2016/10/31/trolls-for-trump. 160 women’s rights activists: Laura Durnell, “All Women Must Control the Narrative in and After the Trumpian Age,” Huffington Post, February 28, 2017, https://www.huffingtonpost.com/entry/women-must-control-the- narrative-in-the-age-of-trump_us_58b609fae4b02f3f81e44dc7. 160 the Kardashian clan: Nathan Heller, “The Multitasking Celebrity Takes Center Stage,” The New Yorker, June 23, 2016, http://www.newyorker.com/ culture/cultural-comment/the-organizational-celebrity. 160 Omar Hammami: Simon Cottee, “Why It’s So Hard to Stop ISIS Propa- ganda,” The Atlantic, March 2, 2015, https://www.theatlantic.com/interna tional/archive/2015/03/why-its-so-hard-to-stop-isis-propaganda/386216/. 161 “we’ll lose the battle”: Meeting (not for attribution), Department of State, Washington, DC, October 7, 2015. 161 Gunner Stone: Korey Lane, “What Does Gunner Stone Mean? Heidi Montag and Spencer Pratt’s First Child Is Already Pretty Interesting,” Romper, October 4, 2017, https://www.romper.com/p/what-does-gun ner-stone-mean-heidi-montag-spencer-pratts-first-child-is-already-pretty- interesting-2790177. 161 “When we do not know”: T. S. Eliot, “The Perfect Critics,” in The Sacred Wood: Essays on Poetry and Criticism (Knopf, 1921), 9. 161 “vast accumulations of knowledge”: Ibid. 162 the stronger the emotions: Jonah Berger and Katherine Milkman, “What Makes Online Content Viral?,” Journal of Marketing Research 49, no. 2 (2012): 192–205; Marco Guerini and Jacopo Staiano, “Deep Feelings: A Massive Cross-Lingual Study on the Relation Between Emotions and Vi- rality,” arXiv:1503.04723 [cs.SI], March 2015. 162 70 million messages: Rui Fan et al., “Anger Is More Influential Than Joy: Sentiment Correlation in Weibo,” PLoS ONE 9, no. 10 (2014), e:110184, http://journals.plos.org/plosone/article/file?id=10.1371/journal. pone.0110184&type=printable. 162 “Anger is more influential”: Ibid. 162 ramp up their language: Ibid. 162 nearly 700,000 users: Adam D. L. Kramer, Jamie E. Guillory, and Jeffrey T. Hancock, “Experimental Evidence of Massive-Scale Emotional Conta- gion Through Social Networks,” PNAS 111, no. 24 (2014): 8788–90. 162 “emotional contagion”: Ibid. 163 “Our lives matter”: Elazar Sontag, “To This Black Lives Matter Co- founder, Activism Begins in the Kitchen,” Washington Post, March 26, 2018, https://www.washingtonpost.com/lifestyle/food/to-this-black-lives- Notes 341 matter-co-founder-activism-begins-in-the-kitchen/2018/03/26/964ec51a- 2df1-11e8-b0b0-f706877db618_story.html?utm_term=.150be2273ebc. 163 adding the hashtag #BlackLivesMatter: Jon Schuppe and Safia Samee Ali, “Cities Don’t Want Justice Department to Back Off Police Reforms,” NBC News, April 5, 2017, http://www.nbcnews.com/news/us-news/cities-dont- want-justice-department-back-police-reforms-n742661. 163 “trolling for MiGs”: Andy Bodle, “Trolls: Where Do They Come From?,” The Guardian, April 19, 2012, https://www.theguardian.com/media/mind- your-language/2012/apr/19/trolls-where-come-from.",
    "meta": {
      "theme": "Social Media and Propaganda",
      "region": "Global/Online",
      "use_case": "Information Warfare/Social Manipulation",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "propaganda",
        "social media",
        "trolling",
        "emotional manipulation",
        "viral content"
      ],
      "influence_map": [],
      "chunk_index": 201
    },
    "id": "likewar_201"
  },
  {
    "section": null,
    "text": "164 “If you don’t fall”: Steven Supmante, “Trolling the Web: A Guide,” Ur- ban75 Magazine, n.d., http://www.urban75.com/Mag/troll.html#one. 164 emotional manipulation: Natalie Sest and Evita March, “Constructing the Cyber-Troll: Psychopathy, Sadism, and Empathy,” Personality and Indi- vidual Differences 119 (December 2017): 69–72. 164 philosopher Jean-Paul Sartre: Anti-Semite and Jew (Schocken, 1948), 13. 164 “Ironghazi”: Ben Collins and Joseph Cox, “Jenna Abrams, Russia’s Clown Troll Princess, Duped the Mainstream Media and the World,” The Daily Beast, November 2, 2017, https://www.thedailybeast.com/jenna- abrams-russias-clown-troll-princess-duped-the-mainstream-media-and- the-world. 164 psychopathy and sadism: Sest and March, “Constructing the Cyber- Troll.” 165 twice as likely to engage: Justin Cheng et al., “Anyone Can Become a Troll: Causes of Trolling Behavior in Online Discussions,” arXiv:1702.01119 [cs. SI], February 2017, 8. 165 “can be contagious”: Ibid., 2. 166 “You have the prettiest”: Jonathan Vankin, “Taylor Swift the New Dear Abby? Gives Lovelorn Fan Wise-Beyond-Her-Years Advice,” Inquisitr, July 25, 2014, http://www.inquisitr.com/1373553/taylor-swift-the-new- dear-abby-gives-lovelorn-fan-wise-beyond-her-years-advice/. 166 another, 16-year-old fan: Rebecca Borison, “Taylor Swift Is Incredibly Good at Being a Celebrity,” Business Insider, September 10, 2014, http:// www.businessinsider.com/taylor-swift-is-a-business-genius-2014-9. 166 #Taylurking: Lindsey Weber, “Taylor Swift Is the Reigning Queen of Celebrity Social-Media,” Vulture, October 29, 2014, http://www.vulture. com/2014/10/taylor-swift-queen-of-celebrity-social-media.html. 166 “this new site”: Taylor Swift, “For Taylor Swift, the Future of Music Is a Love Story,” Wall Street Journal, July 7, 2014, https://www.wsj.com/ar ticles/for-taylor-swift-the-future-of-music-is-a-love-story-1404763219. 166 “In the future”: Ibid. 342 Notes 166 she strategically copyrighted: Dan Rys, “Taylor Swift Files Nine Trade- marks for the Word ‘Swifties,’ but Why?,” Billboard, March 15, 2017, https:// www.billboard.com/articles/business/7727743/taylor-swift-trademarks- swifties-but-why. 166 40 million albums: “Taylor Swift Named IFPI Global Recording Artist of 2014,” IFPI, February 23, 2015, http://www.ifpi.org/news/Taylor-Swift- named-IFPI-global-recording-artists-of-2014. 166 digital streaming records: Lisa Marie Segarra, “Taylor Swift’s Spotify Songs Made an Insane Amount of Money in a Week,” Fortune, June 23, 2017, http://fortune.com/2017/06/23/taylor-swift-spotify-songs-money/. 166 youngest of Forbes: Zack O’Malley Greenburg, “Taylor Swift Is the Youngest of America’s Richest Self-Made Women,” Forbes, June 1, 2016, https://www.forbes.com/sites/zackomalleygreenburg/2016/06/01/ taylor-swift-is-the-youngest-of-americas-richest-self-made-wo men/#3c2593c07c1a.",
    "meta": {
      "theme": "Cultivating Online Fandom",
      "region": "Global/Online",
      "use_case": "Public Relations/Brand Management",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos"
      ],
      "usage_tags": [
        "fan engagement",
        "social media marketing",
        "celebrity branding",
        "online community building"
      ],
      "influence_map": [],
      "chunk_index": 202
    },
    "id": "likewar_202"
  },
  {
    "section": null,
    "text": "166 weren’t very candid: Tim Teeman, “Why Taylor Swift’s Parties Look Like Utter Hell,” The Daily Beast, July 6, 2016, http://www.thedailybeast. com/why-taylor-swifts-parties-look-like-utter-hell. 166 “There’s no simple answer”: Amy Zimmerman, “How Kim Kardashian Beat Taylor Swift at Her Own Game,” The Daily Beast, July 18, 2016, http://www.thedailybeast.com/how-kim-kardashian-beat-taylor-swift- at-her-own-game. 167 an impromptu concert: Anna Silman, “Taylor Swift Gives the Gift of Taylor Swift for Christmas,” The Cut, December 27, 2016, https://www. thecut.com/2016/12/taylor-swift-gives-the-gift-of-taylor-swift-for-christ mas.html. 167 random Christmas gifts: Kristin Harris, “Taylor Swift Surprised Her Fans with Christmas Presents and Their Reactions Are Hysterical,” BuzzFeed, November 13, 2014, https://www.buzzfeed.com/kristinhar ris/taylor-swift-sent-fans-surprise-christmas-presents?utm_term=.aqzd ZLPZB2#.xxNbKEBK2k. 167 “the element of surprise”: Swift, “For Taylor Swift.” 167 birthday parties: Christiaan Triebert (@trbrtc), “IS fighters having din- ner and cake. Photo found on mobile phone killed fighter. (h/t@Afarin- Mamosta/@theOSINTblog),” Twitter, May 18, 2016, 12:35 p.m., https:// twitter.com/trbrtc/status/733018236481089537. 167 their cats: “Cat got your gun? Iraq, Syria, jihadist pictures go vi- ral,” Al Arabiya, June 22, 2014, https://english.alarabiya.net/en/vari ety/2014/06/22/ISIS-fighters-big-on-cats.html. 168 Jumanji: John Hall, “ ‘We Are Humans Like You . . . Why Shouldn’t We Notes 343 See Jumanji?,’ ” Daily Mail, August 12, 2014, http://www.dailymail.co.uk/ news/article-2722878/Bizarre-Twitter-outburst-ISIS-fighters-reveal-love- late-Robin-Williams-blockbuster-hit-Jumanji.html. 169 “People feel like”: “Longform Podcast #254: Maggie Haberman,” Longform, July 26, 2017, https://longform.org/posts/longform-podcast- 254-maggie-haberman. 169 team of eleven staffers: Kyle Cheney, “The Staff Army Behind a Clinton Tweet,” Politico Live Blog, Politico, October 15, 2016, https://www.politico .com/live-blog-updates/2016/10/john-podesta-hillary-clinton-emails- wikileaks-000011. 169 “modern day presidential”: Donald Trump (@realDonaldTrump), “My use of social media is not Presidential ​— ​it’s modern day presi- dential. Make America Great Again!,” Twitter, July 1, 2017, 3:41 p.m., https://twitter.com/realDonaldTrump/status/881281755017355264. 169 La Meute: Julia Carrie Wong, “How Facebook Groups Bring People Closer Together ​— ​Neo-Nazis Included,” The Guardian, July 31, 2017, https://www.theguardian.com/technology/2017/jul/31/extremists-neo- nazis-facebook-groups-social-media-islam. 169 “bring the world”: Josh Constine, “Facebook Changes Mission State- ment to ‘Bring the World Closer Together,’ ” TechCrunch, June 22, 2017, https://techcrunch.com/2017/06/22/bring-the-world-closer-together/.",
    "meta": {
      "theme": "Political Use of Social Media",
      "region": "Global/Online",
      "use_case": "Political Campaigning/Extremism",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "political communication",
        "online extremism",
        "social media campaigns",
        "community building"
      ],
      "influence_map": [],
      "chunk_index": 203
    },
    "id": "likewar_203"
  },
  {
    "section": null,
    "text": "170 ballooned 600 percent: J. M. Berger, “Nazis vs. ISIS on Twitter: A Com- parative Study of White Nationalist and ISIS Online Social Media Net- works” (paper, Program on Extremism, George Washington University, September 2016), https://cchs.gwu.edu/sites/g/files/zaxdzs2371/f/down loads/Nazis%20v.%20ISIS%20Final_0.pdf. 170 some 1,600: “Hate and Extremism,” Southern Poverty Law Center, ac- cessed March 20, 2018, https://www.splcenter.org/issues/hate-and-ex tremism. 170 fifty people were killed: Keegan Hankes and Alex Amend, “The Alt- Right Is Killing People,” Southern Poverty Law Center, February 5, 2018, https://www.splcenter.org/20180205/alt-right-killing-people. 170 mothers of children: Julia Ioffe, “Mothers of ISIS,” Huffington Post, Au- gust 12, 2015, http://highline.huffingtonpost.com/articles/en/mothers-of- isis/. 170 Sunday school teacher: Rukmini Callimachi, “ISIS and the Lonely Young American,” New York Times, June 27, 2015, https://www.nytimes .com/2015/06/28/world/americas/isis-online-recruiting-american.html. 170 “It’s a closed community”: Scott Shane, Matt Apuzzo, and Eric Schmitt, “Americans Attracted to ISIS Find an ‘Echo Chamber’ on Social Media,” New York Times, December 8, 2015, http://www.nytimes.com/2015",
    "meta": {
      "theme": "Online Extremism and Radicalization",
      "region": "Global/Online",
      "use_case": "Recruitment/Propaganda",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "online radicalization",
        "extremist groups",
        "social media recruitment",
        "echo chambers"
      ],
      "influence_map": [],
      "chunk_index": 204
    },
    "id": "likewar_204"
  },
  {
    "section": "Introduction",
    "text": "Americans attracted to ISIS find an echo chamber on social media.  Isolation may be a key factor. Farah Pandith emphasizes the importance of peer-to-peer relations and focusing on millennials. She notes that governments lack credibility with this group. Initiatives like the Online Civil Courage Initiative and Gen Next aim to counter extremist narratives. Creative Minds for Social Good also works to counter terrorist propaganda by swarming the content.  The digital world is a battleground.",
    "meta": {
      "theme": "Social Media and Terrorism",
      "region": "Global",
      "use_case": "Counterterrorism",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "ISIS",
        "terrorism",
        "propaganda",
        "millennials"
      ],
      "influence_map": [],
      "chunk_index": 205
    },
    "id": "likewar_205"
  },
  {
    "section": "Political Manipulation of Social Media",
    "text": "Trump's 2016 presidential campaign heavily utilized social media.  His use of Twitter traumatized Washington, yet he credited social media for his victory. The discussion board /r/The_Donald became a hub for his supporters, and Trump aides engaged with them. Memes created on these platforms were often shared by Trump on Twitter, demonstrating a pattern of online engagement and manipulation.  Hillary Clinton's campaign struggled on social media.  Trump's team, led by Jared Kushner and Brad Parscale, exploited Facebook's advertising tools and data to microtarget voters.  They used data analytics firm Cambridge Analytica to gather extensive user data, including direct messages and likes, to build psychological profiles and target specific demographics with tailored messages.",
    "meta": {
      "theme": "Political Campaigning",
      "region": "United States",
      "use_case": "Election Influence",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "Trump",
        "election",
        "propaganda",
        "data analytics",
        "Facebook",
        "Twitter"
      ],
      "influence_map": [],
      "chunk_index": 206
    },
    "id": "likewar_206"
  },
  {
    "section": "Information Warfare",
    "text": "The use of information as a weapon has a long history.  In World War I, Britain cut Germany's transatlantic cables, disrupting their communication.  Germany responded with propaganda, using the term \"kadaver\" to describe the British action.  The US also used propaganda during the war.  The concept of cyberwar emerged in the 1990s, recognizing the growing importance of information in conflict.",
    "meta": {
      "theme": "Information Warfare",
      "region": "Global",
      "use_case": "Military and Political Strategy",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "information warfare",
        "propaganda",
        "cyberwar",
        "World War I"
      ],
      "influence_map": [],
      "chunk_index": 207
    },
    "id": "likewar_207"
  },
  {
    "section": "Content Creation and Dissemination",
    "text": "BuzzFeed's strategy of creating shareable content, including quizzes and listicles, was highly successful in gaining online attention.  They monitored the performance of their articles closely, optimizing for social sharing.  This approach, combined with the rise of social media, created a new landscape for information dissemination, which could be exploited for political purposes.  The Russian \"firehose of falsehood\" propaganda model involves spreading a high volume of disinformation across multiple channels, overwhelming audiences and making it difficult to distinguish truth from falsehood.",
    "meta": {
      "theme": "Content Strategy and Disinformation",
      "region": "Global",
      "use_case": "Propaganda and Influence Operations",
      "strategic_category": [
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "content strategy",
        "disinformation",
        "propaganda",
        "social media",
        "BuzzFeed"
      ],
      "influence_map": [],
      "chunk_index": 208
    },
    "id": "likewar_208"
  },
  {
    "section": "Memes and Memetic Warfare",
    "text": "“It means trying.”183 essentially a dead topic.183 “Our hope was....”183  “global information warfare”184 release of an atomic bomb.184 “blur the traditional”184 “a system of spiritual”184 “measures aiming to pre-empt”184 “three warfares”184 “War is accelerating”185 Operation Earnest Voice.185 “allow one U.S. serviceman”185 In 2015, Britain formed.185 “agent of change”185 “weaponization of social media”185 “chilled-out [dude]”186 declared a hate symbol.187 Trump tweeted a picture.187 “somewhere in the American”187 Russia’s UK embassy.187 “drinkin’, stinkin’ ”187 “Feels good man”187 began to make their own.187 the unofficial mascot.187",
    "meta": {
      "theme": "Information Warfare & Memetics",
      "region": "Global",
      "use_case": "Military and Political Influence",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos"
      ],
      "usage_tags": [
        "information_operations",
        "propaganda",
        "social_media",
        "internet_culture"
      ],
      "influence_map": [],
      "chunk_index": 209
    },
    "id": "likewar_209"
  },
  {
    "section": "The Weaponization of Memes",
    "text": "thirty “shitposters”188 a literal Nazi.188 punched him in the face.188 “Meme War Veteran”189 far-right militias.189 peppered with Pepe memes.189 Ku Klux Klan mask.189 evolutionary biologist Richard Dawkins.189 “The computers”189 Russian secret police.190 “It is a perfect milieu”190 “a first class ecology”190 a toxic Twitter troll.190 “Digital content can travel”191 went so far as to sue.191 “nonlinear battlefield”191 “military memetics”191 “Exploring the Utility”191 Bureau of Memetic Warfare.192 One user grandly summarized.192 form of Jeff Giesea.192 put his thoughts to paper.192 “It’s time to adopt”192",
    "meta": {
      "theme": "Information Warfare & Memetics",
      "region": "Global",
      "use_case": "Extremism, Political Campaigns, Social Manipulation",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "information_operations",
        "radicalization",
        "political_campaigns",
        "online_communities"
      ],
      "influence_map": [],
      "chunk_index": 210
    },
    "id": "likewar_210"
  },
  {
    "section": "Targeted Killings and Drone Warfare",
    "text": "“Own the moment”193 bombs on packed school buses.193 five assassination attempts.193 Israeli Heron drone.193 “The IDF has begun”193",
    "meta": {
      "theme": "Targeted Killings & Drone Warfare",
      "region": "Middle East (Gaza Strip)",
      "use_case": "Counterterrorism & Military Operations",
      "strategic_category": [
        "military_doctrine",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "drone_strikes",
        "assassinations",
        "hamas",
        "israel_defense_forces"
      ],
      "influence_map": [],
      "chunk_index": 211
    },
    "id": "likewar_211"
  },
  {
    "id": "likewar_212",
    "section": "Extracted Content",
    "text": "2,",
    "meta": {
      "theme": "unspecified",
      "region": "unspecified",
      "use_case": "doctrine_selector",
      "strategic_category": {},
      "economic_category": {},
      "civilizational_category": {},
      "usage_tags": [],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": []
      },
      "chunk_index": 212
    }
  },
  {
    "section": "Online Information Warfare Tactics and Examples",
    "text": "Israel has engaged in online campaigns to counter the BDS movement, utilizing tactics such as recruiting online \"soldiers\" and monitoring social networks.  These efforts involve disseminating information and engaging in online debates to sway public opinion.  Meanwhile, groups like the Taliban have used social media platforms for propaganda and to mock opponents, sometimes employing personal attacks against figures like General David Petraeus.  In Libya, Facebook has played a significant role in militia communications and information dissemination during conflict.  Ukraine has been a battleground for information warfare, with both sides utilizing social media to spread their narratives, often incorporating emotional appeals and manipulating information.  Russia's involvement in information operations, often described as \"hybrid warfare,\" has included spreading disinformation and propaganda, aiming to destabilize adversaries and influence public discourse.  These examples highlight the evolving landscape of information warfare and the various tactics employed by different actors.",
    "meta": {
      "theme": "Information Warfare",
      "region": "Global",
      "use_case": "Propaganda, Counter-messaging, Disinformation",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "propaganda",
        "disinformation",
        "hybrid warfare"
      ],
      "influence_map": [],
      "chunk_index": 213
    },
    "id": "likewar_213"
  },
  {
    "section": "Russian Information Operations and Influence Campaigns",
    "text": "Russia has been accused of extensive information operations, particularly in Eastern Europe and beyond.  In Ukraine, Russia allegedly fueled narratives around the Euromaidan protests and the conflict in the east, disseminating disinformation about atrocities and manipulating public opinion.  Russia's state-funded media outlets, such as RT and Sputnik, have been identified as tools for spreading propaganda and influencing international discourse.  Accusations of Russian interference extend to political events in various countries, including the Scottish independence referendum, the Brexit vote, the Catalan independence movement, and elections in Germany.  These operations often involve exploiting social media, spreading disinformation, and amplifying divisive narratives to destabilize target countries and advance Russian interests.  The concept of \"hybrid warfare,\" combining conventional and unconventional tactics, is frequently used to describe Russia's approach to information operations.",
    "meta": {
      "theme": "Information Warfare, Geopolitical Competition",
      "region": "Eastern Europe, Global",
      "use_case": "Political Interference, Disinformation, Propaganda",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture",
        "geostrategic_positioning"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "hybrid warfare",
        "propaganda",
        "disinformation",
        "political interference"
      ],
      "influence_map": [],
      "chunk_index": 214
    },
    "id": "likewar_214"
  },
  {
    "section": "Balkan Gambit",
    "text": "Gordana Andric reported in Balkan Insight on October 29, 2016, that 207 local police discovered weapons near the Serbian PM's house.  The European Parliament, on November 23, 2016, urged action against Russian 'hostile propaganda,' a statement Putin answered with disdain.  Ladislav Bittman, in *The KGB and Soviet Disinformation* (quoted by Stanley B. Cunningham in *The Idea of Propaganda*), describes how \"every disinformation message\" is crafted.  Hunter S. Thompson, in *Fear and Loathing on the Campaign Trail '72*, uses the phrase \"make the sonofabitch.\" Joseph Bernstein, in a BuzzFeed article from January 11, 2017, detailed the alt-right's campaign to smear Trump protesters, including the use of the phrase \"Rape Melania\" and its rise as a top-trending hashtag.  Breitbart ran a smug headline on the incident on November 13, 2016. Posobiec admitted his involvement in the smear campaign, as noted in Bernstein's article and discussed on Posobiec’s Wikipedia talk page under \"character assassination.\"  In January 2015, Euromaidan Press reported on Yuriy Stets, Minister of Information Policy, wanting to create an 'Internet Army.'  Sputnik, in June 2015, turned the Ukrainian Internet Army's efforts into a joke.  Rachel Stern, in the Christian Science Monitor on January 9, 2017, discussed Germany’s plan to fight fake news, including the Center of Defense Against Disinformation, which RT compared to a 'ministry of truth' in a YouTube video on December 24, 2016. Fox News, on June 17, 2017, reported on Hannity’s claims of a 'deep state' plot against Trump.",
    "meta": {
      "theme": "Disinformation and Propaganda",
      "region": "Balkans, Europe, United States, Ukraine, Germany, Russia, Syria",
      "use_case": "Political manipulation, smear campaigns, online warfare",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "information warfare",
        "propaganda",
        "disinformation",
        "social media manipulation",
        "cyber warfare"
      ],
      "influence_map": [],
      "chunk_index": 215
    },
    "id": "likewar_215"
  },
  {
    "section": "Anonymous, Ghost Security Group, and Tracking Disinformation",
    "text": "A shrouded figure, representing Anonymous, features in a YouTube video from June 21, 2014, about Operation Ice ISIS. Emerson Brooking, in Foreign Policy on November 13, 2015, described the \"war\" between Anonymous and the Islamic State. Ghost Security Group highlights \"cyber terrain vigilance\" on their homepage.  Laura Rosenberger and J. M. Berger, in a German Marshall Fund blog post on August 2, 2017, discuss Hamilton 68, a tool to track Russian disinformation on Twitter.",
    "meta": {
      "theme": "Cyber Warfare and Counter-Disinformation",
      "region": "Global",
      "use_case": "Online activism, tracking disinformation",
      "strategic_category": [
        "military_doctrine",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "hacktivism",
        "cyber security",
        "information warfare",
        "online monitoring"
      ],
      "influence_map": [],
      "chunk_index": 216
    },
    "id": "likewar_216"
  },
  {
    "section": "The Case of Bana Alabed",
    "text": "Bana Alabed, a seven-year-old girl from Aleppo, gained attention on Twitter with tweets about her life during the Syrian civil war.  She tweeted about needing peace, fearing death from bombs, and missing school, garnering over 200,000 followers, including author J. K. Rowling. Critics alleged that her account was a propaganda tool. Nick Waters, in a Bellingcat investigation on December 14, 2016, verified Bana's existence and highlighted her English-literate mother's role in managing the account.  President al-Assad, in an interview with Global Research on October 7, 2016, referred to events in Aleppo as a \"game of propaganda.\"",
    "meta": {
      "theme": "Information Warfare in Conflict Zones",
      "region": "Syria",
      "use_case": "Propaganda, shaping public opinion",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "information operations",
        "social media",
        "civil war",
        "propaganda"
      ],
      "influence_map": [],
      "chunk_index": 217
    },
    "id": "likewar_217"
  },
  {
    "section": "Geopolitical Tensions and Censorship",
    "text": "Reuters reported on January 17, 2016, that Taiwan was Beijing's number one security issue, with China potentially using force for unification.  Peter Navarro, in a HuffPost article on December 6, 2017, wrote about \"Senkaku Suicide Scenarios.\"  Bethany Allen-Ebrahimian, in a Foreign Policy blog post on July 12, 2016, discussed China's censorship of online calls for war after the South China Sea ruling.  Thomas J. Christensen, in Foreign Affairs in March/April 2011, wrote about \"The Advantages of an Assertive China.\" Jan Ian Chong and Todd H. Hall, in \"The Lessons of 1914 for East Asia Today,\" discussed historical parallels and potential conflicts.",
    "meta": {
      "theme": "Geopolitical Tensions and Censorship",
      "region": "East Asia, South China Sea, Taiwan",
      "use_case": "Territorial disputes, information control",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security",
        "geostrategic_positioning"
      ],
      "economic_category": [
        "resource_strategies"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "censorship",
        "territorial disputes",
        "military strategy",
        "international relations"
      ],
      "influence_map": [],
      "chunk_index": 218
    },
    "id": "likewar_218"
  },
  {
    "section": "The Dilemmas of Deletion",
    "text": "mocracy,” The Atlantic, October 12, 2017, https://www.theatlantic.com/technology/archive/2017/10/what-facebook-did/542502/. “process of building”: John Herrman, “How Hate Groups Forced Online Platforms to Reveal Their True Nature,” New York Times Magazine, August 21, 2017, https://www.nytimes.com/2017/08/21/magazine/how-hate-groups-forced-online-platforms-to-reveal-their-true-nature.html?nytmobile=0&_r=0. “You’re so focused”: Deepa Seetharaman, Robert McMillan, and Georgia Wells, “Tone-Deaf: How Facebook Misread America’s Mood on Russia,” Wall Street Journal, March 2, 2018, https://www.wsj.com/articles/tone-deaf-how-facebook-misread-americas-mood-on-russia-1520006034. “Political stories”: “Tell HN: Political Detox Week,” Hacker News, Y Combinator, accessed March 20, 2018, https://news.ycombinator.com/item?id=13108404. This is a fascinating discussion thread that digs deep into the Silicon Valley zeitgeist. “If we could use code”: Authors’ interview with senior social media company official, Washington, DC, July 14, 2016. pleas from Ukrainian activists: Volodymyr Scherbachenko, “We Support Ukraine on Facebook!,” trans. Facebook built-in translator, Facebook, August 28, 2014, https://www.facebook.com/uspikh/posts/355353931293866?fref=nf. “integrity of the German elections”: “Read Mark Zuckerberg’s Full Remarks on Russian Ads That Impacted the 2016 Elections,” CNBC, September 21, 2017, https://www.cnbc.com/2017/09/21/zuckerbergs-full-remarks-on-russian-ads-that-impacted-2016-election.html?view=story&%24DEVICE%24=native-android-tablet. “spreading prosperity”: Mark Zuckerberg, “Building Global Community,” Facebook, February 16, 2017, https://www.facebook.com/notes/mark-zuckerberg/building-global-community/10154544292806634/.",
    "meta": {
      "theme": "Content Moderation and Platform Governance",
      "region": "Global / United States",
      "use_case": "Social Media Platforms",
      "strategic_category": [
        "national_security",
        "diplomatic_posture",
        "geopolitical_strategy"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "censorship",
        "free speech",
        "disinformation",
        "election interference"
      ],
      "influence_map": [],
      "chunk_index": 219
    },
    "id": "likewar_219"
  },
  {
    "section": "Legal Frameworks and Industry Practices",
    "text": "“cyberporn”: Philip Elmer-Dewitt, “Finding Marty Rimm,” Fortune, July 1, 2015, http://fortune.com/2015/07/01/cyberporn-time-marty-rimm/. Rimm vanished: Ibid. “a red-light district”: Robert Cannon, “The Legislative History of Senator Exon’s Communications Decency Act: Regulating Barbarians on the Information Superhighway,” Field Communications Law Journal 49, no. 1 (1996): 53. Communications Decency Act: Ibid., 58. fine of $100,000: Ibid. one crucial tweak: Christopher Zara, “The Most Important Law in Tech Has a Problem,” Wired, January 3, 2017, https://www.wired.com/2017/01/the-most-important-law-in-tech-has-a-problem/. “the most important law”: Ibid. “protection for ‘Good Samaritan’”: 47 U.S.C. § 230 (1996). no list of rules: “The Big FAQ,” Blogger, (2000), accessed March 20, 2018, https://web.archive.org/web/20010904030704/http://ex.blogger.com:80/howto/faq.pyra#30366. Digital Millennium Copyright Act: 17 U.S.C. § 1204 (1998). “safe harbor” provision: David Kravets, “10 Years Later, Misunderstood DMCA Is the Law That Saved the Web,” Wired, October 27, 2008, https://www.wired.com/2008/10/ten-years-later/. ten-minute limit: Ken Fisher, “YouTube Caps Video Lengths to Reduce Infringement,” Ars Technica, March 29, 2006, https://arstechnica.com/uncategorized/2006/03/6481-2/. $1.7 billion: Matt Marshall, “They Did It! YouTube Bought by Google for $1.65B in Less Than Two Years,” VentureBeat, October 9, 2006, https://venturebeat.com/2006/10/09/they-did-it-youtube-gets-bought-by-gooogle-for-165b-in-less-than-two-years/. “Content ID” system: Kevin J. Delaney, “YouTube to Test Software to Ease Licensing Fights,” Wall Street Journal, June 12, 2007, https://www.wsj.com/articles/SB118161295626932114. John McCain complained: Sarah Lai Stirland, “YouTube to McCain: You Made Your DMCA Bed, Lie in It,” Wired, October 15, 2008, https://www.wired.com/2008/10/youtube-to-mcca/. Digital rights activists: Ibid. pushing a toy stroller: “‘Let’s Go Crazy’ #1,” YouTube video, 0:29, uploaded by Stephanie Lenz, February 7, 2007, https://www.youtube.com/watch?v=N1KfJHFWlhQ. plead “fair use”: “Lenz v. Universal Music Corp.,” Harvard Law Review 129, no. 2289 (June 2016), https://harvardlawreview.org/2016/06/lenz-v-universal-music-corp/.",
    "meta": {
      "theme": "Copyright and Content Regulation",
      "region": "United States",
      "use_case": "Online Platforms",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "DMCA",
        "copyright infringement",
        "safe harbor",
        "content ID"
      ],
      "influence_map": [],
      "chunk_index": 220
    },
    "id": "likewar_220"
  },
  {
    "section": "Content Moderation and Platform Policies",
    "text": "PhotoDNA: “New Technology Fights Child Porn by Tracking Its ‘PhotoDNA,’ ” Microsoft, December 15, 2009, https://news.microsoft.com/2009/12/15/new-technology-fights-child-porn-by-tracking-its-photodna/#sm.0001mpmupctevct7pjn11vtwrw6xj. more than a million instances: Tracy Ith, “Microsoft’s PhotoDNA: Protecting Children and Businesses in the Cloud,” Microsoft, July 15, 2015, https://news.microsoft.com/features/microsofts-photodna-protecting-children-and-businesses-in-the-cloud/. half of all American teenagers: Amanda Lenhart et al., “Social Media and Young Adults,” Pew Research Center, February 3, 2010, http://www.pewinternet.org/2010/02/03/social-media-and-young-adults/. 16-year-old Josh Evans: Lauren Collins, “Friend Game,” The New Yorker, January 21, 2008, https://www.newyorker.com/magazine/2008/01/21/friend-game. “meet a great girl”: Ibid. “an online Frankenstein’s monster”: Ibid. joined the Drew family: Ibid. “You’re a shitty person”: Ibid. convicted, but then acquitted: Kim Zetter, “Judge Acquits Lori Drew in Cyberbullying Case, Overrules Jury,” Wired, July 2, 2009, https://www.wired.com/2009/07/drew-court/. Myspace was technically: “Woman Indicted in Cyber-Bully Suicide,” CBS News, May 15, 2008, https://www.cbsnews.com/news/woman-indicted-in-cyber-bully-suicide/. “will not censor”: Sarah Jeong, “The History of Twitter’s Rules,” Motherboard (blog), Vice, January 14, 2016, motherboard.vice.com/read/the-history-of-twitters-rules. “the free speech wing”: Josh Halliday, “Twitter’s Tony Wang: We Are the Free Speech Wing of the Free Speech Party,” The Guardian, March 22, 2012, https://www.theguardian.com/media/2012/mar/22/twitter-tony-wang-free-speech. “honeypot for assholes”: Charlie Warzel, “‘A Honeypot for Assholes’: Inside Twitter’s 10-Year Failure to Stop Harassment,” BuzzFeed, August 11, 2016, https://www.buzzfeed.com/charliewarzel/a-honeypot-for-assholes-inside-twitters-10-year-failure-to-s?utm_term=.yb3RlEBl8O#.wbwxNORNzy. sustained harassment: Ibid. “not a mediator of content”: Ibid. report abusive tweets: Jeong, “The History of Twitter’s Rules.” “Gamergate”: Aja Romano, “The Data Behind Gamergate Reveals Its Ugly Truth,” The Daily Dot, December 11, 2015, https://www.dailydot.com/parsec/72-hours-of-gamergate-twitter-analysis/. inquest by the United Nations: Allegra Frank, “Anita Sarkeesian, Zoe Quinn, and More Take Aim at Cyber Harassment Against Women,” Polygon, September 25, 2015, https://www.polygon.com/2015/9/25/9399169/united-nations-women-cyber-violence-anita-sarkeesian-zoe-quinn. “Freedom of expression”: Vijaya Gadde, “Twitter Executive: Here’s How We’re Trying to Stop Abuse While Preserving Free Speech,” PostEverything (blog), Washington Post, April 4, 2016, https://www.washingtonpost.com/posteverything/wp/2015/04/16/twitter-executive-heres-how-were-trying-to-stop-abuse-while-preserving-free-speech/?utm_term=.5350fac72e36. vanished from its mission statement: Jeong, “The History of Twitter’s Rules.” banned “unlawful, obscene”: “Terms of Use,” YouTube, 2005, accessed March 20, 2018, https://web.archive.org/web/20050428210756/http://www.youtube.com:80/terms.php. Mexican drug cartels: Manuel Roig-Franzia, “Mexican Drug Cartels Leave a Bloody Trail on YouTube,” Washington Post, April 9, 2007, http://www.washingtonpost.com/wp-dyn/content/article/2007/04/08/AR2007040801005.html. Egyptian anti-torture activist: “YouTube Shuts Down Egyptian Anti-torture Activist’s Account,” CNN, November 29, 2007, http://www.cnn.com/2007/WORLD/meast/11/29/youtube.activist/. loss of its “exclusive footage”: “Israel Brings Battle with Hamas to YouTube,” Fox News, December 31, 2008, http://www.foxnews.com/story/2008/12/31/israel-brings-battle-with-hamas-to-youtube.amp.html. wanted to avoid: Julia Angwin and Hannes Grassegger, “Facebook’s Secret Censorship Rules Protect White Men from Hate Speech but Not Black Children,” ProPublica, June 28, 2017, https://www.propublica.org/article/facebook-hate-speech-censorship-internal-documents-algorithms.",
    "meta": {
      "theme": "Content Moderation and Online Harassment",
      "region": "Global / United States",
      "use_case": "Social Media Platforms",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "cyberbullying",
        "hate speech",
        "online harassment",
        "free speech",
        "censorship"
      ],
      "influence_map": [],
      "chunk_index": 221
    },
    "id": "likewar_221"
  },
  {
    "section": "Internal Policies and External Pressures",
    "text": "15,000 words: Catherine Buni and Soraya Chemaly, “The Secret Rules of the Internet,” The Verge, April 13, 2016, https://www.theverge.com/2016/4/13/11387934/internet-moderator-history-youtube-facebook-reddit-censorship-free-speech. “incitement of violence”: Nick Hopkins, “Revealed: Facebook’s Internal Rulebook on Sex, Terrorism and Violence,” The Guardian, May 21, 2017, https://www.theguardian.com/news/2017/may/21/revealed-facebook-internal-rulebook-sex-terrorism-violence. “kick a person”: Ibid. “cut your tongue out”: Ibid. protests of historians: Ibid. images of breastfeeding: Maya Rhodan, “Facebook Lifts Ban on Exposed Nipples in Breastfeeding Pictures,” Time, June 13, 2014, http://time.com/2869849/facebook-breastfeeding-nipples/. #freethenipple: Alex Bruce-Smith, “Instagram Blocks the #Curvy Hashtag for Nudity Reasons,” Pedestrian.TV, July 17, 2015, https://www.pedestrian.tv/news/instagram-blocks-the-curvy-hashtag-for-nudity-reasons/. portrayals of breastfeeding: Soraya Chemaly, “#FreeTheNipple: Facebook Changes Breastfeeding Mothers Photo Policy,” Huffington Post, June 9, 2014, https://www.huffingtonpost.com/soraya-chemaly/freethe-nipple-facebook-changes_b_5473467.html. not the principal focus: Mythili Sampathkumar, “Facebook Bans Woman Who Shared Article on Breastfeeding,” Independent, October 6, 2017, https://www.independent.co.uk/news/world/australasia/facebook-breastfeeding-ban-woman-shared-article-a7985111.html. subject to U.S. laws: Xeni Jardin, “More on Orkut and Law Enforcement: Brazil,” Boing Boing, March 13, 2007, https://boingboing.net/2007/03/13/more-on-Orkut-and-la.html. dozens of national jurisdictions:",
    "meta": {
      "theme": "Content Moderation Challenges and  Cultural Norms",
      "region": "Global / United States",
      "use_case": "Social Media Platforms",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "value_systems",
        "cultural_ethos"
      ],
      "usage_tags": [
        "censorship",
        "community standards",
        "nudity",
        "breastfeeding",
        "violence"
      ],
      "influence_map": [],
      "chunk_index": 222
    },
    "id": "likewar_222"
  },
  {
    "section": "Online Platforms and Content Moderation Challenges",
    "text": "Glyn Moody reports on Facebook facing fines and investigations in six EU countries for privacy law breaches.  The increasing ease of online publishing, exemplified by Twitter's early development, has created challenges for content moderation.  Jocelyn Richard highlights Google's country-specific censorship of Blogger blogs. Austin Carr discusses Alphabet's Jigsaw initiative aimed at solving complex internet problems. The removal of the neo-Nazi site The Daily Stormer by Cloudflare, as reported by Kate Conger, exemplifies a private company's content moderation decision. Judd Legum notes white supremacists' reaction to Trump's response to Charlottesville. Jon Brodkin discusses Cloudflare's change in abuse policy while refusing to broadly censor the internet.  Conger quotes Cloudflare's CEO on his personal decision to terminate service to The Daily Stormer. Paul Mozur, Mark Scott, and Mike Isaac report on increasing government regulations facing Facebook worldwide. Fox News reports on the use of YouTube by Islamic terrorists to spread propaganda in 2007 and their slow response in removing these clips. Brian Bennett discusses YouTube's approach to allowing users to decide on terrorism-related videos. Scott Shane discusses the influence of Anwar al-Awlaki's online propaganda, including his YouTube videos, and the role of YouTube's algorithm. Eric Holder's letter to Patrick Leahy also addresses al-Awlaki's online activities. Alex Hern reports the eventual removal of al-Awlaki's videos from YouTube after six years.",
    "meta": {
      "theme": "Content Moderation and Terrorism",
      "region": "Global",
      "use_case": "Platform Governance",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "terrorism",
        "censorship",
        "online platforms",
        "free speech"
      ],
      "influence_map": [],
      "chunk_index": 223
    },
    "id": "likewar_223"
  },
  {
    "section": "Social Media Platforms and Extremist Content",
    "text": "Ben Farmer reports on Congress calling for Twitter to block Taliban accounts, while Jon Boone highlights the Taliban's use of Twitter. Jessica Stern and J.M. Berger discuss ISIS's use of Twitter in their book. The Westgate attack in Kenya, as reported by NDTV and Harriet Alexander, demonstrates the real-time use of Twitter during a terrorist event, including the spread of misinformation (noted by Josh Kron).  Alexander further reports Twitter's eventual intervention.  J.M. Berger discusses Twitter's challenges in moderating extremist content. J.M. Berger and Jonathon Morgan provide an estimate of ISIS-related Twitter accounts. David Fidler analyzes the challenge of defining and addressing terrorist activity on Twitter. Andrew Griffin reports on Trump's suggestion to shut down parts of the internet. David Auerbach discusses the complexities of Twitter blocklists.  Nichole Perlroth and Mike Isaac report on terrorists mocking attempts to restrict their use of social media. Rachel Kaser highlights Twitter's claim to have removed a significant amount of extremist content. Wired discusses Google's use of advertising to counter ISIS recruitment. Seth Fiegerman reports on Facebook's growth of its counterterrorism team.",
    "meta": {
      "theme": "Content Moderation and Terrorism",
      "region": "Global",
      "use_case": "Platform Governance",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "social media",
        "terrorism",
        "censorship",
        "online platforms",
        "extremism"
      ],
      "influence_map": [],
      "chunk_index": 224
    },
    "id": "likewar_224"
  },
  {
    "section": "Legal and Social Dimensions of Online Extremism",
    "text": "Gwen Ackerman reports on a lawsuit accusing Facebook of being a tool for Hamas. Jonathan Stempel reports on Facebook winning the dismissal of U.S. lawsuits linked to terrorism. Harriet Salem reports on a lawsuit against Facebook for allegedly inciting Palestinian terror. Nina Iacono Brown discusses the legal implications of holding social networks liable for terrorism. J.M. Berger's study compares white nationalist and ISIS online networks. Cooper Fleishman and Anthony Smith explain the use of the \"(((echoes))))\" symbol by neo-Nazis to target Jews online.  John Herrman discusses how hate groups forced a reckoning on online platforms. Charlie Warzel reports on Twitter's suspension of Milo Yiannopoulos. Joseph Bernstein discusses the role of Breitbart in promoting white nationalism. Carter Evans reports on a spike in hate crimes following the Trump election.  NPI/Radix's YouTube video discusses online purges. David Scharfenberg discusses the debate over banning the alt-right from Twitter. Terrence McCoy examines the alt-right and the events in Charlottesville. Herrman again highlights the spread of hate speech online. The Associated Press reports on Facebook banning white nationalist accounts.  Brianna Sacks reports on Reddit removing Nazi and alt-right groups. Matt Stevens reports on dating apps cracking down on hate speech following Charlottesville.",
    "meta": {
      "theme": "Online Extremism and Hate Speech",
      "region": "Global, primarily U.S.",
      "use_case": "Platform Governance, Legal Liability",
      "strategic_category": [
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "hate speech",
        "alt-right",
        "white nationalism",
        "online harassment"
      ],
      "influence_map": [],
      "chunk_index": 225
    },
    "id": "likewar_225"
  },
  {
    "section": "The Challenge of Content Moderation at Scale",
    "text": "Times, August 24, 2017, https://www.nytimes.com/2017/08/24/technology/okcupid-christopher-cantwell.html?smid=tw-nytimes&smtyp=cur%20Most%20deeply%20 impacted:%20; https://www.wsj.com/articles/facebook-employees-push ed-to-remove-trump-posts-as-hate-speech-1477075392.\nMost deeply impacted: Deepa Seetharaman, “Facebook Employees Pushed to Remove Trump’s Posts as Hate Speech,” October 21, 2016, https://www.wsj.com/articles/facebook-employees-pushed-to-remove- trump-posts-as-hate-speech-1477075392.\n“a pretty crazy idea”: Mark Zuckerberg, “Live from the Techonomy Conference,” Facebook, November 17, 2016, https://www.facebook.com/ zuck/videos/10103248351713921/.\na private scolding: Adam Entous, Elizabeth Dwoskin, and Craig Timberg, “Obama Tried to Give Zuckerberg a Wake-Up Call over Fake News on Facebook,” Washington Post, September 24, 2017, https://www .washingtonpost.com/business/economy/obama-tried-to-give-zucker berg-a-wake-up-call-over-fake-news-on-facebook/2017/09/24/15d19b12- ddac-4ad5-ac6e-ef909e1c1284_story.html.\ntried to reassure users: Mark Zuckerberg, https://www.facebook.com/ zuck/posts/10103253901916271.\ncrowdsource solutions: Sheera Frenkel, “Renegade Facebook Employ- ees Form Task Force to Battle Fake News,” BuzzFeed, November 14, 2016, https://www.buzzfeed.com/sheerafrenkel/renegade-facebook-em ployees-form-task-force-to-battle-fake-n?utm_term=.pqkjwVXwK0#. lp00RvnRBr.\nfear of violating: Mike Isaac, “Facebook, in Cross Hairs After Election, Is Said to Question Its Influence,” New York Times, November 12, 2016, https://www.nytimes.com/2016/11/14/technology/facebook-is-said-to- question-its-influence-in-election.html?_r=0.\n“Information Operations and Facebook”: Jen Weedon, William Nu- land, and Alex Stamos, “Information Operations and Facebook” (report, Facebook Security, April 27, 2017), https://fbnewsroomus.files.wordpress .com/2017/04/facebook-and-information-operations-v1.pdf.\nnamed its adversary: Alex Stamos, “An Update on Information Op- erations on Facebook,” Facebook Newsroom, September 6, 2017, https:// newsroom.fb.com/news/2017/09/information-operations-update/.\na crucial nine months: Seetharaman, McMillan, and Wells, “Tone- Deaf.”\nFrench and German governments: Dustin Volz and Jonathan Landay, “Twitter to Brief Congress on Possible Russia-Backed Ads: U.S. Senator,” Reuters, September 7, 2017, https://www.reuters.com/article/us-twitter- propoganda/twitter-to-brief-congress-on-possible-russia-backed-ads-u-s- senator-idUSKCN1BI22R.",
    "meta": {
      "theme": "Content Moderation and Platform Governance",
      "region": "Global",
      "use_case": "Social Media Platforms",
      "strategic_category": [
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "fake news",
        "disinformation",
        "election interference",
        "hate speech"
      ],
      "influence_map": [],
      "chunk_index": 226
    },
    "id": "likewar_226"
  },
  {
    "section": "The Human Cost of Content Moderation",
    "text": "a thousand graphic images: Olivia Solon, “Underpaid and Overbur- dened: The Life of a Facebook Moderator,” The Guardian, May 25, 2017, https://www.theguardian.com/news/2017/may/25/facebook-moderator- underpaid-overburdened-extreme-content.\na million pieces of content: Buni and Chemaly, “The Secret Rules of the Internet.”\na 74-year-old grandfather: Olivia Solon, “Facebook Killing Video Puts Moderation Policies Under the Microscope, Again,” The Guardian, April 17, 2017, https://www.theguardian.com/technology/2017/apr/17/face book-live-murder-crime-policy.\nan estimated 150,000 workers: Benjamin Powers, “The Human Cost of Monitoring the Internet,” Rolling Stone, September 9, 2017, https://www .rollingstone.com/culture/features/the-human-cost-of-monitoring-the- internet-w496279.\nIndia and the Philippines: Adrian Chen, “The Laborers Who Keep Dick Pics and Beheadings out of Your Facebook Feed,” Wired, October 23, 2014, https://www.wired.com/2014/10/content-moderation/.\nbright young college graduates: Sarah T. Roberts, “Behind the Screen: The People and Politics of Commercial Content Moderation” (presenta- tion at re:publica 2016, Berlin, May 2, 2016), transcript available at Open Transcripts, http://opentranscripts.org/transcript/politics-of-commer cial-content-moderation/.\nreduced libido: Brad Stone, “Policing the Web’s Lurid Precincts,” New York Times, July 28, 2010, http://www.nytimes.com/2010/07/19/ technology/19screen.html.\nregular psychological counseling: Abby Ohlheiser, “The Work of Moni- toring Violence Online Can Cause Real Trauma. And Facebook Is Hiring,” Washington Post, May 4, 2017, https://www.washingtonpost. com/news/the-intersect/wp/2017/05/04/the-work-of-monitoring-vi olence-online-can-cause-real-trauma-and-facebook-is-hiring/?utm_ term=.3fb95a5143da.\n“compassion fatigue”: Greg Hadley, “Forced to Watch Child Porn for Their Job, Microsoft Employees Developed PTSD, They Say,” McClatchy, January 11, 2017, http://www.mcclatchydc.com/news/nation-world/na tional/article125953194.html.\n“internal video screen”: Ibid.\njust 55 employees: Cade Metz, “Why WhatsApp Only Needs 50 Engi- neers for Its 900m Users,” Wired, September 15, 2015, https://www.wired .com/2015/09/whatsapp-serves-900-million-users-50-engineers/.\nnone of whom spoke Arabic: Heather Timmons, “Why It Remains Dif- ficult to Shut Down Jihadist Propaganda Online,” Defense One, January 12, 2015, http://www.defenseone.com/threats/2015/01/why-it-remains- difficult-shut-down-jihadist-propaganda-online/102684/. ",
    "meta": {
      "theme": "Content Moderation and its Psychological Impact",
      "region": "Global",
      "use_case": "Social Media and Tech Platforms",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "content moderation",
        "psychological trauma",
        "labor exploitation",
        "outsourcing"
      ],
      "influence_map": [],
      "chunk_index": 227
    },
    "id": "likewar_227"
  },
  {
    "id": "likewar_228",
    "section": "Extracted Content",
    "text": "Its Biggest Problem,” Wall Street Journal, October 1, 2017,",
    "meta": {
      "theme": "unspecified",
      "region": "unspecified",
      "use_case": "doctrine_selector",
      "strategic_category": {},
      "economic_category": {},
      "civilizational_category": {},
      "usage_tags": [],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": []
      },
      "chunk_index": 228
    }
  },
  {
    "section": "Introduction and Early Internet History",
    "text": "“ocracy” views: Parag Khanna, “To Beat Populism, Blend De- mocracy and Technocracy, S’pore Style,” Straits Times, January 21, 2017. the Flux movement: Mark Kaye and Nathan Spataro, “Redefining De- mocracy: On a Democratic System Designed for the 21st Century, and Dis- rupting Democracy for Good” (unpublished paper, January 2017). “dangerous speech”: “Understanding Dangerous Speech,” Dangerous Speech Project, accessed March 12, 2018. “The more we connect”: Chris Matyszcyk, “Facebook’s New Ads Aren’t as Friendly as They Seem,” CNET, February 16, 2015. like Mark Zuckerberg: Mark Zuckerberg, “I Wanted to Share Some Thoughts on Facebook and the Election,” Facebook, November 12, 2016; Callum Bor- chers, “Twitter Executive on Fake News: ‘We Are Not the Arbiters of Truth,’ ” The Fix (blog), Washington Post, February 8, 2018. “answers to simple questions”: Lorenzo Franceschi-Bicchierai, “If Face- book Actually Wants to Be Transparent, It Should Talk to Journalists,” Motherboard (blog), Vice, November 10, 2017. the word “transparency”: Charlie Warzel, “Twitter Would Like You to Know It Is Committed to Being More Transparent,” BuzzFeed, Octo- ber 12, 2017. Reddit is the only one: Caroline O., “Russian Propaganda on Reddit,” Arc (blog), Medium, April 17, 2018. effective information literacy education: John Cook, Stephan Lewan- dowsky, and Ullrich K. H. Ecker, “Neutralizing Misinformation Through Inoculation: Exposing Misleading Argumentation Techniques Reduces Their Influence,” PLoS ONE 12, no. 5 (May 2017). not a single social media firm: Alexis Madrigal, “15 Things We Learned from the Internet Giants,” The Atlantic, November 2, 2017. outside researchers raised concerns: Charlie Warzel, “Researchers Are Upset That Twitter Is Dismissing Their Work on Election Interference,” BuzzFeed, October 3, 2017. “Facebook is only”: Zeynep Tufekci, “It’s the (Democracy Poisoning) Age of Free Speech,” Wired, January 16, 2018. the least informed: Christoph Aymanns, Jakob Foerster, and Co-Pierre Georg, “Fake News in Social Networks,” arXiv:1708.06233 [cs.AI], August 2017; Mark Buchanan, “Why Fake News Spreads So Quickly on Facebook,” Sydney Morning Herald, September 1, 2017. “easily manipulated”: Sam Wineburg and Sarah McGre, “Lateral Read- ing: Reading Less and Learning More When Evaluating Digital Infor- mation” (working paper no. 2017-A1, Stanford History Education Group, Stanford University, October 2017). approached the task “laterally”: Ibid. “a maze”: Carrie Spector, “Stanford Scholars Observe ‘Experts’ to See How They Evaluate the Credibility of Information Online,” Stanford News Service, Stanford University, October 24, 2017. “seeking context and perspective”: Ibid. Reality is one: Paul J. Griffiths, An Apology for Apologetics: A Study in the Logic of Interreligious Dialogue (Wipf and Stock, 2007), 46. most important insights: Plato, “The Allegory of the Cave,” Republic, 7.514a2–517a7, trans. Thomas Sheehan. “believe whatever you want”: The Matrix, directed by the Wachowski Brothers (Warner Bros., 1999).",
    "meta": {
      "theme": "Information Warfare and Disinformation",
      "region": "Global",
      "use_case": "Understanding the spread and impact of disinformation",
      "strategic_category": [
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "social media",
        "propaganda",
        "censorship",
        "information literacy"
      ],
      "influence_map": [],
      "chunk_index": 229
    },
    "id": "likewar_229"
  },
  {
    "section": "Index and further examples",
    "text": "Abbottabad, Pakistan, 53–55 Abdallat, Lara, 213 account suspensions, 92, 235, 236, 242 Active Measures Working Group, 263 Advanced Research Projects Agency (ARPA), 26–27 Advocates for Peace and Urban Unity, 14 Ahmadinejad, Mahmoud, 60 AIDS disinformation campaign, 104, 208 Airbnb, 239 Al Qaeda, 54, 65, 79–80, 149, 234 Alabed, Bana, 214–16 al-Assad, Bashar, 9, 72, 88, 215 al-Awlaki, Anwar, 234 Albright, Jonathan, 113 Alefantis, James, 128 Algeria, 88–89 algorithms, 124, 139, 141, 147, 209, 221, 251 Ali, Muhammad, 254 al-Jabari, Ahmed, 193 Allen, George, 55–57, 58 #AllEyesOnISIS, 5–7, 10 Al-Shabaab, 235 alternative (alt-)right, 133–34, 170, 188–89, 232, 237–39 Al-Werfalli, Mahmoud, 76 Al-Zomor, Aboud, 151 Amazon, 41 America Online, 218–19, 244–45 American Civil War, 30–31 Android, 48 anger, 162–63, 165 Anonymous (hacktivist group), 212–13 anti-Semitism, 146, 190, 198, 238 anti-vaxxers, 124–25 “Anyone Can Become a Troll” (re- port), 165 Apple, 47–51 Apprentice, The (TV show), 2 apps, 47–48, 58, 101, 200 Arab Spring, 85–87, 126, 183 Arendt, Hannah, 170 Argus Panoptes, 57 arms dealers, 76–77 Armstrong, Matt, 108 Aro, Jessikka, 114 ARPANET, 27, 35–42 historical background, 27–35 Arquilla, John, 182–83 Index arrests, 91, 92, 100, 200 artificial intelligence, 250, 255–56 Aristotle, 168 Ashley Madison (social network), 59 Asif, Khawaja, 135 astroturfing, 142 AT&T, 26, 31, 37–38 “@” symbol, 36 Athar, Sohaib, 53–55 attacks, on others. See discrediting; trolls and trolling attention economy (and war), 148–80 authenticity, 165–69 community, 169–73 emotion, 161–65 fake news, 120 future of, 261–73 inundation, 173–79 ISIS, 148–54 reality stars, 154–57 Trump, 3–4, 125 attention span, 158 audience engagement, 65–66, 119, 152, 165–67 Austen, Ben, 13 authenticity, 165–69, 186, 215 authoritarianism, 86–87, 102–3, 116, 262–63 Bahrain, 89 Baidu Baike, 98 balkanization, 89 Baltica, 108, 206 Bangladesh, 140",
    "meta": {
      "theme": "Examples and Case Studies",
      "region": "Global",
      "use_case": "Illustrating the various actors and tactics involved in information warfare",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security",
        "diplomatic_posture"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [
        "cultural_ethos",
        "historical_memory"
      ],
      "usage_tags": [
        "cyber warfare",
        "terrorism",
        "social engineering",
        "political campaigns"
      ],
      "influence_map": [],
      "chunk_index": 230
    },
    "id": "likewar_230"
  },
  {
    "section": "Introduction - Social Media's Impact",
    "text": "The 70 Mumbai 2008 massacre, the Chicago gang violence, and the rise of ISIS demonstrate the profound impact of social media on global events. From influencing elections to fueling conflicts, social media's role in shaping narratives and mobilizing individuals is undeniable.  This text explores the evolution of online communication, from its early days to the complex landscape we navigate today, examining its influence on political discourse, conflict, and even the spread of misinformation.",
    "meta": {
      "theme": "Social Media's Impact on Global Events",
      "region": "Global",
      "use_case": "Analysis of Social Media's Influence",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "social media analysis",
        "conflict studies",
        "information warfare"
      ],
      "influence_map": [],
      "chunk_index": 231
    },
    "id": "likewar_231"
  },
  {
    "section": "The Evolution of Online Communication",
    "text": "The journey from ARPANET to the modern internet is marked by rapid technological advancements, shaping how we communicate.  From email and early online forums to the rise of social media giants like Facebook and Twitter, the speed and accessibility of information have transformed our world. Figures like Licklider and Taylor, with their vision of the 'Computer as a Communication Device,' laid the groundwork for this interconnected age.  This evolution has also brought challenges, including the spread of misinformation and the rise of online polarization.",
    "meta": {
      "theme": "History of Online Communication",
      "region": "Global",
      "use_case": "Technological Development and Societal Impact",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "temporal_orientation"
      ],
      "usage_tags": [
        "internet history",
        "digital communication",
        "technological change"
      ],
      "influence_map": [
        "Licklider and Taylor"
      ],
      "chunk_index": 232
    },
    "id": "likewar_232"
  },
  {
    "section": "Disinformation and Propaganda",
    "text": "The digital age has amplified the reach and impact of disinformation and propaganda.  From the Cold War to the present day, states and non-state actors have utilized online platforms to manipulate public opinion and sow discord. The Gerasimov Doctrine, outlining Russia's approach to information warfare, highlights the blurring lines between conventional and unconventional conflict.  Fake news, deep fakes, and botnet manipulation represent new challenges to truth and democratic processes.  This section examines how disinformation campaigns, like those surrounding the MH17 flight downing and the 2016 U.S. presidential election, exploit the vulnerabilities of online spaces.",
    "meta": {
      "theme": "Information Warfare and Manipulation",
      "region": "Global",
      "use_case": "Analysis of Disinformation Tactics",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [],
      "usage_tags": [
        "disinformation",
        "propaganda",
        "information warfare",
        "cybersecurity"
      ],
      "influence_map": [
        "Gerasimov Doctrine"
      ],
      "chunk_index": 233
    },
    "id": "likewar_233"
  },
  {
    "section": "Social Media and Conflict",
    "text": "Social media has become a battleground in modern conflicts, from the Arab Spring uprisings to the ongoing conflict between Russia and Ukraine.  Platforms like Facebook and Twitter are used to mobilize supporters, spread propaganda, and even coordinate attacks.  The rise of ISIS and its sophisticated use of social media for recruitment and propaganda demonstrates the power of online platforms in shaping the narrative of conflict. This section examines how social media has impacted conflicts in Gaza, Myanmar, and elsewhere, exploring the role of citizen journalism, hashtag activism, and the spread of violent extremism.",
    "meta": {
      "theme": "Social Media's Role in Conflict",
      "region": "Global",
      "use_case": "Impact on Conflict Dynamics and Mobilization",
      "strategic_category": [
        "military_doctrine",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "conflict studies",
        "terrorism",
        "social media activism",
        "citizen journalism"
      ],
      "influence_map": [],
      "chunk_index": 234
    },
    "id": "likewar_234"
  },
  {
    "section": "The Future of Social Media and its Implications",
    "text": "The future of social media presents both opportunities and challenges. Advancements in artificial intelligence, like deep learning and generative networks, have the potential to revolutionize how we interact online, but also raise concerns about the creation and spread of even more sophisticated forms of disinformation. The increasing need for content moderation and the ongoing debate surrounding free speech online highlight the complex ethical and societal dilemmas we face.  This section explores potential future scenarios and offers recommendations for navigating the evolving landscape of social media.",
    "meta": {
      "theme": "Future of Social Media and its Societal Impact",
      "region": "Global",
      "use_case": "Forecasting and Recommendations",
      "strategic_category": [],
      "economic_category": [],
      "civilizational_category": [
        "value_systems"
      ],
      "usage_tags": [
        "artificial intelligence",
        "disinformation",
        "free speech",
        "content moderation"
      ],
      "influence_map": [],
      "chunk_index": 235
    },
    "id": "likewar_235"
  },
  {
    "section": "Introduction - LikeWar Techniques",
    "text": "masking technology, 89–90 India, 62–67, 89, 136 Indonesia, 213 influence botnets, 144–45 campaign ads, 178 confirmation bias, 121, 125, 130, 132–33, 137, 208 elections. See elections of ISIS, 153–54 sharing and, 124 of super-spreaders, 130 use of social media, 39, 44, 46, 48–49, 51–52, 95, 137 See also consequences; politics; war information authoritarianism, 86–87, 102–3 in book form, 45 collection of, 77–82 history of, 27–29 intelligence gathering, 61 units of, 26 volume of, 46 weaponization of, 107, 181–86, 261–64 Wikipedia, 45 information jihad, 154 information literacy, 269–71 “Information Operations and Face- book” (document), 241 information war campaigns ISIS, 4–7, 8–9, 203–6 Russian, 203–6 Infowars, 128, 204, 208 Instagram, 61 anti-hate organizations, 172 authenticity, 165–66 botnets, 139, 144 growth of, 49 terrorism, 4, 65–66 instant gratification. See feedback loop intellectual property rights, 225–26 intelligence gathering, 61, 77–82, 96–97, 101–2, 177 See also surveillance Intergalactic Computer Network, 26, 27 internet China and, 50–51, 95–103 commercialization of, 39 control of, 88 definition, 24–25 future of, 261–73 growth of, 39, 44 impact on society, 41 international communication, 182 mobility, 47–51 origin of, 35–42 physical components of, 87–90 reach of, 51–52 regulation, 223–32 usage vs. understanding, 24–25 internet blackouts, 88 Internet Research Agency, 111–14, 144 internet revolutions, 83–84 internet service providers (ISPs), 88 inundation, 173–79 inventions. See technology iPhone, 47 Iran, 84, 89",
    "meta": {
      "theme": "Information Warfare",
      "region": "Global",
      "use_case": "Propaganda, Disinformation, Social Media Manipulation",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [],
      "usage_tags": [
        "information_operations",
        "social_media",
        "internet_governance"
      ],
      "influence_map": [],
      "chunk_index": 236
    },
    "id": "likewar_236"
  },
  {
    "section": "ISIS and LikeWar",
    "text": "Iraq conflict in, 5–6 deaths in, 153 internet access of, 5 ISIS soldier capture, 65–66 Mosul, 4–7, 8–9, 10 weapons, 77 Iron Dome, 194 Ironghazi, 164 ISIS Abu Hussain al-Britani, 148–49 audience participation, 65–66, 152 countering violent extremism, 185, 213–14 deprogramming jihadists, 172 ISIS (cont.) emotion, 162–63 fake news, 136–37 isolation and community, 170 #killajew, 198 marketing and brand of, 151–54 Mosul, attack of, 4–7, 8–11, 150 narrative success of, 159, 160 vs. Operation Inherent Resolve, 60 origin of, 79 propaganda, 212–13, 247 Raqqa city attack, 70 recruitment and training, 150–51, 167–68 Twitter and, 235–36 Islamic State. See ISIS isolation, 170 Israel, 193–200, 237 Israeli Defense Forces (IDF), 185, 193–200 Jackson, Janet, 218–19 Jackson, Michael, 1–2 Jenkins, Brian, 150 Jewish Internet Defense Force, 198 Jihad, Janna, 197–98 Jihadi Design, 151 Jingwang (web-cleansing) app, 101 Jobs, Steve, 47 “Johnny Appleseed,” 83–84 Johnson, Lyndon B., 34, 209 Joint Readiness Training Center, 259–60 Joint Special Operations Command (JSOC), 79–80 Jones, Alex, 128 journalists, 91–92 censorship of, 90, 91, 92 discrediting of, 15, 114 disintermediation, 54–55 murder of, 69–70 photographs, 62–63 Russia and, 105–6 social media and, 135 vs. spies, 75 Twitter, 49 validation vs. information, 134 junk news, 131 See also fake news Kardashians, 155 Karim, Jawed, 218 Kashmir, 171, 242",
    "meta": {
      "theme": "Terrorism and Online Propaganda",
      "region": "Middle East, Global",
      "use_case": "Recruitment, Propaganda Dissemination, Information Operations",
      "strategic_category": [
        "military_doctrine",
        "national_security"
      ],
      "economic_category": [],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "terrorism",
        "isis",
        "propaganda",
        "social_media"
      ],
      "influence_map": [],
      "chunk_index": 237
    },
    "id": "likewar_237"
  },
  {
    "id": "likewar_238",
    "section": "Introduction - Chapter 1",
    "text": "132, 209–10 post-traumatic stress disorder (PTSD), 247 power botnets, 138–39, 176, 184 censorship. See censorship Index 397 power (cont.) concentration of, in social media, 49–50, 143 elections. See elections followers. See followers See also leaders; politics Pratt, Spencer, 154–57, 158, 159 Predata, 77 presentism, 66–67 Prince, Matthew, 232–33 Princes of Malibu (TV show), 155 printing press, 28–29, 90, 91 privacy, 251 profit botnets, 139, 141 internet and, 39 Macedonia and, 118–21 vs. propaganda, 236, 243 social media companies, 45–46, 221 Project Alamo, 176–77, 255 propaganda Al Qaeda, 234 amount of, 179 anti-Semitism, 190 Belarusian regime, 86 Britain, 181 China and, 96, 100–101, 139–40 enemy casualties, 201 IDF vs. Palestinians, 194–95 by ISIS, 8–9, 150–53, 162–63, 235–36 Israel, 199 netwar, 183–85 Nissenbaum and, 92–93 Russia and, 103–17, 204, 208 Trump and, 174–75 via radio (World War II), 7–8, 18, 32–33 ProPublica, 140 Prosser, Michael, 191, 192 Protestant Reformation, 28 public awareness, 264–65 Pulitzer, Joseph, 31 “Purloined Letter, The” (Poe), 110 Putin, Vladimir, 81, 94, 102, 104, 105, 106, 107, 208 “Question More,” 107, 108 racism Charlottesville, VA, 115, 138, 189, 232, 239 white supremacists, 115, 170, 188–89, 232, 237–39 radio intelligence gathering, 78 invention of, 32–33 transatlantic cables, 181 as weapon in World War II, 7–8 #RapeMelania hoax, 210–11, 214 Raqqa Is Being Slaughtered Silently, 70 reality stars, 154–57",
    "meta": {
      "theme": "Information Warfare",
      "region": "Global",
      "use_case": "Propaganda, Censorship, Social Media Manipulation",
      "strategic_category": [
        "military_doctrine",
        "geopolitical_strategy",
        "national_security"
      ],
      "economic_category": [
        "economic_warfare"
      ],
      "civilizational_category": [
        "cultural_ethos",
        "value_systems"
      ],
      "usage_tags": [
        "disinformation",
        "misinformation",
        "influence_operations",
        "cyberwarfare"
      ],
      "influence_map": [],
      "chunk_index": 238
    }
  },
  {
    "id": "likewar_239",
    "section": "Extracted Content",
    "text": "The text covers the early days of internet warfare, highlighting examples like the Zapatista National Liberation Army",
    "meta": {
      "theme": "unspecified",
      "region": "unspecified",
      "use_case": "doctrine_selector",
      "strategic_category": {},
      "economic_category": {},
      "civilizational_category": {},
      "usage_tags": [],
      "influence_map": {
        "influenced_works": [],
        "modern_applications": []
      },
      "chunk_index": 239
    }
  }
]